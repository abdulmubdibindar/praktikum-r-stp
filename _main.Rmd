---
title: "Modul Praktik Statistika Untuk Perencanaan"
subtitle: "Penggunaan R dalam Pengolahan Data Kuantitatif"
site: bookdown::bookdown_site
output:
    bookdown::gitbook:
        css: style.css
        split_bib: false
    bookdown::pdf_book:
        latex_engine: xelatex
        citation_package: natbib
        keep_tex: true
        pandoc_args: ["--lua-filter=capaian.lua"]
        includes:
            in_header: preamble.tex
bibliography: referensi.bib
biblio-title: "Referensi"
link-citations: true
---

```{r setup, include=FALSE}
# Opsi ini penting untuk mencegah error LaTeX karena karakter khusus dari pesan warning/error
options(cli.hyperlink = FALSE)

# Konfigurasi knitr untuk output gambar
knitr::opts_chunk$set(
    echo = FALSE,
    fig.path = "figures/", # Gunakan folder tanpa underscore untuk GitHub Pages
    message = FALSE,
    warning = FALSE
)

```

# Pengantar {.unnumbered}

Selamat datang di modul daring Praktikum Statistika untuk Perencanaan. Modul ini digunakan untuk mendampingi kalian mengikuti Praktikum dalam mata kuliah Statistika untuk Perencanaan, mata kuliah di Program Studi Perencanaan Wilayah dan Kota, Institut Teknologi Sumatera.

Modul praktikum ini akan mendampingi Anda mempelajari pengolahan statistik menggunakan bahasa pemrograman R. Untuk itu, modul ini terbagi menjadi **9 modul** yang disusun secara bertahap, dimulai dari pengenalan dasar hingga analisis multivariat:

| Modul |                   Topik                    |                                      Deskripsi Singkat                                       |
| :---: | :----------------------------------------: | :------------------------------------------------------------------------------------------: |
|   1   |        Pengolahan Data Terstruktur         | Dasar *data wrangling*: Impor, seleksi, standardisasi, penggabungan, dan ekspor data/dataset |
|   2   |           Statistika Deskriptif            |                 Perhitungan proporsi, mean, median, standar deviasi, dan IQV                 |
|   3   |              Visualisasi Data              |        Pembuatan grafik dengan `ggplot2`: bar chart, histogram, boxplot, scatter plot        |
|   4   | Distribusi Sampling & Interval Kepercayaan |                  Simulasi sampling, standard error, dan estimasi parameter                   |
|   5   |               Uji Hipotesis                |                 Uji hipotesis 1 dan 2 populasi untuk rata-rata dan proporsi                  |
|   6   |         Korelasi Nominal & Ordinal         |                            Koefisien V Cramer, Lambda, dan Gamma                             |
|   7   |              Korelasi Metrik               |                            Koefisien Spearman's Ï dan Pearson's r                            |
|   8   |               Regresi Linear               |                            Regresi linear sederhana dan berganda                             |
|   9   |         Analisis Komponen Prinsip          |                                   PCA dan Analisis Faktor                                    |

Setiap modul dilengkapi dengan **capaian pembelajaran**, **contoh kode**, dan **soal latihan** yang harus dikerjakan.

------------------------------------------------------------------------

# Pengenalan R dan RStudio {.unnumbered}

Selamat datang di dunia pengolahan data yang lebih canggih! Dalam praktikum ini, kalian akan berkenalan dengan teknik pengolahan dan analisis data dengan menggunakan bahasa pemrograman bernama R. R adalah bahasa pemrograman yang dibuat khusus untuk keperluan analisis statistik.

## Apa itu R?

R adalah lingkungan perangkat lunak (*software environment*) dan bahasa pemrograman yang digunakan untuk komputasi statistik dan grafik. R dikembangkan oleh Ross Ihaka dan Robert Gentleman di Universitas Auckland, Selandia Baru, pada awal tahun 1990-an sebagai evolusi dari bahasa S yang sebelumnya dikembangkan di Bell Laboratories [@history_overview_r]. R bersifat *open-source* (berlisensi GNU GPL), yang berarti dapat digunakan secara gratis dan dikembangkan secara kolaboratif oleh komunitas global [@r_wikipedia].

Keunggulan utama R dalam konteks perencanaan dan pemerintahan meliputi:

1.  **Ekosistem Paket yang Luas**: R memiliki puluhan ribu paket (*packages*) di CRAN untuk berbagai keperluan, mulai dari manipulasi data, pemodelan statistik, hingga analisis geospasial menggunakan `sf` dan `terra` [@spatial_r_sf; @spatial_data_science_terra].
2.  **Visualisasi Data**: Dengan paket seperti `ggplot2` dan `Shiny`, R memungkinkan pembuatan grafik berkualitas tinggi dan dashboard interaktif yang informatif [@shiny_gallery].
3.  **Dukungan Kebijakan Berbasis Data**: R mendukung implementasi kebijakan "Satu Data Indonesia" dengan kemampuan standardisasi, interoperabilitas, dan transparansi metode analisis yang dapat diaudit [@satu_data_local_govt]. R memfasilitasi proses ETL (*Extract-Transform-Load*) otomatis untuk membersihkan data dari berbagai instansi [@r_public_data].

Dalam bidang perencanaan wilayah dan kota, R digunakan untuk:

-   **Analisis Geospasial**: Mengelola data vektor dan raster untuk pemetaan dan pemodelan lingkungan [@spatial_data_science_terra].
-   **Perencanaan Transportasi**: Menggunakan paket seperti `stplanr` untuk analisis jaringan, rute, dan pemodelan transportasi berkelanjutan [@stplanr_cran; @sustainable_transport_stplanr].
-   **Simulasi Kebijakan**: Melakukan simulasi dampak kebijakan publik, seperti perubahan penggunaan lahan atau intervensi sosial, sebelum diterapkan secara nyata [@simulation_public_policies].

## Mengapa Menggunakan R?

R memiliki kelebihan yang signifikan dibandingkan dengan alat analisis berbasis antarmuka grafis (*Graphical User Interface* - GUI) seperti SPSS atau Microsoft Excel. Berikut adalah beberapa alasan utama mengapa R menjadi standar de facto dalam sains data modern:

1.  **Reproduksibilitas (*Reproducibility*)**:
    Berbeda dengan perangkat lunak berbasis *point-and-click* di mana langkah-langkah analisis seringkali sulit dilacak kembali, R bekerja berbasis skript (*script-based*). Setiap langkah analisis, mulai dari pembersihan data hingga pembuatan model, terekam secara eksplisit dalam kode. Hal ini memungkinkan analisis untuk diverifikasi, diaudit, dan dijalankan ulang oleh orang lain (atau diri kita sendiri di masa depan) dengan hasil yang identik, sebuah prinsip fundamental dalam penelitian ilmiah yang kredibel [@peng2011reproducible; @gandrud2013reproducible].

2.  **Fleksibilitas dan Kemampuan Kostumisasi**:
    R tidak membatasi pengguna pada menu yang sudah tersedia. Sebagai bahasa pemrograman, R memungkinkan kita untuk membangun alat analisis sendiri atau memodifikasi metode yang sudah ada sesuai dengan kebutuhan spesifik penelitian, memberikan fleksibilitas yang hampir tak terbatas dibandingkan perangkat lunak tertutup (*proprietary*) [@wickham2016r].

3.  **Gratis dan *Open Source***:
    Sebagai perangkat lunak *open source*, R dapat digunakan sepenuhnya secara gratis. Ini menghilangkan hambatan biaya lisensi yang mahal yang sering ditemui pada perangkat lunak komersial, membuatnya sangat aksesibel bagi mahasiswa, peneliti, dan pemerintah daerah dengan anggaran terbatas.

4.  **Komunitas yang Masif**:
    Dukungan komunitas R sangat luar biasa melalui platform seperti StackOverflow dan R-Bloggers. Jika Anda menemui masalah, kemungkinan besar orang lain sudah pernah menghadapinya dan solusinya sudah tersedia secara daring.

## Apa itu RStudio?

RStudio (yang kini bertransformasi menjadi **Posit**) adalah *Integrated Development Environment* (IDE) untuk R. Diluncurkan pertama kali pada tahun 2009, RStudio menyediakan antarmuka visual yang lebih ramah pengguna dibandingkan antarmuka baris perintah (*command line*) asli R [@about_posit]. Fitur-fitur seperti penyorotan sintaksis (*syntax highlighting*), *auto-completion*, dan manajemen *workspace* membuat pengguna baru lebih mudah mempelajari dan menggunakan R. Transformasi menjadi Posit mencerminkan komitmen terhadap ekosistem *data science* modern yang lebih luas, termasuk dukungan untuk Python [@goodbye_rstudio].

Gambar \@ref(fig:jendela-rstudio) memberikan penjelasan singkat tentang tampilan jendela RStudio yang terdiri atas 4 panel.

```{r jendela-rstudio, fig.cap = "Bagian-bagian jendela RStudio", echo=FALSE, fig.align='center'}
knitr::include_graphics("images/jendela_rstudio.png")
```

1.  Panel *Environment* yang menampilkan daftar data atau variabel yang telah kita impor atau buat.
2.  Panel *Files, Plots, dan Help*, tempat kita melihat daftar *file* yang tersedia, grafik yang dihasilkan, dan menemukan dokumen bantuan untuk berbagai bagian dari R.
3.  Panel *Console*, digunakan untuk menjalankan kode.
4.  Panel *Script*, digunakan untuk menulis kode. Di sinilah kita akan menghabiskan sebagian besar waktu kerja kita.

## Instalasi R dan RStudio

Sebelum memulai praktikum, kalian perlu menginstal R dan RStudio terlebih dahulu. R harus diinstal **sebelum** RStudio, karena RStudio memerlukan instalasi R yang berfungsi untuk dapat berjalan.

**Langkah 1: Instalasi R**

1. Kunjungi situs resmi CRAN di **[cran.r-project.org](https://cran.r-project.org)**
2. Pilih sistem operasi Anda (Windows/macOS/Linux)
3. Untuk **Windows**: Klik "base" lalu unduh installer terbaru
4. Untuk **macOS**: Pilih versi sesuai prosesor (Apple Silicon M1/M2/M3/M4/M5 atau Intel)
5. Jalankan file installer dan ikuti petunjuk hingga selesai

**Langkah 2: Instalasi RStudio**

1. Kunjungi situs resmi Posit di **[posit.co/downloads](https://posit.co/downloads)**
2. Unduh **RStudio Desktop** versi gratis sesuai sistem operasi Anda
3. Jalankan installer dan ikuti petunjuk hingga selesai

**Verifikasi**: Buka RStudio setelah instalasi selesai. RStudio akan otomatis mendeteksi instalasi R yang sudah ada.

## Cara Menjalankan R

Cara (paling) utama untuk menjalankan perintah bahasa pemrograman R adalah dengan mengetikkannya langsung di **Console** (jendela nomor 3 pada Gambar \@ref(fig:jendela-rstudio)).

Misalnya, jika Anda mengetikkan `1 + 1` di Console lalu menekan **Enter**, R akan langsung memberikan jawabannya.

::: rmdexercise
**Aktivitas Mandiri: Halo Dunia**

Cobalah ketik perintah berikut di Console, lalu tekan Enter:

`print("Halo dunia!")`

Selamat! Anda baru saja menjalankan kode R pertama Anda.
:::

Namun, mengetik satu per satu di Console akan melelahkan jika perintahnya banyak. Oleh karena itu, kita biasanya menulis kode dalam sebuah file *source code* (ekstensi `.R`).

### Membuat File Kode Sumber R (`.R`)

File kode sumber R (berekstensi `.R`) adalah dokumen teks yang berisi rangkaian perintah R yang dapat disimpan, diedit, dan dijalankan berulang kali. Ini adalah cara profesional dalam bekerja dengan R, karena kode kita menjadi **terdokumentasi**, **dapat direproduksi**, dan **mudah dibagikan**.

**Langkah-langkah membuat file `.R` baru:**

1. Di RStudio, pilih menu **File â†’ New File â†’ R Script** (atau tekan **Ctrl + Shift + N** di Windows/Linux, **Cmd + Shift + N** di Mac)
2. Sebuah tab baru akan muncul di panel *Script* (jendela kiri atas)
3. Ketikkan kode R Anda di dalam tab tersebut
4. Simpan file dengan memilih **File â†’ Save** (atau **Ctrl + S** / **Cmd + S**)
5. Beri nama file dengan ekstensi `.R`, misalnya `kode_R_pertama_saya.R`

**Menjalankan kode dari file `.R`:**

Untuk menjalankan kode dari file `.R` ke Console tanpa mengetik ulang:

1. Sorot (blok) baris kode yang ingin dijalankan di panel *Script*
2. Tekan kombinasi tombol **Ctrl + Enter** (Windows/Linux) atau **Cmd + Enter** (Mac)
3. Kode yang disorot akan otomatis dikirim ke *Console* dan dijalankan

Ini adalah cara kerja standar yang efisien dalam menggunakan R. Dengan cara ini, kita bisa:

- **Menyimpan pekerjaan** untuk digunakan di lain waktu
- **Menjalankan ulang** analisis dengan mudah
- **Berbagi kode** dengan rekan kerja atau asisten praktikum
- **Mendokumentasikan** setiap langkah analisis kita

::: rmdexercise
**Aktivitas Mandiri: Membuat Kode Sumber R**

1. Buatlah file R Script baru melalui menu **File â†’ New File â†’ R Script**
2. Ketikkan kode berikut di dalam file tersebut:

``` r
# File kode R pertama saya
# Dibuat pada: [isi dengan tanggal hari ini]

print("Halo dunia!")
print("Hari ini saya mulai belajar R!")

# Operasi matematika sederhana
1 + 1
2 * 3
```

3. Simpan file dengan nama `kode_R_pertama_saya.R` di dalam folder **Praktikum STP 2026**
4. Sorot baris-baris kode `print`, lalu tekan **Ctrl + Enter** (Windows/Linux) atau **Cmd + Enter** (Mac). Setelah itu, sorot baris-baris operasi matematika, lalu tekan **Ctrl + Enter** (Windows/Linux) atau **Cmd + Enter** (Mac) lagi.
5. Perhatikan jendela *Console* - Anda akan melihat hasil eksekusi kode Anda
6. Selamat! Anda baru saja membuat file kode sumber R pertama Anda yang dapat disimpan dan dijalankan kapan saja. Jangan lupa tekan **Ctrl + S** / **Cmd + S** untuk menyimpan file Anda setiap kali Anda selesai mengeditnya.

:::

------------------------------------------------------------------------

# Pengenalan Teknis R {.unnumbered}

Sebelum memulai praktikum dengan set data sesungguhnya, ada baiknya kita memahami beberapa konsep teknis dasar dalam bahasa pemrograman R. Bagian ini merangkum keterampilan-keterampilan dasar yang akan kalian temui tersebar di modul-modul praktikum.

## Pengaturan Direktori

Salah satu keterampilan penting dalam bekerja dengan R adalah mengorganisasi *file* dan data dengan baik. Sepanjang semester ini, kalian akan bekerja dengan berbagai dataset, kode R, dan hasil analisis. Pengaturan direktori yang terstruktur akan memudahkan kalian dalam mengelola semua file tersebut dan memastikan kode dapat berjalan dengan lancar.

### Struktur Direktori yang Ideal

Sebelum memulai praktikum, kalian perlu menyiapkan direktori kerja (*working directory*) yang terorganisir dengan baik. Berikut adalah struktur direktori yang **wajib** kalian gunakan sepanjang semester:

```text
Praktikum STP 2026/
â”œâ”€â”€ Praktikum STP 2026.Rproj
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ data.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ output_1.xlsx
â”‚   â””â”€â”€ ...
â”œâ”€â”€ modul_1.R
â””â”€â”€ modul_2.R
```

**Komponen-komponen penting:**

-   **`Praktikum STP 2026.Rproj`**: File RStudio Project yang mengatur *working directory* secara otomatis dan menyimpan *environment* kerja kalian.
-   **`datasets/`**: Folder khusus untuk menyimpan **semua dataset mentah** (file Excel, CSV, atau format lainnya yang kalian terima dari asisten praktikum).
-   **`output/`**: Folder khusus untuk menyimpan **hasil-hasil analisis** seperti file Excel yang sudah diolah, file CSV hasil export, atau grafik yang dihasilkan.
-   **`modul_1.R`, `modul_2.R`, ...**: File-file kode R (script) yang akan kalian buat untuk setiap modul praktikum.

Dengan struktur seperti ini, kode R kalian akan lebih **ringkas** dan **portabel**. Sebagai contoh, untuk membaca data, kalian cukup menulis:

``` r
data <- read.xlsx("datasets/data_penduduk.xlsx")
```

Tanpa perlu menulis *path* lengkap seperti `C:\Users\NamaAnda\Documents\praktikum\data_penduduk.xlsx` yang panjang, rumit, dan berbeda-beda di setiap komputer.

### Membuat dan Mengatur Direktori Praktikum

Ikuti langkah-langkah berikut untuk menyiapkan direktori praktikum kalian:

#### Langkah 1: Membuat Folder Utama

Buatlah sebuah folder di komputer kalian dengan nama **`Praktikum STP 2026`** (sesuai tahun ajaran yang sedang berjalan). Penamaan yang seragam ini **sangat penting** agar asisten praktikum dapat dengan mudah membantu kalian jika terjadi masalah atau kesalahan.

Folder ini akan menjadi **direktori kerja** (*working directory*) kalian selama satu semester penuh.

#### Langkah 2: Membuat Subfolder `datasets` dan `output`

Di dalam folder `Praktikum STP 2026`, buatlah **dua subfolder**:

1.  Subfolder **`datasets`** - untuk menyimpan semua data mentah
2.  Subfolder **`output`** - untuk menyimpan hasil analisis

**Cara membuat folder:**

-   **Di Windows**: Klik kanan di dalam folder `Praktikum STP 2026` â†’ pilih *New* â†’ *Folder* â†’ beri nama `datasets`, lalu ulangi untuk membuat folder `output`
-   **Di Mac/Linux**: Klik kanan di dalam folder `Praktikum STP 2026` â†’ pilih *New Folder* â†’ beri nama `datasets`, lalu ulangi untuk membuat folder `output`

Setiap kali kalian mendapatkan dataset baru untuk praktikum (misalnya file Excel atau CSV dari asisten), **simpanlah di dalam folder `datasets`**. Setiap kali kalian menghasilkan output analisis, **simpanlah di dalam folder `output`**.

#### Langkah 3: Mengubahnya Menjadi RStudio Project

Setelah struktur folder dasar sudah siap, langkah selanjutnya adalah mengubahnya menjadi **RStudio Project**. RStudio Project adalah fitur yang sangat berguna untuk mengelola sesi kerja R kalian.

**Keuntungan RStudio Project:**

1.  **Otomatis mengatur *working directory***: Ketika kalian membuka sebuah Project, RStudio otomatis mengatur *working directory* ke folder tersebut, sehingga kalian tidak perlu menggunakan perintah `setwd()` lagi.

::: rmdnote
Perintah `setwd()` digunakan untuk mengatur *working directory* secara manual. Misalnya, jika kita ingin mengatur *working directory* ke folder `Praktikum STP 2026` yang terletak dalam folder `Documents` pada direktori `C:/Users/NamaAnda/`, kita bisa menggunakan perintah 

```r
setwd("C:/Users/NamaAnda/Documents/Praktikum STP 2026")
```

Namun, jika kita sudah membuat direktori Anda sebagai Project, dalam praktikum ini, kita tidak perlu menggunakan perintah ini lagi.
:::

2.  **Mempertahankan status kerja**: RStudio menyimpan *environment* (variabel, data yang sudah dimuat) sehingga kalian bisa melanjutkan pekerjaan dari tempat terakhir kalian berhenti.
3.  **Memudahkan manajemen path**: Kalian cukup menulis *relative path* (misalnya `datasets/data.xlsx`) tanpa perlu mengetik *path* lengkap yang panjang dan berisiko error.
4.  **Portabilitas**: Project folder bisa dipindahkan ke komputer lain atau dibagikan ke rekan tanpa perlu mengubah kode, karena semua path bersifat relatif.

**Cara membuat RStudio Project:**

1.  Buka RStudio
2.  Pilih menu **File â†’ New Project...**
3.  Pilih **Existing Directory** (karena folder sudah dibuat)
4.  Klik **Browse...** dan cari folder **`Praktikum STP 2026`** yang sudah kalian buat
5.  Klik **Create Project**

Setelah itu, RStudio akan membuat file **`Praktikum STP 2026.Rproj`** di dalam folder kalian. File `.Rproj` ini adalah "pintu masuk" ke Project kalian.

**Setiap kali ingin bekerja**: Cukup *double-click* file **`Praktikum STP 2026.Rproj`** tersebut, dan RStudio akan terbuka dengan *working directory* yang sudah otomatis diatur ke folder praktikum kalian. Kalian siap untuk mulai bekerja!

::: rmdwarning
**Catatan Penting:** Selalu buka RStudio melalui file `.Rproj`, bukan dengan membuka RStudio terlebih dahulu lalu membuka *script*. Ini memastikan *working directory* selalu benar dan kode kalian berjalan sebagaimana mestinya.
:::

### Mengunduh Dataset Praktikum dari GitHub

Setelah struktur direktori dan Project sudah siap, langkah selanjutnya adalah **mengunduh dataset-dataset praktikum** yang akan digunakan sepanjang semester. Semua dataset praktikum disimpan di repository GitHub dan dapat diunduh secara gratis.

::: rmdnote
**Mengapa Dataset Disimpan di GitHub? {.header}**

Dataset praktikum disimpan di GitHub agar:
- Semua mahasiswa mendapatkan dataset yang **sama** dan **terbaru**
- Dataset dapat **diakses kapan saja** tanpa perlu menunggu distribusi dari asisten
- Jika ada pembaruan dataset, kalian bisa **mengunduh ulang** dengan mudah
- Dataset **tidak hilang** meskipun laptop rusak atau file terhapus
:::

#### Langkah-Langkah Mengunduh Dataset

Ikuti langkah-langkah berikut dengan seksama untuk mengunduh folder `datasets/` dari GitHub:

**1. Buka halaman GitHub repository praktikum**

Klik link berikut atau copy-paste ke browser kalian:

**[https://github.com/abdulmubdibindar/praktikum-r-stp](https://github.com/abdulmubdibindar/praktikum-r-stp)**

Kalian akan melihat halaman repository yang berisi semua file praktikum.

**2. Download seluruh repository sebagai file ZIP**

- Di halaman GitHub, cari dan klik tombol hijau **"Code"** di bagian kanan atas
- Pada menu yang muncul, pilih **"Download ZIP"**
- Simpan file ZIP di lokasi yang mudah kalian temukan (misalnya folder **Downloads** atau **Desktop**)
- Tunggu hingga proses download selesai

**3. Ekstrak file ZIP yang sudah didownload**

- Buka folder tempat kalian menyimpan file ZIP (misalnya **Downloads**)
- Klik kanan pada file **`praktikum-r-stp-main.zip`**
- Pilih **"Extract All..."** atau **"Extract Here"** (di Windows)
- Atau untuk Mac/Linux: double-click file ZIP, akan otomatis ter-ekstrak
- Setelah ekstrak selesai, akan muncul folder bernama **`praktikum-r-stp-main`**

**4. Copy folder `datasets` ke dalam Project RStudio kalian**

Ini adalah langkah paling penting! Ikuti dengan teliti:

- Buka folder **`praktikum-r-stp-main`** yang baru diekstrak
- Di dalam folder tersebut, cari folder bernama **`datasets`**
- **Klik kanan** pada folder `datasets`, lalu pilih **"Copy"** (atau tekan `Ctrl + C`)
- Buka folder **`Praktikum STP 2026`** (folder Project RStudio kalian)
- **Klik kanan** di dalam folder tersebut, lalu pilih **"Paste"** (atau tekan `Ctrl + V`)
- Folder `datasets` beserta seluruh isinya sekarang sudah tersalin ke Project kalian

**5. Verifikasi dataset sudah tersimpan dengan benar**

Untuk memastikan dataset sudah tersimpan di lokasi yang benar, buka RStudio (klik file `.Rproj` kalian), lalu jalankan kode berikut di **Console**:

```{r eval=FALSE}
# Mengecek apakah folder datasets ada di working directory
dir.exists("datasets")
```

Jika hasilnya `TRUE`, berarti folder `datasets` sudah berada di lokasi yang benar! âœ“

Selanjutnya, cek isi folder `datasets` dengan kode:

```{r eval=FALSE}
# Melihat daftar file di dalam folder datasets
list.files("datasets")
```

Kalian akan melihat daftar file-file dataset seperti `Data Praktikum 01.xlsx`, `Data Praktikum 02.xlsx`, `DataUtama_mhsUBL.csv`, dan lain-lain.

::: rmdimportant
**Struktur Folder yang Benar {.header}**

Pastikan struktur folder Project kalian sekarang terlihat seperti ini:

```text
Praktikum STP 2026/           â† Folder Project kalian
â”œâ”€â”€ Praktikum STP 2026.Rproj  â† File Project RStudio
â”œâ”€â”€ datasets/                 â† Folder datasets (HARUS ada di sini!)
â”‚   â”œâ”€â”€ Data Praktikum 01.xlsx
â”‚   â”œâ”€â”€ Data Praktikum 02.xlsx
â”‚   â”œâ”€â”€ Data Praktikum 03.xlsx
â”‚   â”œâ”€â”€ DataUtama_mhsUBL.csv
â”‚   â”œâ”€â”€ DataUtama_mhsUINRIL.csv
â”‚   â”œâ”€â”€ DataUtama_mhsUNILA.csv
â”‚   â”œâ”€â”€ DataUtama_mhsITERA.csv
â”‚   â”œâ”€â”€ data_mahasiswa.csv
â”‚   â””â”€â”€ ... (file-file dataset lainnya)
â”œâ”€â”€ output/                   â† Folder untuk hasil analisis
â””â”€â”€ ... (file .R kalian)
```

**PENTING**: Jika folder `datasets` berada di lokasi lain (misalnya di **Desktop** atau **Downloads**), kode praktikum **tidak akan bisa** membaca dataset. Pastikan folder `datasets` berada **langsung di dalam** folder `Praktikum STP 2026`.
:::

#### Alternatif: Download Dataset Satu per Satu (Tidak Disarankan)

Jika kalian hanya ingin mengunduh satu atau beberapa file dataset tertentu, bisa menggunakan cara berikut:

1. Buka [folder datasets di GitHub](https://github.com/abdulmubdibindar/praktikum-r-stp/tree/main/datasets)
2. Klik nama file dataset yang ingin diunduh (misalnya `Data Praktikum 01.xlsx`)
3. Klik tombol **"Download"** di pojok kanan atas halaman
4. Simpan file tersebut ke dalam folder **`datasets/`** di Project RStudio kalian

> **Catatan**: Cara ini lebih lambat jika kalian perlu banyak file. **Sangat disarankan** menggunakan cara download ZIP untuk mendapatkan **semua dataset sekaligus** agar tidak perlu download berulang-ulang.

#### Troubleshooting: Jika Kode Tidak Bisa Membaca Dataset

Jika kalian mengalami error seperti:

```
Error in file(file, "rt") : cannot open the connection
```

Kemungkinan penyebabnya:

- âŒ Folder `datasets` tidak berada di lokasi yang benar
- âŒ Nama folder salah ketik (misalnya `dataset` tanpa huruf 's' atau `Datasets` dengan huruf kapital)
- âŒ File Project `.Rproj` tidak dibuka (sehingga *working directory* salah)

**Solusi:**

1. Tutup RStudio
2. Buka **kembali** RStudio dengan cara double-click file **`Praktikum STP 2026.Rproj`**
3. Jalankan kembali kode `dir.exists("datasets")` - harus menghasilkan `TRUE`
4. Jika masih `FALSE`, cek kembali apakah folder `datasets` sudah benar-benar berada di dalam folder Project


## Sintaks Dasar Bahasa r

Dalam subbab ini, kita akan membahas sintaks dasar bahasa R yang akan sering digunakan dalam praktikum ini.

### Komentar

Pada dasarnya, semua yang kita tulis di *script* akan dijalankan oleh R. Akan tetapi, kita bisa memberi tahu R untuk tidak menjalankan kode yang kita tulis dengan mengubah formatnya menjadi **komentar** (*comment*). Kita bisa menuliskan komentar dengan menggunakan tanda pagar (`#`) sebelum kode yang ingin kita komentari.

``` r
# Kode ini akan menghitung 1 + 1
1 + 1 
```

::: rmdimportant
Komentar sangat berperan penting dalam kode kalian. Malahan, ini adalah kekuatan terbesar dari penggunaan R dalam Kita akan sering menggunakan komentar dalam kode kalian. Jadi, jangan ragu untuk menggunakan komentar untuk menjelaskan kode kalian.
:::

### *Assignment* (Pemberian Nilai)

Untuk menyimpan nilai ke dalam variabel/objek, kita menggunakan tanda panah kiri (`<-`). Gunakanlah selalu `<-` sebagai penanda bahwa kita sedang memasukkan nilai ke dalam objek, karena ini adalah standar baku dalam pemrograman R.

``` r
x <- 10
nama <- "Budi"
```

### *Case Sensitivity*

R membedakan huruf besar dan huruf kecil (*case sensitive*). Variabel `Data` dianggap berbeda dengan `data`.

## Paket (*Packages*)

R memiliki ribuan paket tambahan yang menyediakan fungsi-fungsi khusus.

-   **`install.packages("nama_paket")`**: Digunakan untuk mengunduh dan menginstal paket dari internet ke komputer kita. Ini cukup dilakukan satu kali saja.
-   **`library(nama_paket)`**: Digunakan untuk memuat paket yang sudah terinstal ke dalam sesi kerja kita agar isinya bisa digunakan. Ini harus dilakukan setiap kali kita membuka RStudio baru.

Paket utama yang akan sering kita gunakan adalah:

-   **`tidyverse`**: Kumpulan paket untuk pengolahan data modern.
-   **`openxlsx`**: Untuk membaca dan menulis file Excel.

::: rmdexercise
**Aktivitas Mandiri: Instalasi Paket**

Cobalah untuk menginstal paket `tidyverse` dan `openxlsx` di komputer Anda dengan mengetikkan perintah berikut di *Console*:

`install.packages(c("tidyverse", "openxlsx"))`

Tunggu hingga proses instalasi selesai. Ingat, tahap ini hanya perlu dilakukan satu kali saja.
:::

## Fungsi (*Functions*)

Fungsi adalah serangkaian instruksi yang dibungkus menjadi satu perintah untuk melakukan tugas tertentu. R memiliki banyak fungsi bawaan, dan kita juga bisa membuat fungsi sendiri.

### Menggunakan Fungsi

Untuk menggunakan fungsi, kita memanggil namanya diikuti dengan tanda kurung `()`. Di dalam tanda kurung, kita bisa memasukkan **argumen** (input).

``` r
# Contoh fungsi bawaan: mean (rata-rata)
nilai <- c(10, 20, 30)
rata_rata <- mean(nilai) # Hasil: 20
```

### Membuat Fungsi Sendiri

Kita dapat membuat fungsi kustom menggunakan perintah `function()`. Struktur dasarnya adalah:

``` r
nama_fungsi <- function(input) {
  # Proses yang dilakukan
  hasil <- input * 2
  return(hasil)
}
```

Ini akan sangat berguna ketika kita ingin melakukan perhitungan yang sama berulang kali, seperti pada perhitungan IQV di Modul 2.

## Struktur Data Dasar

### Vektor

Vektor adalah struktur data paling dasar di R yang menampung deretan nilai dengan tipe yang sama. Kita membuatnya dengan fungsi `c()` (*combine*).

``` r
angka <- c(1, 2, 3, 4, 5)
huruf <- c("a", "b", "c")
```

### Tipe Data

Saat mengolah data, kalian akan sering menemukan singkatan tipe data berikut:

-   **`dbl` (Double)**: Angka numerik (bisa desimal).
-   **`chr` (Character)**: Teks atau *string*. Ditandai dengan tanda kutip.
-   **`fct` (Factor)**: Data kategorik (bisa nominal atau ordinal). Factor menyimpan nilai sebagai angka di belakang layar namun menampilkan label teks, yang berguna untuk analisis statistik dan plot.

### Data Frame dan Tibble

Data dalam R biasanya disimpan dalam bentuk tabel yang disebut *Data Frame*. Di era modern (tidyverse), kita sering menggunakan versi yang lebih canggih disebut **Tibble**. Strukturnya mirip spreadsheet: baris mewakili observasi, kolom mewakili variabel.

## Operator Pipa (`|>`)

Dalam `tidyverse`, kita sering menggunakan operator pipa (`|>`) untuk merangkai beberapa perintah sekaligus. Bayangkan ini sebagai penyambung proses:

``` r
# Tanpa pipa
hasil <- fungsi_2(fungsi_1(data))

# Dengan pipa (lebih mudah dibaca)
data |> 
  fungsi_1() |> 
  fungsi_2()
```

Artinya: "Ambil `data`, lalu `fungsi_1`, kemudian hasilnya dimasukkan ke `fungsi_2`."

## Manajemen Data (Input/Output)

### Membaca Data

Kita sering menggunakan `read.xlsx()` dari paket `openxlsx` untuk membaca file Excel.

``` r
data <- read.xlsx("folder/nama_file.xlsx", sheet = "nama_sheet")
```

### Menyimpan Data

Setelah diolah, data bisa disimpan kembali ke Excel atau CSV.

``` r
write.xlsx(data, "folder/nama_file_baru.xlsx")
write.csv2(data, "folder/nama_file_baru.csv") # Format CSV Excel Indonesia (pemisah titik koma)
```

<!--chapter:end:index.Rmd-->

# Modul-1: Pengolahan Data Terstruktur

Setelah mempelajari modul ini Anda diharapkan dapat:

1.  menganalisis variabel dan objek dalam sebuah format data terstruktur [STP-1.3]{.capaian}
2.  mengelola data terstruktur dengan tepat menggunakan perangkat komputer [STP-1.4]{.capaian}

---

Kita akan mempelajari cara pengolahan data terstruktur atau *dataset*/set data dari hasil kuesioner kepada mahasiswa-mahasiswa Universitas Islam Negeri Raden Intan Lampung (UINRIL) dan Universitas Bandar Lampung (UBL) tentang pola perjalanan mereka.

Dalam R, pengolahan data terstruktur dipermudah dengan adanya paket `tidyverse`. Paket ini menyertakan paket-paket lain yang mempunyai kegunaan unik dalam pengolahan data terstruktur.

```{r}
library(tidyverse)
```

Seperti yang kalian lihat, paket `tidyverse` menyertakan paket-paket berikut yang mempunyai kegunaan masing-masing:

-   `dplyr`: menyediakan serangkaian fungsi inti untuk memanipulasi dan mentransformasi data secara efisien.
-   `forcats`: memudahkan pekerjaan dengan data kategorikal atau yang dalam R disebut juga 'factors'.
-   `ggplot2`: untuk membuat grafik yang ciamik.
-   `lubridate`: mempermudah pekerjaan terkait format tanggal
-   `purrr`: meningkatkan kemampuan pemrograman fungsi dan vektor
-   `readr`: untuk membaca data tabular seperti `.csv`
-   `stringr`: menyederhanakan operasi teks/*string*
-   `tibble`: versi modern dari *data.frame* yang lebih rapi dan mudah digunakan.
-   `tidyr`: untuk merapikan data dengan mengubah format atau struktur tata letaknya.

Selain paket `tidyverse`, kita juga akan menggunakan paket `openxlsx` untuk mengoperasikan *file* Excel.

```{r}
library(openxlsx)
```

## Mengimpor set data *(dataset)* dari Excel

Untuk membuat set data di lingkungan kerja R kita, gunakan fungsi `read.xlsx()` seperti berikut. Fungsi `read.xlsx()` mempunyai atribut utama berupa *file path* lokasi file yang ditempatkan di dalam tanda kurung.

::: rmdwarning

âš ï¸ **Penting**

Pastikan file Excel yang akan diimpor sudah tertutup, karena mengimpor file yang sedang terbuka akan menghasilkan *error*.
:::


```{r}
# Memuat dataset dari file Excel "Data Gabungan.xlsx" yang terletak di folder yang sama dengan file R Markdown ini.
data <- read.xlsx("datasets/Data Praktikum 01.xlsx")

# Menampilkan 6 baris pertama dataset
head(data)
```

Fungsi tersebut akan mengimpor seluruh isi dari file Excel `Data Gabungan.xlsx` pada *sheet* pertama saja.

Apabila kita ingin mengimpor set data dari *sheet* lainnya, kita harus menyertakan detil nama sheet yang kita ingin impor pada atribut `sheet`.

*Dataset* yang kita impor akan menjadi objek dengan jenis *tibble*.

```{r}
# Menyimpan file sebagai variabel tersendiri sehingga lebih fleksibel
file_dibaca <- "datasets/Data Praktikum 01.xlsx" # nama variabel bukan 'file' saja karena sudah ada fungsi R tersendiri dengan nama tersebut

# Mengimpor data dari file_dibaca dan menyimpannya sebagai variabel
data_ubl <- read.xlsx(file_dibaca, sheet = "DataUtama_mhsUBL")

# Melihat data tersebut
head(data_ubl)
```

Kita juga dapat melihat *dataset* kita secara lengkap dengan perintah `View()`

```{r, eval=FALSE}
# Melihat set data UINRIL
View(data)

# Melihat set data UBL
View(data_ubl)
```

## Analisis data terstruktur pada set data

Kita sudah mempelajari bahwa data terstruktur terdiri atas **objek**, **variabel**, dan **nilai**. Satu objek diwakili oleh satu baris, variabel oleh kolom, dan nilai berada di dalam sel-sel yang merupakan perpotongan kolom dan baris.

> âš ï¸ **Penting**
>
> Di modul ini kita menggunakan istilah "variabel" untuk menyebut dua hal yang berbeda. Makna pertama mengacu pada penyimpan nilai di R, sementara yang kedua adalah elemen data terstruktur yang menjadi kolom-kolom.
>
> Dalam modul ini kita akan menggunakan istilah yang sama untuk kedua makna, jadi pahami konteks kalimatnya terlebih dahulu ketika menemukan kata ini.

Untuk mengetahui ringkasan struktur data, kita dapat menggunakan fungsi `glimpse()` yang membutuhkan set data yang kita simpan sebagai argumen.

```{r}
# ringkasan struktur data UIN RIL
glimpse(data)
```

Hasil dari fungsi `glimpse()` tersebut menunjukkan jumlah baris, jumlah kolom, dan kolom-kolom yang ada dalam set data kita beserta rinciannya. Set data kita memiliki 400 baris yang ditunjukkan oleh **`Rows`** dan 25 kolom yang ditunjukkan oleh **`Columns`** . Ini artinya, set data kita memiliki 400 objek dan 25 variabel.

Rincian nama-nama variabel ditunjukkan pada baris keluaran yang diawali oleh simbol **`\$`**. Singkatan-singkatan di dalam kurung sudut `<>` bermakna jenis nilai dari variabel tersebut. [Laman ini](https://cran.r-project.org/web/packages/tibble/vignettes/types.html) memberikan penjelasan makna setiap singkatan tersebut.

Terlihat dalam data kita bahwa hanya ada dua tipe nilai variabel: `dbl` dan `chr` yang berarti *double* (bilangan desimal) dan *character* (huruf/*string*).

::: {.rmdexercise}
**Aktivitas Mandiri 1: Menganalisis Struktur Data [STP-1.3]**

Jalankan `glimpse(data)` untuk dataset UIN RIL dan jawab:

1. Berapa jumlah objek (baris) dalam dataset ini?
2. Berapa jumlah variabel (kolom)?
3. Sebutkan 3 variabel dengan tipe `dbl` dan 3 variabel dengan tipe `chr`
4. Mengapa variabel `Jenis.Kelamin` bertipe `chr` bukan `dbl`? Jelaskan!
:::

## Mengolah set data

Dalam bagian ini kita akan mengolah set data kita yang bertujuan untuk memenuhi kebutuhan pengolahan data kita. Sebelum melakukan pengolahan, maka kita perlu menjawab pertanyaan terlebih dahulu "apa yang kita butuhkan untuk pengolahan data kita?"

Dalam praktikum ini kita sudah mengetahui bahwa terdapat dua jenis set data hasil kuesioner, yakni set data mahasiswa Universitas Islam Negeri Raden Intan Lampung (UINRIL) dan juga Universitas Bandar Lampung (UBL). Kedua jenis set data tersebut disimpan dalam variabel yang berbeda. Kita butuh untuk *menggabungkan kedua set data* tersebut menjadi satu set data yang mencakup kedua kampus agar nanti kita bisa melakukan analisis dengan lebih leluasa.

Pengolahan set data seperti ini punya istilah yang keren: ***data wrangling*** (bisa dibaca "data rengling")

### Merancang Algoritma (Urutan kerja)

Karena R adalah program yang mayoritasnya *character user interface* (CUI) alih-alih *graphical user interface*, maka pekerjaan kita tidak bisa seleluasa GUI yang dapat kita bolak-balik urutannya. Kita sebaiknya memiliki "rencana kerja" yang jelas, yang dalam bahasa pemrograman disebut **algoritma**.

Algoritma yang akan kita lakukan dalam praktikum ini adalah sebagai berikut:

1.  Mengidentifikasi nama-nama kolom di set data UIN RIL
2.  Mengidentifikasi nama-nama kolom di set data UBL
3.  Menentukan kolom-kolom yang akan diambil di set data baru
4.  Menyeleksi kolom-kolom yang akan dipakai di set data UIN RIL dan UBL,
5.  Mengubah nama kolom-kolom di kedua set data menjadi nama-nama yang sudah ditentukan di langkah-3.
6.  Menyatukan kedua set data.

> ğŸ’¡ **Tip**
>
> Sebisa mungkin rancang setiap langkah pada urutan kerja kita dengan rinci agar kita dapat menerjemahkan langkah-langkah tersebut dengan lebih mudah ke baris kode.

### Mengidentifikasi Nama-nama Kolom

Untuk mengidentifikasi nama-nama kolom kita dapat menggunakan fungsi `colnames()` yang mengambil argumen nama set data.

```{r}
# data UIN RIL
colnames(data)
```

```{r}
# data UIN RIL
colnames(data_ubl)
```

Kita dapat mengetahui jumlah kolom setiap set data secara langsung dengan fungsi `length()`.

```{r}
length(colnames(data)) # jumlah kolom set data UIN RIL
length(colnames(data_ubl)) # jumlah kolom set data UBL
```

> âš ï¸ Penting!
>
> Fungsi `length()` pada dasarnya adalah fungsi penghitung jumlah elemen dalam suatu vektor atau jenis data lain yang berupa daftar.

```{r}
# Mendefinisikan suatu vektor
suatu_vektor <- c(1, 2, 3, 4, 5)

# Mengukur panjangnya
length(suatu_vektor)
```

Dari kedua fungsi tersebut, kita dapat mengetahui bahwa terdapat perbedaan jumlah kolom dan juga perbedaan penamaan:

-   `kepemilikan.sepedan` di data UIN vs `kepemilikan.sepeda` di data UBL.

-   `biaya.dalam.ribu2` di data UIN vs `biaya.dalam.seminggu` di data UBL.

Perbedaan-perbedaan inilah yang membuat kita tidak bisa langsung menggabungkan data. Kita harus menyeragamkannya terlebih dahulu,

### Menentukan Kolom-kolom yang Akan Diambil di Set Data Baru

Setelah mengidentifikasi nama-nama variabel dan jumlahnya, kita putuskan untuk mengambil variabel-variabel berikut: (1) `Nomor.urut`, (2) `Jenis.Kelamin`, (3) `Umur`, (4) `Fakultas`, (5) `Prodi`, (6) `Tingkat.Semester`, (7) `Uang.Saku`, (8) `kepemilikan.mobil`, (9) `kepemilikan.motor`, (10) `kepemilikan.sepeda`, (11) `kendaraan.utama`, (12) `jenis.tempat.tinggal`, (13) `jarak`, (14) `biaya.dalam.seminggu`, (15) `Jumlah.perjalanan.Senin`, (16) `Jumlah.perjalanan.Selasa`, (17) `Jumlah.perjalanan.Rabu`, (18) `Jumlah.perjalanan.Kamis`, (19) `Jumlah.perjalanan.Jumat`, (20) `Jumlah.perjalanan.Sabtu`, (21) `Jumlah.perjalanan.Ahad`.

Kita akan menyimpan nama-nama kolom yang sudah kita tentukan tersebut menjadi sebuah vektor.

```{r}
# Membuat vektor berisi nama-nama kolom final yang kita inginkan
kolom_final <- c(
  "Nomor.urut", "Jenis.Kelamin", "Umur", "Fakultas", "Prodi", 
  "Tingkat.Semester", "Uang.Saku",
  "kepemilikan.mobil", 
  "kepemilikan.motor", "kepemilikan.sepeda", "kendaraan.utama", 
  "jenis.tempat.tinggal", "jarak", "biaya.dalam.sepekan", 
  "Jumlah.perjalanan.Senin", "Jumlah.perjalanan.Selasa", 
  "Jumlah.perjalanan.Rabu", "Jumlah.perjalanan.Kamis", 
  "Jumlah.perjalanan.Jumat", "Jumlah.perjalanan.Sabtu", 
  "Jumlah.perjalanan.Ahad"
)
```

### Menyeleksi Kolom-kolom Yang Akan Dipakai

Kita akan menggunakan fungsi `select()` dari `dplyr` (bagian dari `tidyverse`) untuk memilih hanya kolom-kolom yang relevan dari masing-masing set data. Perhatikan baik-baik, kita harus menggunakan **nama kolom asli** saat menyeleksi.

```{r}
# 4. Menyeleksi kolom dari data UIN RIL
data_uin_selected <- select(data,
  Nomor.urut, Jenis.Kelamin, Umur, Fakultas, Prodi, Tingkat.Semester,
  Uang.Saku, 
  kepemilikan.mobil, kepemilikan.motor, 
  kepemilikan.sepedan, # Ingat, nama aslinya pakai 'n'
  kendaraan.utama, jenis.tempat.tinggal, 
  `jarak.(km)`, # Gunakan backtick (`) karena ada karakter spesial, yakni tanda kurung.
  `biaya.dalam.ribu2`,
  Jumlah.Perjalanan.Senin, Jumlah.Perjalanan.Selasa, Jumlah.Perjalanan.Rabu,
  Jumlah.Perjalanan.Kamis, Jumlah.Perjalanan.Jumat, Jumlah.Perjalanan.Sabtu,
  Jumlah.Perjalanan.Ahad
)
```

```{r}
# 5. Menyeleksi kolom dari data UBL
data_ubl_selected <- select(data_ubl,
  Nomor.urut, Jenis.Kelamin, Umur, Fakultas, Prodi, Tingkat.Semester,
  Uang.Saku,
  kepemilikan.mobil, kepemilikan.motor, 
  kepemilikan.sepeda, # Di sini namanya sudah benar
  kendaraan.utama, jenis.tempat.tinggal,
  `jarak.(km)`,
  biaya.dalam.seminggu,
  Jumlah.perjalanan.Senin, Jumlah.Perjalanan.Selasa, Jumlah.Perjalanan.Rabu,
  Jumlah.Perjalanan.Kamis, Jumlah.Perjalanan.Jumat, Jumlah.Perjalanan.Sabtu,
  Jumlah.Perjalanan.Ahad
)
```

Sekarang kita punya dua *data frame* baru (`data_uin_selected` dan `data_ubl_selected`) yang isinya hanya kolom-kolom yang kita butuhkan.

### Mengubah Nama Kolom Menjadi Nama Standar

Ini adalah langkah kuncinya. Kita cukup menimpa nama-nama kolom di kedua *data frame* yang sudah kita seleksi tadi dengan nama-nama kolom dari vektor `kolom_final` yang kita buat di 3.3.3.

```{r}
# Mengganti nama kolom di kedua data frame
colnames(data_uin_selected) <- kolom_final
colnames(data_ubl_selected) <- kolom_final
```

Untuk membuktikan bahwa namanya sudah berubah, kita bisa cek lagi.

```{r}
# Cek nama kolom setelah diubah
colnames(data_uin_selected)
print("============================================================")
colnames(data_ubl_selected)
```

Hasil dari kedua perintah di atas seharusnya adalah daftar nama yang identik.

::: {.rmdexercise}
**Aktivitas Mandiri 2: Seleksi dan Rename Kolom [STP-1.4]**

Gunakan dataset `data_ubl` yang sudah diimpor:

1. Pilih hanya kolom: `Nomor.urut`, `Jenis.Kelamin`, `Umur`, `Fakultas`, `Prodi`
2. Rename kolom `Jenis.Kelamin` menjadi `JK` (gunakan fungsi `rename()`)
3. Simpan hasilnya ke variabel `data_ubl_subset`
4. Gunakan `glimpse(data_ubl_subset)` untuk memverifikasi hanya ada 5 kolom dan nama `JK` sudah benar
:::

### Menyatukan Kedua Set Data

Ini adalah langkah terakhir kita. Karena kedua set data kini memiliki struktur kolom yang sama persis, kita bisa menyatukannya menjadi satu *data frame* besar dengan fungsi `bind_rows()`.

```{r, eval = FALSE}
# Menggabungkan kedua data frame menjadi satu
data_gabungan <- bind_rows(data_uin_selected, data_ubl_selected)
```

Hasil dari penggabungan tersebut menyebabkan *error* pada kolom `biaya.dalam.sepekan` . Ini disebabkan oleh biaya.dalam.sepekan dalam set data UINRIL (`data`) berbeda jenisnya dengan set data UBL (`data_ubl`). Begitu pula `Jumlah.perjalanan.Senin`

```{r}
# Mengecek tipe data dalam set data UINRIL
glimpse(data_uin_selected)

print("=================================================================================")

# Mengecek tipe data dalam set data UBL
glimpse(data_ubl_selected)
```

Ini adalah kasus yang tepat untuk menggambarkan bahwa dalam data terstruktur, jenis nilai harus sama persis. Untuk kesederhanaan praktikum, kita akan melewati dulu variabel `biaya.dalam.sepekan` dan `Jumlah.perjalanan.Senin` tersebut.

### Memperbaiki Set Data yang Akan Digabungkan

Kita akan menghapus `biaya.dalam.sepekan` dari kedua set data kita. Untuk menghapus suatu kolom, kita dapat menggunakan fungsi `select()` juga, akan tetapi kita tambahkan tanda negatif (`-`) di depan nama variabelnya.

```{r}
# 'Menimpa' data_uin_selected dengan data_uin_selected yang variabel biaya.dalam.sepekan sudah dihapus
data_uin_selected <- select(data_uin_selected, 
                            -`biaya.dalam.sepekan`, -`Jumlah.perjalanan.Senin`)

# Melihat hasilnya
glimpse(data_uin_selected)
colnames(data_uin_selected)
```

```{r}
# 'Menimpa' data_ubl_selected dengan data_ubl_selected yang variabel biaya.dalam.sepekan sudah dihapus
data_ubl_selected <- select(data_ubl_selected, 
                            -`biaya.dalam.sepekan`, -`Jumlah.perjalanan.Senin`)

# Melihat hasilnya
glimpse(data_ubl_selected)
```

### Menyatukan Kedua Set Data Setelah Diperbaiki

Kita akan coba menggabungkan kedua set data tadi.

```{r}
# Menggabungkan kedua data frame menjadi satu
data_gabungan <- bind_rows(data_uin_selected, data_ubl_selected)
```

Selesai! ğŸ¥³ Mari kita lihat hasil akhir dari kerja keras kita dengan `glimpse()`. Hasil akan menunjukkan bahwa kita mempunyai 779 objek yang merupakan gabungan responden mahasiswa UIN RIL dan UBL.

```{r}
# Tampilkan struktur data gabungan yang sudah rapi
glimpse(data_gabungan)
```

### Mengekspor Set Data Hasil Pengolahan ke Fail *(File)* Terpisah

Dalam dunia data sains dikenal jenis fail `.csv` yang merupakan singkatan dari *"comma-separated values."* Fail ini menyimpan nilai-nilai sehingga dapat dibaca sebagai tabel seperti contoh berikut:

```         
Nama; umur
Ifna; 20
Salbina; 21
```

Hasilnya adalah:

| Nama    | umur |
| ------- | ---- |
| Ifna    | 20   |
| Salbina | 21   |

Kita dapat mengekspor set data hasil pengolahan menjadi fail dengan format data terstruktur seperti `.csv` atau Excel (`.xls`, `.xlsx`) dengan fungsi `write.csv2()` atau `write.xlsx()`.

Format perintah fungsi-fungsi ini adalah:

``` r
write.csv2(variabel_dataset, "nama_file_ekspor.csv")

write.xlsx(variabel_dataset, "nama_file_ekspor.xlsx")
```

Seluruh fail yang diekspor lokasi direktorinya **sama seperti lokasi file .Rproj** kita.

#### Mengekspor set data ke fail `.csv`

Terdapat dua jenis fungsi untuk mengekspor set data ke fail `.csv`: `write.csv()` dan `write.csv2()`. Perbedaan antara keduanya adalah **pemisah nilainya**.

Fungsi `write.csv()` digunakan untuk set data yang menggunakan **tanda titik** sebagai pemisah desimal, sehingga pemisahnya adalah **tanda koma (,)**. Ini adalah format yang biasa dipakai di Amerika Utara.

Sementara itu, `write.csv2()` menggunakan pemisah **titik-koma (;)** *(semicolon)*. Ini digunakan untuk set data yang pemisah desimalnya adalah **tanda koma**.

```{r}
# Mengekspor data_gabungan dalam format csv
write.csv2(data_gabungan, "Data UINRIL & UBL.csv")
```

#### Mengekspor set data ke fail `.xlsx`

Sama seperti write.csv2(), fungsi write.xlsx() juga mengikuti format yang sama.

```{r}
write.xlsx(data_gabungan, "Data UINRIL & UBL.xlsx")
```

::: {.rmdexercise}
**Aktivitas Mandiri 3: Menggabungkan Data ITERA dan UNILA [STP-1.3, STP-1.4]**

Dari file `Data Praktikum 01.xlsx`, terdapat dua sheet tambahan:
- `DataUtama_mhsITERA`
- `DataUtama_mhsUNILA`

**Langkah-langkah:**

1. **Impor data dari kedua sheet** menggunakan `read.xlsx()`
   - Simpan sheet ITERA ke variabel `data_itera`
   - Simpan sheet UNILA ke variabel `data_unila`

2. **Identifikasi kolom yang bisa digabungkan**
   - Gunakan `colnames()` untuk melihat nama kolom di kedua dataset
   - Gunakan `glimpse()` untuk melihat tipe data setiap kolom
   - Tentukan kolom mana yang tipenya sama dan bisa digabungkan

3. **Seleksi kolom yang sesuai** menggunakan `select()`
   - Pilih hanya kolom yang ada di kedua dataset dan tipenya sama
   - Ingat menggunakan backtick (`) untuk kolom dengan karakter khusus

4. **Seragamkan nama kolom**
   - Buat vektor `kolom_final` berisi nama standar untuk semua kolom
   - Gunakan `colnames(data_itera_selected) <- kolom_final`
   - Lakukan hal sama untuk `data_unila_selected`

5. **Gabungkan dengan `bind_rows()`**
   - Jika ada error tipe data, periksa dengan `glimpse()` dan perbaiki
   - Simpan hasil gabungan ke variabel `data_gabungan_iteraunila`

6. **Simpan ke file**
   - Ekspor hasil gabungan dengan `write.xlsx()`
   - Nama file: `Prak1_[NIM1]_[NIM2].xlsx`

**Analisis [STP-1.3]:**

7. Berapa jumlah **variabel** (kolom) dalam data gabungan?
8. Berapa jumlah **objek** (baris) dalam data gabungan?
9. Tampilkan bukti dengan `glimpse(data_gabungan_iteraunila)` dan sertakan screenshot

**Refleksi:**
- Apa tantangan terbesar yang Anda hadapi dalam menggabungkan data?
- Mengapa penting untuk mengecek tipe data sebelum menggabungkan dataset?
:::

------------------------------------------------------------------------




<!--chapter:end:01-data-terstruktur.Rmd-->

# Modul-2: Analisis Statistika Deskriptif

Setelah mempelajari modul ini, Anda diharapkan dapat mengoperasikan perhitungan persentase/proporsi, rasio, laju, ukuran pemusatan, dan ukuran penyebaran untuk suatu data kuantitatif dengan menggunakan perangkat lunak [STP-2.4]{.capaian}

---

Dalam praktikum ini kita akan melanjutkan analisis data terstruktur kita dengan analisis statistika deskriptif untuk variabel-variabel **kategoris** dan **numerik**. Kedua jenis variabel ini berkaitan juga dengan tingkat pengukurannya yang terdiri atas **nominal**, **ordinal**, dan **interval/rasio (metrik).**

Analisis statistik deskriptif yang akan kita lakukan mencakup **persentase/proporsi**, **rata-rata *(mean)***, **median**, dan **standar deviasi**. Ada beberapa ukuran statistik yang tidak kita pelajari di kelas tetapi dikenalkan pada praktikum ini, seperti **persentil** dan **kuartil**. Perhitungan IQV akan dilakukan dengan sekaligus mengenalkan mekanisme `function` di R.

## Persiapan

Seperti biasa, kita perlu memuat *library* andalan kita dalam mengolah data, `tidyverse`, dan juga untuk membaca file Excel, `openxlsx`.

```{r}
# Memuat library yang diperlukan
library(tidyverse)
library(openxlsx)
```

## Mengimpor Dataset

Kita menggunakan data mahasiswa UBL yang sudah lengkap karena sudah diolah kembali.

```{r}
# Mengeset variabel tersendiri untuk nama file nama sheet
file.dibaca <- "datasets/Data Praktikum 02.xlsx"
sheet.ubl <- "DataUtama_mhsUBL"

# Mengimpor file menjadi dataset memanfaatkan variabel nama file dan nama sheet yang kita buat tadi
data.ubl <- read.xlsx(file.dibaca, sheet = sheet.ubl)
```

Sebelumnya kita sudah mengenal `glimpse()` yang berasal dari *library* `dplyr`, sekarang kita akan mengenal perintah untuk menampilkan ringkasan dataset bawaan R (disebut juga *'base R'*) bernama `summary()`.

```{r}
# Melihat ringkasan dataset (cara lain)
summary(data.ubl)
```

## Merapikan Dataset *(Data Wrangling)*

Sering dikatakan bahwa 50% pekerjaan ilmuwan data adalah **merapikan dataset**. Ini diistilahkan dengan *wrangling*. *Data wrangling* mencakup penggantian nama variabel, pengecekan nilai yang hilang *(missing values)*, mengubah/memanipulasi variabel, dan masih banyak lagi.

#### Mengganti Nama Variabel

Pada praktikum sebelumnya kita mengubah nama kolom/variabel dalam *dataset* secara **keseluruhan**, yakni dengan menimpakan vektor nama-nama baru variabel kita dengan fungsi `colnames()` .

Kita pastinya tidak akan selalu mengubah semua kolom secara sekaligus, karena itu kita harus belajar bagaimana cara mengganti nama beberapa kolom saja, yakni dengan perintah `rename()`.

Perintah `rename()` memiliki sintaks seperti berikut

```r
rename(dataset_kita, nama_kolom_baru = nama_kolom_lama) 
```

```{r}
# Membaca ulang dataset supaya menjadi kondisi semula
data.ubl <- read.xlsx(file.dibaca, sheet = sheet.ubl)
colnames(data.ubl)

# Mengganti nama variabel-variabel
data.ubl <- rename(data.ubl, biaya.dalam.sepekan = biaya.dalam.seminggu)
data.ubl <- rename(data.ubl, Jumlah.Perjalanan.Senin = Jumlah.perjalanan.Senin)
data.ubl <- rename(data.ubl, jarak = `jarak.(km)`)  # tanda backtick (`) digunakan di antara "jarak.(km)" 
                                                    # karena ada tanda kurung yang dianggap oleh R mempunyai fungsi khusus
```

::: {.rmdnote}
**Pengenalan Teknik Pengolahan dalam R: *Pipe Operator* (`|>`)**

Dalam pengolahan data dengan `tidyverse` penting untuk kita kuasai penggunaan operator yang satu ini. Perhatikan dua cara berikut untuk mengganti nama variabel-variabel kita.

```{r}
# CARA-1: CARA KONVENSIONAL

# Membaca ulang dataset supaya menjadi kondisi semula
data.ubl <- read.xlsx(file.dibaca, sheet = sheet.ubl)
colnames(data.ubl)

# Mengganti nama variabel-variabel
data.ubl <- rename(data.ubl, biaya.dalam.sepekan = biaya.dalam.seminggu)
data.ubl <- rename(data.ubl, Jumlah.Perjalanan.Senin = Jumlah.perjalanan.Senin)
data.ubl <- rename(data.ubl, jarak = `jarak.(km)`)
```

```{r}
# CARA-2: MENGGUNAKAN PIPE OPERATOR

# Membaca ulang dataset supaya menjadi kondisi semula
data.ubl <- read.xlsx(file.dibaca, sheet = sheet.ubl)

# Mengganti nama variabel-variabel
data.ubl <- data.ubl |> 
  rename(biaya.dalam.sepekan = biaya.dalam.seminggu) |>
  # setiap baris yang masih ada proses selanjutnya harus diisi dengan pipe operator
  rename(Jumlah.Perjalanan.Senin = Jumlah.perjalanan.Senin) |> 
  rename(jarak = `jarak.(km)`)
```

Dalam cara 1, kita harus menulis `data.ubl` berkali-kali untuk setiap perintah. Ini mungkin tidak akan terasa jika jumlah kolom yang kita miliki sedikit. Tetapi, akan lain ceritanya jika jumlahnya banyak. Selain itu, data kita tidak bisa secara intuitif seperti biasanya kita membaca suatu teks dari kiri ke kanan.

Operator pipa (`|>`) memungkinkan hal tersebut. Selain kita tidak perlu menuliskan dataset kita berkali-kali, kita dengan lebih mudah memahami baris-baris kode kita tersebut sebagai proses dari atas ke bawah, dari kiri ke kanan, seperti pipa.

Berikut adalah penjelasan cara-2:

-   `data.ubl |>`: perintah "Ambil dataset `data.ubl`."

-   Kirimkan dataset itu ke fungsi berikutnya (`rename`).

-   Hasil dari fungsi `rename` pertama dikirimkan lagi ke fungsi `rename` kedua, dan seterusnya.

> âš ï¸ **Penting**
>
> Pipe operator dapat dimasukkan dengan kombinasi tombol `Ctrl` + `Shift` + `M` di *keyboard*.

:::

::: {.rmdexercise}
**Aktivitas Mandiri 1: Menguasai Pipe Operator [STP-2.4]**

Dengan satu blok kode menggunakan pipe operator `|>`:
1. Baca dataset UBL dari file dan sheet yang sudah ditentukan
2. Ubah nama variabel `biaya.dalam.seminggu` menjadi `biaya.dalam.sepekan`
3. Ubah nama variabel `Jumlah.perjalanan.Senin` menjadi `Jumlah.Perjalanan.Senin`
4. Buang baris yang mengandung missing values dengan fungsi `drop_na()`
5. Simpan hasilnya ke variabel `data_ubl_bersih`
6. Verifikasi dengan `glimpse(data_ubl_bersih)` - pastikan tidak ada NA
:::

#### Mengecek *Missing Values*

Pengecekan *missing values* dilakukan dengan perintah `is.na()` yang menghasilkan tabel berisi nilai *boolean* `FALSE` dan `TRUE` yang berarti 'tidak kosong' dan 'kosong' secara berturut-turut.

`colSums()` menjumlahkan nilai-nilai `TRUE` pada setiap kolom, menandakan berapa jumlah objek yang kosong nilainya.

```{r}
checkMV_ubl <- is.na(data.ubl)

head(checkMV_ubl)

colSums(checkMV_ubl)
```

#### Menghapus *Missing Values*

Penghapusan *missing values* juga dapat digunakan dengan *pipe operator.* Adapun perintah yang dapat kita gunakan adalah `drop_na()` dari paket `tidyr`.

```{r}
# Menghapus observasi yang memiliki Missing Values
data.ubl <- data.ubl |>
  drop_na()

# Mengecek kembali Missing Values
checkMV_ubl <- is.na(data.ubl)
colSums(checkMV_ubl)
```

#### Menyesuaikan Variabel Nominal dan Ordinal dengan `factor()`

Apabila kita mengimpor dataset dengan variabel nonangka, bentuknya akan terbaca sebagai *character* (`chr`). Perintah `factor()` dari paket `forcats` berfungsi untuk mendefinisikan nilai-nilai yang ada dalam variabel kategoris tersebut sehingga kita mendefinisikan urutannya dan menetapkannya sebagai variabel ordinal.

```{r}
# Mengidentifikasi variabel-variabel yang bisa diubah menjadi factor
glimpse(data.ubl)
```

Contoh pertama kita adalah variabel yang paling mudah: `Jenis.Kelamin`.

```{r}
# Mengubah variabel Jenis.Kelamin dari chr menjadi factor (fct)
jk <- c("Laki-laki", "Perempuan") # Membuat vektor rincian nilai nominal

# Mengubah jenis variabel "Jenis.Kelamin" dari chr ke fct dengan 'mutate()'
data.ubl <- data.ubl |> 
  mutate(Jenis.Kelamin = factor(Jenis.Kelamin,jk))

# Mengecek hasil
glimpse(data.ubl)
```

Ternyata, hasil pendefinisian `factor` ke dalam data kita mengandung `NA` yang berarti data kosong atau *missing value*. Hal tersebut terjadi karena kita mendefinisikan vektor `jk` berisi `c("Laki-laki", "Perempuan")`.

Sementara itu, jika kita cermat, sebelumnya nilai jenis kelamin ditulis dengan `"Laki-Laki"` . Maka, kita harus memperbaiki vektor kita yang berisi nilai-nilai yang sesuai dengan dataset terlebih dahulu.

```{r}
# Mengulangi pembacaan file sekaligus merapikan nama variabel-variabelnya serta menghilangkan Missing Values menggunakan Pipe operator
data.ubl <- read.xlsx(file.dibaca, sheet = sheet.ubl) |> 
  rename(biaya.dalam.sepekan = biaya.dalam.seminggu) |>
  rename(Jumlah.Perjalanan.Senin = Jumlah.perjalanan.Senin) |> 
  rename(jarak = `jarak.(km)`) |> 
  drop_na()

# Memperbaiki vektor nilai nominal sesuai dengan yang ada di data dengan mengganti penulisan "Laki-laki" menjadi "Laki-Laki"
jk <- c("Laki-Laki", "Perempuan")

# Mengubah lagi jenis variabel "Jenis.Kelamin" dari chr ke fct dengan 'mutate()
data.ubl <- data.ubl |> 
  mutate(Jenis.Kelamin = factor(Jenis.Kelamin,jk))

# Mengecek hasil
glimpse(data.ubl)
```

Kita sudah berhasil menjadikan variabel `Jenis.Kelamin` sebagai factor. Selanjutnya, kita akan mengubah variabel-variabel kategoris lain menjadi factor juga. Variabel-variabel tersebut di antaranya adalah `Prodi`, `Tingkat.Semester`, `Uang.Saku`, dan `jenis.tempat.tinggal`.

Sekarang kita akan mengecek nilai variabel-variabel kategoris tersebut dengan dua cara berikut:

```{r}
# Mengecek rincian nilai-nilai variabel lain secara bersamaan 
table(data.ubl$Fakultas) # cara 1
data.ubl |>  # cara 2
  count(Prodi)
data.ubl |> 
  count(Tingkat.Semester)
data.ubl |> 
  count(Uang.Saku)
table(data.ubl$jenis.tempat.tinggal)
```

Kemudian kita buat vektor-vektor yang menyimpan nilai-nilai yang mungkinnya.

Perhatikan bahwa untuk **variabel ordinal** kita harus menuliskan vektor nilainya dengan urutan yang sesuai dengan tingkatannya.

```{r}
# Membuat vektor nilai-nilai kategoris (untuk factor) berdasarkan nilai-nilai dari tampilan rincian
fakultas <- c("Fakultas Ekonomi dan Bisnis", "Fakultas Hukum",
              "Fakultas Ilmu Komputer", "Fakultas Ilmu Sosial dan Politik",
              "Fakultas Keguruan dan Ilmu Pendidikan", "Fakultas Teknik")
# nilai-nilai dalam vektor dapat di-Enter setelah tanda koma agar script lebih rapi dan enak dibaca

prodi <- c("Administrasi Bisnis", "Administrasi Publik",
           "Akuntansi","Arsitektur","Ilmu Hukum","Ilmu Komunikasi",
           "Informatika","Manajemen",
           "Pendidikan Bahasa Inggris", "Sistem Informasi")

# Variabel ordinal harus ditulis sesuai dengan urutan yang benar
tingkat <- c("1 (Semester 1 â€“ Semester 2)",
             "2 (Semester 3 â€“ Semester 4)",
             "3 (Semester 5 - Semester 6)",
             "4 (Semester 7 - Semester 8)")

uang_saku <- c("< 1 jt", "1 jt â€“ 2 jt", "2,1 jt â€“ 3 jt",
               "3,1 jt â€“ 4 jt", "> 4 jt")
```

Sekarang kita sudah bisa mengubah nilai-nilai di variabel kategoris tersebut dari *character* menjadi *factor*. Variabel ordinal menggunakan atribut `ordered` yang bernilai `TRUE`, artinya urutan dipentingkan dalam `levels`.

```{r}
# Mengubah variabel-variabel tersebut menjadi factor
data.ubl <- data.ubl |> 
  mutate(Jenis.Kelamin = factor(Jenis.Kelamin, levels = jk),
         Fakultas = factor(Fakultas, levels = fakultas),
         Prodi = factor(Prodi, levels = prodi),
         # jangan lupa atribut 'ordered = TRUE' untuk var. ordinal
         Tingkat.Semester = factor(Tingkat.Semester, 
                                   levels = tingkat,
                                   ordered = TRUE), 
         Uang.Saku = factor(Uang.Saku, levels = uang_saku, ordered = TRUE))

# Mengecek hasil
glimpse(data.ubl)
```

Sekarang, tipe data untuk variabel-variabel kategoris kita tadi sudah menampilkan `<fct>` yang berarti "factor". Variabel ordinal diidentifikasi dengan tipe `<ord>`.

Kita dapat mengecek urutan factor kita dengan perintah `levels()` berikut.

```{r}
# Mengecek hasil dengan mengidentifikasi level factor untuk data kategoris-ordinal
levels(data.ubl$Tingkat.Semester)
levels(data.ubl$Uang.Saku)
```

::: {.rmdexercise}
**Aktivitas Mandiri 2: Membuat Factor untuk Variabel Kategoris [STP-2.4]**

Untuk dataset UBL yang sudah dibersihkan:
1. Buat vektor `tempat_tinggal` dengan nilai-nilai jenis tempat tinggal yang ada di data
   (Gunakan `table(data.ubl$jenis.tempat.tinggal)` untuk melihat nilai-nilainya)
2. Gunakan `mutate()` untuk mengubah `jenis.tempat.tinggal` menjadi factor
3. Verifikasi dengan `glimpse()` - tipe harus `<fct>`
4. Cek level dengan `levels(data.ubl$jenis.tempat.tinggal)`
:::

## Analisis Statistika Deskriptif

Kita akan menggunakan paket `gtsummary` dan `flextable` untuk melakukan analisis statistik deskriptif dengan ringkas. Paket ini memiliki perintah `tbl_summary()` yang dapat mengeluarkan analisis statistika deskriptif secara intuitif berdasarkan jenis data yang kita masukkan.

Untuk meng-install kedua paket tersebut, hapus tanda pagar di depan baris pertama dalam *chunk* di bawah dan muat paket `gtsummary` saja.

```{r}
# install.packages(c("gtsummary", "flextable"))
library(gtsummary)
```

### Variabel Kategoris

Kita masih akan menggunakan *pipe operator* dalam mengoperasikan analisis ini. Perintah yang kita gunakan adalah `tbl_summary()` yang kita teruskan ke `as_flex_table()` sebagai keluarannya.

Untuk menampilkan persentase/proporsi, kita cukup memasukkan variabel-variabel kategoris ke dalam tabel dengan atribut `include`. Atribut tersebut menerima masukan berupa vektor nama-nama variabel kategoris dalam dataset kita. Fungsi `tbl_summary` ini akan menampilkan secara otomatis tabel distribusi frekuensinya disertai dengan nilai persentasenya di samping nilai frekuensi tersebut.

```{r}
data.ubl |> 
  tbl_summary(include = c(Jenis.Kelamin,
                          Fakultas,
                          Tingkat.Semester,
                          Uang.Saku,
                          jenis.tempat.tinggal)) |> 
  as_flex_table()
```

Untuk menghitung IQV, kita bisa memanfaatkan perintah `function` yang mengambil masukan nilai-nilai yang ada di tanda kurungnya dan memprosesnya di dalam kurung kurawal `{}`. Perintah function selalu diakhiri dengan `return()` di dalamnya untuk menunjukkan hasil yang akan menjadi keluaran fungsi tersebut.

```{r}
iqv <- function(x) {
  
  # 1. Membersihkan data dari nilai yang hilang (NA)
  x_clean <- x[!is.na(x)]
  
  # 2. Membuat tabel frekuensi dari data yang bersih
  counts <- table(x_clean)
  
  # 3. Menghitung jumlah kategori (K)
  K <- length(counts)
  
  # 4. Kasus khusus: Jika hanya ada 1 kategori atau tidak ada data,
  #    maka tidak ada variasi, sehingga IQV = 0.
  if (K <= 1) {
    return(0)
  }
  
  # 5. Menghitung jumlah total observasi (n)
  n <- sum(counts)
  
  # 6. Menghitung jumlah kuadrat dari proporsi setiap kategori (Î£páµ¢Â²)
  sum_p_sq <- sum((counts / n)^2)
  
  # 7. Menerapkan formula IQV
  #    IQV = [K / (K - 1)] * [1 - Î£páµ¢Â²]
  iqv_value <- (K / (K - 1)) * (1 - sum_p_sq)
  
  # 8. Mengembalikan hasil perhitungan IQV
  return(iqv_value)
}
```

Untuk menghasilkan nilai IQV suatu variabel, kita perlu memasukkan vektor yang berisi nilai-nilai dalam variabel dataset kita. Ini dapat dilakukan dengan sintaks `dataset$nama_variabel`. Tanda \$ berfungsi memberi tahu R untuk memilih variabel yang ada dalam dataset yang digunakan.

```{r}
# Menampilkan vektor jenis.tempat.tinggal (opsional. Hapus komentar pada baris 
# berikut jika ingin mencobanya)
# data.ubl$jenis.tempat.tinggal

# Menghitung IQV variabel jenis.tempat.tinggal
iqv(data.ubl$jenis.tempat.tinggal)
```

### Variabel Numerik

Perintah `tbl_summary` akan menentukan jenis statistik deskriptif yang ditampilkan secara intuitif berdasarkan dataset yang dibacanya. Perhatikan hasil dari `tbl_summary` berikut untuk variabel `kepemilikan.mobil` dan `jarak`.

```{r}
data.ubl |> 
  tbl_summary(include = c(kepemilikan.mobil,
                          jarak)) |> 
  as_flex_table()
```

Seperti yang kalian lihat, `tbl_summary` langsung menampilkan persentase tiap nilai yang ada di kepemilikan.mobil seolah-olah `kepemilikan.mobil` adalah variabel diskret. Hal ini terjadi karena nilai variabel `kepemilikan.mobil` adalah nilai numerik diskret, sehingga masing-masing nilai dikenali sebagai kategori.

Hal ini berbeda lagi dengan variabel `jarak` yang menampilkan statistik deskriptif untuk variabel numerik, yakni median, kuartil bawah dan kuartil atas (Q1 & Q3).

Untuk meminta `tbl_summary` menampilkan analisis statistik deskriptif untuk variabel numerik seperti mean, median, kuartil, dan standar deviasi (simpangan baku), kita dapat menyatakannya dalam atribut-atribut berikut.

```{r}
data.ubl |> 
  tbl_summary(include = c(kepemilikan.mobil,
                          kepemilikan.motor,
                          jarak),
              type = list(kepemilikan.mobil ~ "continuous", # untuk mengarahkan tbl_summary membaca tipe data sesuai yang kita butuhkan
                          kepemilikan.motor ~ "continuous"),
              digits = list(kepemilikan.mobil ~ 0, # untuk menentukan jumlah desimal nilai yang ditampilkan
                            kepemilikan.motor ~ 0),
              statistic = list(kepemilikan.mobil ~ "{median} ({p25}, {p75})", # untuk menentukan jenis statistik deskriptif yang ditampilkan
                               kepemilikan.motor ~ "{median}",
                               jarak ~ "{mean} ({sd})")) |> 
  as_flex_table()

# Ketika meng-enter script, jangan salah memperhatikan urutan dan kelengkapan tanda koma pada fungsi
```

Untuk mengatur jenis statistik deskriptif yang ditampilkan, ubah bagian kanan tanda `~` pada atribut `statistic` sehingga apa yang ditulis di antara tanda petik menjadi template untuk ditampilkan di tabel. Adapun teknik statistik yang kita pakai harus kita tuliskan dalam kurung kurawalnya. Teknik-teknik statistik yang bisa kita gunakan di antaranya:

-   `{mean}` : rata-rata

-   `{median}` : median

-   `{min}`, `{max}`: nilai minimum, maksimum

-   `{p##}` : persentil ##. Persentil adalah nilai yang membagi data menjadi seratus bagian. Karena kuartil membagi data menjadi empat bagian, maka untuk menampilkan kuartil bawah (Q1), yang berarti nilai yang membagi data menjadi 1/4 terbawah (25%), kita menuliskan `{p25}`. Begitu juga dengan Q3 yang membagi data menjadi 3/4 terbawah (75%), kita menuliskan `{p75}`

-   `{sd}` : *standard deviation*/simpangan baku

-   `{n}` : frekuensi kategori

-   `{N}` : jumlah seluruhnya

-   `{p}` : persentase

::: {.rmdnote}
**Pengenalan Tipe Data Baru R: List (`list)`**

*List* pada dasarnya adalah tipe data nontunggal seperti vektor, hanya saja perbedaannya terletak pada tipe nilai yang dikandung. Vektor mewajibkan setiap elemen bernilai sama: string saja, angka saja, atau *boolean* saja misalnya.

Di sisi lain, *list* bisa memuat lebih dari satu jenis nilai. Ini sangat berguna ketika kita harus mendefinisikan sesuatu yang membutuhkan lebih dari satu nilai, seperti cara menampilkan statistik deskriptif untuk tiap-tiap variabel kita di fungsi `tbl_summary` di atas:

``` r
type = list(kepemilikan.motor ~ "continuous", kepemilikan.mobil ~ "continuous")

digits = list(kepemilikan.motor ~ 0, kepemilikan.mobil ~ 0)
```

-   *list* dalam pengaturan atribut `type` berarti "anggap tipe variabel `kepemilikan.motor` sebagai *continuous**,*** begitu juga untuk variabel `kepemilikan.mobil`

-   *list* dalam pengaturan atribut `digits` berarti "atur agar nilai desimal untuk `kepemilikan.motor` adalah 0, begitu juga untuk variabel `kepemilikan.mobil`
:::

::: {.rmdexercise}
**Aktivitas Mandiri 3: Analisis Statistik Deskriptif Komprehensif [STP-2.4]**

**Persiapan:**
Impor dataset UIN RIL dari sheet `DataUtama_mhsUINRIL` dan bersihkan seperti yang sudah dipraktikkan:
- Rename variabel yang perlu disesuaikan
- Gunakan `drop_na()` untuk menghapus missing values
- Buat factor untuk variabel kategoris (minimal: `Jenis.Kelamin`, `Tingkat.Semester`, `Uang.Saku`)

**Analisis yang Diminta:**

a. **Persentase/Proporsi:**
   - Hitung persentase mahasiswa berdasarkan `Uang.Saku`
   - Gunakan `tbl_summary(include = Uang.Saku)` dan `as_flex_table()`

b. **Ukuran Pemusatan (Median dan Kuartil):**
   - Untuk variabel `Jumlah.Perjalanan.Senin` (atau hari lain jika variabel ini tidak ada)
   - Tampilkan Median, Q1 (p25), dan Q3 (p75)
   - Gunakan `statistic = "{median} ({p25}, {p75})"`

c. **Ukuran Pemusatan dan Penyebaran (Mean dan SD):**
   - Untuk variabel biaya perjalanan per pekan
   - Tampilkan Mean dan Standar Deviasi
   - Gunakan `statistic = "{mean} ({sd})"`

d. **Ukuran Variasi Nominal (IQV):**
   - Hitung IQV untuk variabel `alasan.pemilihan.lokasi.tempat.tinggal`
   - Gunakan fungsi `iqv()` yang sudah dipelajari
   - Interpretasi: seberapa bervariasi alasan mahasiswa memilih tempat tinggal?

**Dokumentasi:**
- Kumpulkan semua hasil dalam file R Markdown Anda
- Sertakan interpretasi singkat untuk setiap hasil analisis
:::

------------------------------------------------------------------------


<!--chapter:end:02-statistik-deskriptif.Rmd-->

# Modul-3: Visualisasi Data Kuantitatif


Setelah mempelajari modul ini, Anda diharapkan dapat:

1. memilih visualiasi yang tepat sesuai dengan variabel yang akan disajikan dan informasi yang ingin disampaikan [STP-3.1]{.capaian}
2. menginterpretasikan suatu visualiasi data kuantitatif secara mendalam [STP-3.2]{.capaian}
3. menjelaskan pentingnya menentukan tingkat pengukuran untuk sebuah variabel dari kaitannya dengan analisis statistik deskriptif dan diagram yang dipilih untuk menyajikan informasi [STP-3.4]{.capaian}
4. menghasilkan grafik yang tepat sesuai variabel yang akan disajikan [STP-3.3]{.capaian}


---

## Visualisasi Data dengan `ggplot2`

`ggplot2` adalah sebuah paket R yang dibuat oleh Hadley Wickham untuk membuat grafik dan visualisasi data. Paket ini didasarkan pada "Grammar of Graphics", sebuah kerangka kerja yang memecah visualisasi menjadi komponen-komponen terpisah seperti data, sistem koordinat, dan elemen-elemen visual (geometries). Dengan pendekatan ini, Anda dapat membangun grafik lapis demi lapis *(layer by layer)*.

![Konsep `ggplot2`](images/basics_ggplot2.png)

### Mengimpor *Library* & Mengatur Dataset

Pertama, kita perlu memuat paket `tidyverse` yang sudah mencakup `ggplot2` untuk visualisasi dan `dplyr` serta `readr` untuk manipulasi data.

Tak lupa, kita juga akan menyertakan `openxlsx` dan `gtsummary` untuk mengolah data secara tabular jika sekiranya diperlukan dalam menunjang alur kerja kita.

```{r load-lib}
library(tidyverse)
library(openxlsx)
library(gtsummary)
```

Selanjutnya, kita akan mengimpor *dataset* kita, yakni hasil kuesioner kepada mahasiswa UBL., seperti halnya praktikum-praktikum sebelumnya.

```{r import-data}
# Mengeset variabel tersendiri untuk nama file nama sheet}
file.dibaca <- "datasets/Data Praktikum 03.xlsx"
sheet.ubl <- "DataUtama_mhsUBL"

# Mengimpor file menjadi dataset memanfaatkan variabel nama file dan nama sheet yang kita buat tadi
data.ubl <- read.xlsx(file.dibaca, sheet = sheet.ubl)

# Pengenalan fungsi baru: 'mengintip' sejumlah baris pertama dari dataset kita
head(data.ubl)
```

Kemudian kita perlu menetapkan `factor` untuk variabel-variabel kategoris kita agar data kita lebih 'bersih.'

```{r factor}
# Menetapkan vektor untuk factor variabel kategoris
jk <- c("Laki-Laki", "Perempuan")

fakultas <- c("Fakultas Ekonomi dan Bisnis", "Fakultas Hukum",
              "Fakultas Ilmu Komputer", "Fakultas Ilmu Sosial dan Politik",
              "Fakultas Keguruan dan Ilmu Pendidikan", "Fakultas Teknik")

prodi <- c("Administrasi Bisnis", "Administrasi Publik","Akuntansi","Arsitektur",
           "Ilmu Hukum","Ilmu Komunikasi", "Informatika","Manajemen",
           "Pendidikan Bahasa Inggris", "Sistem Informasi")

tingkat <- c("1 (Semester 1 â€“ Semester 2)",
             "2 (Semester 3 â€“ Semester 4)",
             "3 (Semester 5 - Semester 6)",
             "4 (Semester 7 - Semester 8)")

uang_saku <- c("< 1 jt", "1 jt â€“ 2 jt", "2,1 jt â€“ 3 jt", "3,1 jt â€“ 4 jt", "> 4 jt")


# Merapikan dataset
data.ubl <- data.ubl |> 
  # mengubah nama variabel
  rename(biaya.dalam.sepekan = biaya.dalam.seminggu) |>
  rename(Jumlah.Perjalanan.Senin = Jumlah.perjalanan.Senin) |> 
  rename(jarak = `jarak.(km)`) |> 
  # menghapus data dengan missing values
  drop_na() |> 
  # menambahkan factor ke variabel kategoris
  mutate(Jenis.Kelamin = factor(Jenis.Kelamin, levels = jk),
         Fakultas = factor(Fakultas, levels = fakultas),
         Prodi = factor(Prodi, levels = prodi),
         Tingkat.Semester = factor(Tingkat.Semester, 
                                   levels = tingkat,
                                   ordered = TRUE), 
         Uang.Saku = factor(Uang.Saku, levels = uang_saku, ordered = TRUE))
  
```

Kita akan mengubah kategori `factor` pada variabel `Tingkat.Semester` dan `Uang.Saku` agar lebih mudah dibaca saat divisualisasikan. Kita akan menggunakan fungsi dari `dplyr` (bagian dari `tidyverse`) untuk membersihkan dan mengubah data.

```{r clean-data}
# Membersihkan dan mengubah nama level pada variabel Tingkat.Semester dan Uang.Saku
data.ubl.cleaned <- data.ubl %>%
  mutate(
    Tingkat.Semester = fct_recode(Tingkat.Semester,
      "Semester 1 & 2" = "1 (Semester 1 â€“ Semester 2)",
      "Semester 3 & 4" = "2 (Semester 3 â€“ Semester 4)",
      "Semester 5 & 6" = "3 (Semester 5 - Semester 6)",
      "Semester 7 & 8" = "4 (Semester 7 - Semester 8)",
      "Di Atas Semester 8" = "5 (Di atas semester 8)"
    ),
    Uang.Saku = fct_relevel(Uang.Saku, 
      "< 1 jt", "1 jt â€“ 2 jt", "> 2 jt"
    )
  )

# Menampilkan hasil pembersihan data
glimpse(data.ubl.cleaned)
```

Sekarang kita siap memvisualkan data kita.

### Tata Tulis Grafik *(Grammar of Graphics)*

Setiap grafik `ggplot2` terdiri dari beberapa komponen kunci:

-   **DATA**: Dataset yang ingin Anda visualisasikan.
-   **MAPPING**: `aes()` (aesthetics), yang menghubungkan variabel dari data Anda ke properti visual dari grafik (misalnya, sumbu x, sumbu y, warna, ukuran).
-   **GEOM_FUNCTION**: Objek geometris yang merepresentasikan data (misalnya, `geom_point()` untuk scatter plot, `geom_bar()` untuk diagram batang).
-   **STAT**: Transformasi statistik. Setiap `geom` memiliki statistik default (misalnya, `geom_bar` secara default menggunakan `stat_count`), tetapi Anda bisa menentukannya secara manual.
-   **POSITION**: Penyesuaian posisi untuk `geom` yang tumpang tindih (misalnya, `position_dodge()` atau `position_stack()`).
-   **COORDINATE_FUNCTION**: Sistem koordinat yang digunakan (`coord_cartesian`, `coord_flip`, dll.).
-   **FACET_FUNCTION**: Membagi plot menjadi beberapa sub-plot berdasarkan variabel kategori (`facet_wrap` atau `facet_grid`).

``` r
ggplot(<DATA>) + 
  <GEOM_FUNCTION>(mapping = aes(<MAPPING>),
             stat = <STAT>,
             position = <POSITION>) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION> +
  <SCALE_FUNCTION> +  # opsional
  <THEME_FUNCTION>    # opsional
```

!["Grammar of Graphics"](images/grammar_of_graphics.png)

### Praktik Visualisasi Data

#### Diagram Batang *(Column/Bar Chart)*

Diagram batang sangat baik untuk menampilkan distribusi atau perbandingan data **kategoris**.

##### Diagram Batang Tunggal

Mari kita lihat distribusi mahasiswa berdasarkan tingkat semester. `geom_bar()` secara otomatis menghitung jumlah observasi untuk setiap kategori di sumbu x.

```{r bar-chart-single}

diagram_batang <- ggplot(data.ubl.cleaned) +
  geom_bar(mapping = aes(x = Tingkat.Semester), fill = "skyblue",
           color = "black") +
  labs(
    title = "Distribusi Mahasiswa Berdasarkan Tingkat Semester",
    x = "Tingkat Semester",
    y = "Jumlah Mahasiswa"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotasi label x agar tidak tumpang tindih

diagram_batang
```

**Interpretasi:** Grafik di atas menunjukkan bahwa mayoritas responden mahasiswa berasal dari tingkat semester 5 & 6, diikuti oleh semester 7 & 8.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA**: `ggplot(data.ubl.cleaned)` mendefinisikan dataset yang digunakan.
-   **GEOM**: `geom_bar(...)` menentukan bentuk geometris yang digunakan, yaitu batang.
-   **MAPPING**: `mapping = aes(x = Tingkat.Semester)` memetakan variabel `Tingkat.Semester` dari data ke sumbu x pada grafik.
-   **STAT**: `geom_bar()` secara default menggunakan `stat = "count"`, yang berarti ia secara otomatis melakukan transformasi statistik dengan menghitung jumlah baris untuk setiap kategori `Tingkat.Semester` dan menampilkannya sebagai ketinggian batang di sumbu y.
-   `fill = "skyblue", color = "black"`: Ini adalah pengaturan properti visual, bukan pemetaan. Kita mengatur semua batang agar memiliki warna isian "skyblue" dan garis tepi "black".
-   `labs(...)`, `theme_minimal()`, `theme(...)`: Ini adalah lapisan tambahan untuk kustomisasi label dan tema, bukan bagian inti dari "grammar".

##### Diagram Batang Bertumpuk *(Stacked)*

Kita bisa menambahkan variabel lain, misalnya `Uang.Saku`, ke dalam `aes()` dengan properti `fill` untuk membuat diagram batang bertumpuk. Ini menunjukkan proporsi uang saku di setiap tingkat semester.

```{r bar-chart-stacked}
diagram_batangTumpuk <- ggplot(data.ubl.cleaned) +
  geom_bar(mapping = aes(x = Tingkat.Semester, fill = Uang.Saku)) +
  labs(
    title = "Distribusi Uang Saku per Tingkat Semester",
    x = "Tingkat Semester",
    y = "Jumlah Mahasiswa",
    fill = "Uang Saku per Bulan"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

diagram_batangTumpuk
```

**Interpretasi:** Dari grafik ini, kita bisa melihat komposisi uang saku di setiap angkatan. Misalnya, pada tingkat "Semester 5 & 6", sebagian besar mahasiswa memiliki uang saku antara 1 juta hingga 2 juta. Hal ini kita ketahui dari perbandingan relatif tinggi porsi warna-warna dalam masing-masing batang.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **MAPPING**: `mapping = aes(x = Tingkat.Semester, fill = Uang.Saku)` kini memiliki pemetaan tambahan. Selain sumbu x, kita juga memetakan variabel `Uang.Saku` ke properti visual `fill` (warna isian). `ggplot` akan membuat segmen berwarna berbeda di dalam setiap batang sesuai kategori uang saku.
-   **POSITION**: Secara default, `geom_bar()` menggunakan `position = "stack"` ketika `fill` dipetakan ke sebuah variabel. Inilah yang menyebabkan segmen-segmen tersebut ditumpuk di atas satu sama lain.
-   `labs(fill = "Uang Saku per Bulan")`: Argumen `fill` di dalam `labs()` berfungsi untuk mengubah judul dari legenda yang secara otomatis dibuat dari pemetaan `fill`.

Untuk membandingkan jumlah absolut antar kategori uang saku, diagram batang berkelompok lebih efektif. Kita gunakan `position = "dodge"`.

```{r bar-chart-grouped}
diagram_batangSebar <- ggplot(data.ubl.cleaned) +
  geom_bar(mapping = aes(x = Tingkat.Semester, fill = Uang.Saku),
           position = "dodge") +
  labs(
    title = "Perbandingan Uang Saku per Tingkat Semester",
    x = "Tingkat Semester",
    y = "Jumlah Mahasiswa",
    fill = "Uang Saku per Bulan"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

diagram_batangSebar
```

**Interpretasi:** Grafik ini mempermudah perbandingan langsung. Terlihat jelas bahwa kategori uang saku "1 jt â€“ 2 jt" mendominasi di hampir semua tingkat semester.

-   **POSITION**: Komponen `position` diubah secara eksplisit menjadi `position = "dodge"`. Ini menginstruksikan `ggplot` untuk menempatkan batang-batang yang memiliki kategori x yang sama (misalnya, "Semester 5 & 6") bersebelahan, bukan menumpuknya. Ini memungkinkan perbandingan langsung antar kategori `Uang.Saku`.

Terkadang kita lebih tertarik pada perbandingan proporsi antar grup daripada jumlah absolutnya. Dengan mengubah `position` menjadi `"fill"`, kita dapat membuat setiap batang memiliki tinggi yang sama (100%) dan menunjukkan persentase relatif dari setiap subgrup.

```{r bar-chart-fill}
diagram_btTumpuk100 <- ggplot(data.ubl.cleaned) +
  geom_bar(mapping = aes(x = Tingkat.Semester, fill = Uang.Saku),
           position = "fill") +
  scale_y_continuous(labels = scales::percent) + # untuk mengubah satuan sumbu Y menjadi '%'
  labs(
    title = "Proporsi Uang Saku per Tingkat Semester",
    x = "Tingkat Semester",
    y = "Persentase",
    fill = "Uang Saku per Bulan"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

diagram_btTumpuk100
```

**Interpretasi:** Grafik ini menunjukkan bahwa secara proporsional, mahasiswa dengan kategori uang saku tertinggi ("\>4jt") yang paling dominan terdapat pada tingkat 3 ("Semester 5 & 6"). Sementara itu, mahasiswa kategori uang saku terrendah paling banyak porsinya pada tingkat 2 ("Semester 3 & 4"). Ini adalah wawasan yang mungkin tidak terlihat jelas pada grafik jumlah absolut.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **POSITION**: Komponen `position` diubah menjadi `position = "fill"`. Pengaturan ini secara otomatis melakukan transformasi **STAT** yang berbeda: ia menghitung proporsi dari setiap subgrup (`Uang.Saku`) dalam setiap grup (`Tingkat.Semester`). Hasilnya adalah setiap batang dinormalisasi menjadi setinggi 1 (atau 100%).

-   **SCALE**: `scale_y_continuous(labels = scales::percent)` adalah lapisan tambahan yang mengontrol **SKALA** pada sumbu y. Fungsi `scales::percent` digunakan untuk memformat label sumbu dari angka desimal (misal: 0.5) menjadi format persentase (misal: 50%) agar lebih mudah dibaca.

::: {.rmdexercise}
**Aktivitas Mandiri 1: Membuat dan Menginterpretasikan Diagram Batang [STP-3.2, STP-3.3]**

Buatlah diagram batang untuk variabel `Fakultas`:

1. **Diagram batang sederhana** - gunakan `geom_bar()`
2. **Diagram batang bertumpuk** dengan `Uang.Saku` sebagai fill
3. **Diagram batang berkelompok** dengan `position = "dodge"` dan interpretasikan hasilnya:
   - Fakultas mana yang paling banyak mahasiswa dengan uang saku >2jt?
   - Bagaimana pola distribusi uang saku antar fakultas?
   - Apakah ada fakultas yang dominan memiliki mahasiswa dengan uang saku tertentu?
:::

### Diagram Lollipop

Diagram lolipop adalah alternatif dari diagram batang yang dapat mengurangi tinta visual dan memberikan penekanan lebih pada nilai data. Grafik ini menggunakan segmen garis dan titik untuk merepresentasikan nilai. Ini sangat efektif untuk menampilkan data kategoris yang banyak kategorinya.

```{r buat-data-bahan}
# Pertama, kita perlu membuat tabel baru yang menampilkan jumlah mahasiswa per program studi
prodi_count <- data.ubl.cleaned |> 
  count(Prodi, name = "jumlah") |> 
  arrange(jumlah) |> 
  mutate(Prodi = fct_inorder(Prodi)) # mengubah jadi faktor terurut
```

```{r lollipop-chart}
# Kedua, kita baru bisa membuat diagram lollipop-nya
diagram_lollipop <- ggplot(prodi_count) +
  # diagram lollipop terdiri atas 2 geometri: geom_segment yang bertindak sebagai
  # batang dan geom_point yang bertindak sebagai permennya
  geom_segment(
    mapping = aes(x = Prodi,
                  y = 0, yend = jumlah),
    color = "grey",
    size = 1.5) +
  geom_point(
    mapping = aes(x = Prodi, y = jumlah),
    color = "#0072B2", size = 4
  ) + 
  coord_flip() + # Membalik sumbu agar mudah dibaca
  labs(
    title = "Jumlah Responden Mahasiswa UBL Per Program Studi",
    x = "Program Studi",
    y = "Jumlah Responden"
  ) +
  theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank()
  )

diagram_lollipop
```

**Interpretasi:** Grafik ini menunjukkan bahwa kebanyakan responden berasal dari program studi Ilmu Hukum dan Manajemen, dengan perbandingan yang cukup timpang dengan prodi-prodi lain. Selain itu, ternyata cukup dominan mahasiswa yang tidak memberikan data prodi mereka (NA) di antara prodi-prodi selain dua yang tertinggi tadi.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA & STAT**: Sama seperti contoh sebelumnya, kita melakukan pra-pemrosesan data menggunakan `dplyr`. Kita mengelompokkan data berdasarkan `Prodi`, menghitung (`count`) jumlahnya, mengurutkan (`arrange`), dan yang terpenting, mengubah `Prodi` menjadi variabel faktor yang terurut (`fct_inorder`) agar plot ditampilkan sesuai urutan yang kita inginkan.
-   **GEOM & MAPPING (Layering)**: Di sinilah keunikan diagram lolipop. Kita menggunakan **dua lapisan `geom`**:
    -   `geom_segment()`: Digunakan untuk membuat "batang" atau segmen garis. **Mapping**-nya membutuhkan empat estetika: `x` dan `xend` (yang sama untuk garis vertikal) serta `y` (titik awal, yaitu 0) dan `yend` (titik akhir, yaitu `jumlah`).
    -   `geom_point()`: Digunakan untuk membuat "permen" atau titik di ujung segmen. **Mapping**-nya lebih sederhana, hanya membutuhkan `x` dan `y`.
-   **KOORDINAT**: `coord_flip()` digunakan untuk membalik sumbu, membuat diagram lolipop horizontal yang seringkali lebih mudah dibaca label kategorinya.
-   **THEME**: Lapisan tema digunakan untuk membersihkan tampilan, seperti menghilangkan beberapa garis grid dan batas panel untuk menonjolkan data itu sendiri.

### Diagram Pai/Donat *(Pie/Donut Chart)*

Diagram pai (dan variasinya, diagram donat) digunakan untuk menunjukkan proporsi dari sebuah keseluruhan. Meskipun populer, diagram pai seringkali sulit untuk dibaca secara akurat, terutama ketika ada banyak irisan atau ukurannya mirip. Diagram donat sedikit lebih baik karena mengurangi penekanan pada sudut dan lebih fokus pada panjang busur.

Di `ggplot2`, diagram pai dibuat dengan memulai dari diagram batang bertumpuk, lalu mengubah sistem **KOORDINAT**-nya menjadi koordinat polar. Akan tetapi, dalam `ggplot2` kita tidak bisa membuat diagram pai langsung dari datasetnya, tetapi kita harus membentuk **tabel distribusi frekuensinya** terlebih dahulu.

```{r bahan-pie-and-donut}
fakultas_count <- data.ubl.cleaned |> 
  count(Fakultas, name = "jumlah") |> # Membuat kolom jumlah responden per fakultas
  mutate(
    persen = jumlah / sum(jumlah) # Membuat kolom persentase dari 'jumlah
  )

fakultas_count
```

Baru kemudian kita bisa menghasilkan perintah `ggplot` untuk

```{r membuat-diagram-pai}
diagram_pai <- ggplot(fakultas_count, aes(x = 2, y = persen, fill = Fakultas)) +
  geom_bar(stat = "identity", color = "white") +
  coord_polar(theta = "y", start = 0) +
  labs(
    title = "Sebaran Fakultas Responden Mahasiswa UBL",
    fill = "Fakultas"
  ) +
  # Membersihkan tema
  theme_void() +
  theme(legend.position = "right")

diagram_pai
```

**Interpretasi:** Diagram donat ini menunjukkan proporsi dari setiap fakultas. Terlihat jelas bahwa irisan "Fakultas Ekonomi dan Bisnis" dan "Fakultas Hukum" mendominasi porsi responden.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA & STAT**: Kita menggunakan data `alasan_counts` yang sudah diagregasi, lalu menambahkan kolom baru untuk persentase (`persen`) dan posisi vertikal untuk label (`posisi_y_label`).
-   **GEOM & MAPPING**: Kita mulai dengan `geom_bar(stat = "identity")` yang membuat diagram batang di mana tinggi batang (`y`) adalah nilai persentase itu sendiri. `x=2` adalah trik untuk membuat satu batang tunggal yang akan kita "lilit".
-   **KOORDINAT**: `coord_polar(theta = "y")` adalah komponen kunci. Ini mengambil diagram batang dan mengubah sistem koordinatnya dari Kartesius (x,y) menjadi Polar. Sumbu y "dibengkokkan" menjadi sebuah lingkaran.
-   `theme_void()`: Menghilangkan semua elemen tema seperti sumbu, label sumbu, dan latar belakang, yang tidak relevan untuk diagram pai/donat.
-   kita bisa menambahkan lubang di tengah pai dengan menambahkan `xlim(0.5, 2.5)` yang merupakan batas dalam dan batas luar dari radius si diagram seperti berikut.

```{r membuat-diagram-donat}
diagram_donat <- diagram_pai + xlim(0.5, 2.5)

diagram_donat
```

> âš ï¸**Penting**
>
> Komunitas perupa data pada dasarnya menganjurkan kita untuk 'menghindari' diagram lingkaran. Hal ini bisa kalian baca di [laman ini](https://www.data-to-viz.com/caveat/pie.html). Alternatifnya, mereka lebih menyarankan kita untuk menggunakan diagram batang atau diagram lollipop saja

### Diagram *Treemap*

Treemap adalah alternatif lain untuk diagram pai, terutama efektif ketika Anda memiliki banyak kategori. Treemap menampilkan data hierarkis atau bagian-ke-keseluruhan sebagai satu set persegi panjang bersarang. Ukuran setiap persegi panjang sebanding dengan nilainya.

Untuk membuat treemap, kita perlu paket tambahan yaitu `treemapify`.

```{r load-treemapify}
# Pastikan paket sudah terinstall: install.packages("treemapify")
# install.packages("treemapify")
library(treemapify)
```

Kita akan membuat *treemap* dari alasan mahasiswa memilih tempat tinggal mereka

```{r membuat-alasan-count}
# Pertama, kita siapkan data dengan menghitung jumlah dan mengurutkannya
alasan_counts <- data.ubl.cleaned |> 
  # Mengganti nama yang terlalu panjang agar muat di plot
  mutate(alasan_singkat = fct_recode(`alasan.pemilihan.lokasi.tempat.tinggal`,
    "Bersama Keluarga" = "Bersama keluarga/saudara/teman",
    "Dekat Kampus/lokasi lain" = "Dekat dengan kampus",
    "Dekat Kampus/lokasi lain" = "Dekat dengan fasilitas umum",
    "Dekat Kampus/lokasi lain" = "Mudahnya akses berpergian dari tempat tinggal ",
    "Fasilitas Lengkap" = "Fasilitas tempat tinggal lengkap",
    "Murah" = "Biaya tempat tinggal murah",
    "Aman" = "Lingkungan nyaman karna aman dari kejahatan"
  )) |>
  count(alasan_singkat, name = "jumlah")

alasan_counts
```

```{r treemap}
ggplot(alasan_counts, aes(area = jumlah, fill = alasan_singkat, label = alasan_singkat)) +
  geom_treemap() +
  geom_treemap_text(
    colour = "white", 
    place = "centre",
    size = 13
  ) +
  labs(
    title = "Proporsi Alasan Mahasiswa Memilih Tempat Tinggal (Treemap)",
    fill = "Alasan utama"
  ) +
  theme(legend.position = "bottom") # Untuk menampilkan area yang tidak ada labelnya
```

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA**: Kita menggunakan data `alasan_counts` yang sudah diagregasi.
-   **GEOM & MAPPING**: Paket `treemapify` menyediakan `geom` baru yang terintegrasi dengan `ggplot2`.
    1.  `geom_treemap()`: Ini adalah `geom` utama. Alih-alih `x` dan `y`, **MAPPING** utamanya adalah `aes(area = jumlah)`. `ggplot` akan secara otomatis menghitung tata letak persegi panjang berdasarkan nilai `jumlah`. Kita juga memetakan `alasan_singkat` ke `fill` untuk warna dan `label` untuk teks.
    2.  `geom_treemap_text()`: Ini adalah `geom` tambahan khusus untuk menempatkan teks di dalam setiap area treemap.
-   **THEME**: Kita bisa menyembunyikan legenda karena setiap area sudah diberi label secara langsung, sehingga legenda menjadi berlebihan. Caranya adalah mengatur nilai `bottom =` menjadi `"none"`. Akan tetapi, untuk kasus kita, kita punya area yang terlalu kecil untuk diberi label, sehingga kita tetap tampilkan legenda.

### Histogram

Histogram digunakan untuk melihat distribusi dari variabel numerik/kontinu, seperti `Umur`.

```{r histogram}
histogram <- ggplot(data.ubl.cleaned) +
  geom_histogram(mapping = aes(x = Umur), binwidth = 1, fill = "darkseagreen", color = "white") +
  labs(
    title = "Distribusi Umur Mahasiswa",
    x = "Umur (Tahun)",
    y = "Frekuensi"
  ) +
  theme_minimal()

histogram
```

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA**: `ggplot(data.ubl.cleaned)` mendefinisikan dataset.
-   **GEOM**: `geom_histogram(...)` menentukan bentuk geometris berupa histogram.
-   **MAPPING**: `mapping = aes(x = Umur)` memetakan variabel numerik `Umur` ke sumbu x.
-   **STAT**: `geom_histogram` memiliki `stat = "bin"` sebagai defaultnya. Transformasi statistik ini akan membagi data `Umur` ke dalam beberapa rentang (bins) yang lebarnya diatur oleh `binwidth = 1`, lalu menghitung frekuensi data di setiap rentang tersebut untuk ditampilkan di sumbu y.

### *Boxplot*

Box plot berguna untuk membandingkan distribusi variabel numerik di antara beberapa grup/kategori. Mari kita bandingkan distribusi jarak tempat tinggal (`jarak`) untuk setiap jenis kendaraan utama.

```{r box-plot}
boxplot <- ggplot(data.ubl.cleaned) +
  geom_boxplot(mapping = aes(x = kendaraan.utama, y = jarak, fill = kendaraan.utama)) +
  coord_flip() + # Membalik sumbu agar label mudah dibaca
  labs(
    title = "Distribusi Jarak Tempat Tinggal Berdasarkan Kendaraan Utama",
    x = "Kendaraan Utama",
    y = "Jarak dari Kampus (km)"
  ) +
  theme_minimal() +
  theme(legend.position = "none") # Menghilangkan legenda karena sudah ada di sumbu

boxplot
```

**Interpretasi:** Box plot ini menunjukkan bahwa mahasiswa yang menggunakan mobil pribadi cenderung memiliki rentang jarak tempat tinggal yang lebih bervariasi dan median yang sedikit lebih tinggi dibandingkan pengguna sepeda motor. Pengguna ojek online memiliki median jarak yang paling rendah di antara kategori lainnya.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA**: `ggplot(data.ubl.cleaned)` mendefinisikan dataset.

-   **GEOM**: `geom_boxplot(...)` menentukan bentuk geometris berupa diagram kotak.

-   **MAPPING**: `mapping = aes(x = kendaraan.utama, y = \`jarak.(km)\`, fill = kendaraan.utama)`memetakan tiga hal: variabel kategori`kendaraan.utama`ke sumbu x, variabel numerik`jarak.(km)`ke sumbu y, dan`kendaraan.utama`ke warna isian`fill\`.

-   **STAT**: `geom_boxplot` secara default menggunakan `stat_boxplot`, yang menghitung ringkasan lima angka (minimum, Q1, median, Q3, maksimum) untuk setiap grup di sumbu x.

-   **KOORDINAT**: `coord_flip()` secara eksplisit mengubah sistem koordinat dengan membalik sumbu x dan y. Ini adalah komponen terpisah yang diterapkan setelah komponen lainnya.

-   `theme(legend.position = "none")`: Kustomisasi lapisan tema untuk menyembunyikan legenda.

### Grafik Pencar *(Scatter Plot)*

Scatter plot ideal untuk melihat hubungan antara dua variabel numerik. Mari kita lihat hubungan antara `Umur` dan `jarak` tempat tinggal.

```{r scatter-plot}
scatter_plot <- ggplot(data.ubl.cleaned) +
  geom_point(mapping = aes(x = Umur, y = jarak), alpha = 0.6, color = "darkblue") + # alpha untuk transparansi
  labs(
    title = "Hubungan Antara Umur dan Jarak Tempat Tinggal",
    x = "Umur (Tahun)",
    y = "Jarak dari Kampus (km)"
  ) +
  theme_minimal()
  
scatter_plot

```

**Interpretasi:** Grafik ini tidak menunjukkan adanya pola atau hubungan yang jelas antara umur mahasiswa dan jarak tempat tinggal mereka dari kampus. Titik-titik tersebar secara acak.

**Penjelasan Sintaks (Grammar of Graphics):**

-   **DATA**: `ggplot(data.ubl.cleaned)` mendefinisikan dataset.
-   **GEOM**: `geom_point(...)` menentukan bentuk geometris berupa titik.
-   **MAPPING**: `mapping = aes(x = Umur, y = \`jarak.(km)\`)`memetakan dua variabel,`Umur`ke sumbu x dan`jarak.(km)\` ke sumbu y. Setiap baris data akan menjadi satu titik pada plot.
-   `alpha = 0.6` dan `color = "darkblue"` adalah pengaturan properti visual untuk semua titik.

Penting untuk menjaga konteks dalam interpretasi. Scatter plot kita menunjukkan bahwa mahasiswa yang lebih tua cenderung tinggal lebih jauh dari kampus. Namun, untuk benar-benar memahami kekuatan hubungan ini, kita perlu menggunakan statistik korelasi (akan dipelajari di modul selanjutnya).

::: {.rmdexercise}
**Aktivitas Mandiri 2: Histogram dan Boxplot untuk Variabel Numerik [STP-3.2, STP-3.3]**

Gunakan variabel `jarak` (jarak tempat tinggal dari kampus):

1. **Buat histogram** dengan `binwidth = 2` dan interpretasikan:
   - Apakah distribusi jarak simetris atau menceng (skewed)?
   - Pada rentang jarak berapa frekuensi mahasiswa paling tinggi?
   - Apakah ada pola tertentu dalam distribusi jarak?

2. **Buat boxplot** yang membandingkan `jarak` berdasarkan `Tingkat.Semester` dan interpretasikan:
   - Tingkat semester mana yang rata-rata (median) tinggal paling jauh dari kampus?
   - Apakah ada outlier? Jika ada, pada tingkat semester mana?
   - Bagaimana variabilitas jarak pada setiap tingkat semester?
:::

::: {.rmdexercise}
**Aktivitas Mandiri 3: Visualisasi Komprehensif untuk `biaya.dalam.sepekan` [STP-3.1, STP-3.2, STP-3.3, STP-3.4]**

**A. Menghasilkan Grafik [STP-3.3]:**

1. Buat **histogram** untuk `biaya.dalam.sepekan`
   - Coba beberapa nilai `binwidth` (misal: 20, 50, atau 100) dan pilih yang paling informatif
   - Tambahkan judul dan label sumbu yang jelas

2. Buat **boxplot** untuk `biaya.dalam.sepekan` berdasarkan `kendaraan.utama`
   - Gunakan `geom_boxplot()` dengan `fill` berdasarkan kendaraan
   - Tambahkan label yang jelas

3. Buat **scatter plot** untuk `Umur` vs `biaya.dalam.sepekan`
   - Tambahkan `geom_point()` dengan `alpha = 0.5` untuk transparansi
   - Pertimbangkan menambahkan `geom_smooth(method = "lm")` untuk melihat trend

**B. Pemilihan Visualisasi dan Tingkat Pengukuran [STP-3.1, STP-3.4]:**

4. **Mengapa histogram cocok untuk `biaya.dalam.sepekan`?**
   - Jelaskan kaitannya dengan tingkat pengukuran variabel (metrik/rasio)
   - Informasi apa yang bisa diperoleh dari histogram? (distribusi, spread, outlier)

5. **Apakah scatter plot cocok untuk `Jenis.Kelamin` vs `Umur`? Mengapa tidak?**
   - Jelaskan kaitannya dengan tingkat pengukuran variabel
   - Diagram apa yang lebih sesuai untuk membandingkan umur berdasarkan jenis kelamin?

**C. Interpretasi Mendalam [STP-3.2]:**

6. **Dari histogram no.1:**
   - Berapa rentang biaya yang paling sering muncul (modus)?
   - Apakah distribusinya simetris, menceng kanan, atau menceng kiri?
   - Apakah ada outlier (nilai ekstrem)?

7. **Dari boxplot no.2:**
   - Kendaraan apa yang memiliki median biaya tertinggi?
   - Kendaraan apa yang paling bervariasi biayanya (IQR terbesar)?
   - Apakah ada outlier? Pada jenis kendaraan apa?

8. **Dari scatter plot no.3:**
   - Apakah ada pola hubungan antara umur dan biaya transportasi?
   - Jika ada trend line, apakah slopenya positif atau negatif?
   - Apa interpretasi kontekstualnya?

**D. Dokumentasi [STP-3.3]:**

9. Kumpulkan file modul ini dengan:
   - Seluruh kode diagram yang sudah Anda buat di modul ini
   - Seluruh interpretasi dan analisis untuk setiap diagram
   - Screenshot atau output grafik yang sudah dihasilkan
:::

------------------------------------------------------------------------


<!--chapter:end:03-visualisasi-data.Rmd-->

# Modul-4: Distribusi Sampling dan Interval Kepercayaan

Setelah mempelajari modul ini, Anda diharapkan dapat:

1. menghasilkan distribusi statistik sampel dan menghitung standard error-nya [STP-4.3]{.capaian}
2. menghasilkan interval kepercayaan dengan menggunaan perangkat lunak komputer [STP-5.2]{.capaian}


---

## Pendahuluan

Dalam statistika inferensial, kita seringkali ingin mengetahui karakteristik dari sebuah populasi (misalnya, rata-rata uang saku seluruh mahasiswa di Indonesia). Namun, mengumpulkan data dari seluruh populasi seringkali tidak memungkinkan. Sebagai solusinya, kita mengambil sampel acak dari populasi tersebut dan menggunakan statistik dari sampel (seperti rata-rata sampel) untuk menduga parameter populasi.

Modul ini akan membahas dua konsep fundamental dalam statistika inferensial: **Distribusi Sampling** dan **Interval Kepercayaan** untuk rata-rata dan proporsi. Kita akan menggunakan studi kasus data jarak tempuh mahasiswa dari empat universitas di Bandar Lampung dan sekitarnya untuk memahami bagaimana konsep ini diterapkan dalam praktik.

## Perangkat Lunak dan Pustaka (Libraries)

Pastikan Anda telah menginstal pustaka `tidyverse` yang akan sangat membantu dalam proses manipulasi dan visualisasi data.

```{r}
library(tidyverse)
library(readr)
```

## Memuat dan Mempersiapkan Data

Langkah pertama adalah memuat data survei mahasiswa dari empat universitas. Kita akan menggabungkan dan membersihkan data tersebut untuk analisis. Variabel yang akan menjadi fokus kita adalah **jarak tempuh (km)** dan **jenis tempat tinggal**.

```{r baca-gabung-bersihkan-data}
# Membaca 4 file CSV
df_uinril <- read_csv2("datasets/DataUtama_mhsUINRIL.csv")
df_ubl <- read_csv2("datasets/DataUtama_mhsUBL.csv")
df_unila <- read_csv2("datasets/DataUtama_mhsUNILA.csv")
df_itera <- read_csv2("datasets/DataUtama_mhsITERA.csv")

# Membersihkan dan menggabungkan data
data_mahasiswa <- bind_rows(
  df_uinril |>
    select(
      kampus = Kampus_PT,
      jarak_km = `jarak (km)`,
      jenis_tinggal = `jenis tempat tinggal`
    ),
  df_ubl |>
    select(
      kampus = Kampus_PT,
      jarak_km = `jarak (km)`,
      jenis_tinggal = `jenis tempat tinggal`
    ),
  # Perhatikan nama kolom 'jarak' dan 'jenis tempat tinggal' berbeda di file UNILA
  df_unila |>
    select(
      kampus = Kampus_PT,
      jarak_km = jara,
      jenis_tinggal = `Jenis Tempat Tinggal`
    ),
  df_itera |>
    select(
      kampus = Kampus_PT,
      jarak_km = `jarak (km)`,
      jenis_tinggal = `jenis tempat tinggal`
    )
) |>
  # Mengubah tipe data 'jarak_km' menjadi numerik
  mutate(jarak_km = as.numeric(jarak_km)) |>
  # Menghapus baris dengan data yang kosong (NA)
  drop_na(jarak_km, jenis_tinggal) |>
  # Melakukan filter sederhana untuk data jarak yang lebih masuk akal
  filter(jarak_km > 0 & jarak_km < 50) |>
  # Membuat variabel baru yang disederhanakan untuk jenis tempat tinggal
  mutate(
    tipe_tinggal_baku = case_when(
      # Menggunakan str_detect untuk mencari kata kunci "kos", "asrama", atau "rusunawa" (tidak case-sensitive)
      str_detect(tolower(jenis_tinggal), "kos|asrama|rusunawa") ~ "Kos/Asrama",
      # Selain itu, dikategorikan sebagai "Rumah Keluarga/Pribadi"
      TRUE ~ "Rumah Keluarga/Pribadi"
    )
  )

# Menampilkan beberapa baris pertama dari data gabungan
head(data_mahasiswa)

# Menampilkan ringkasan data
summary(data_mahasiswa)

# Menampilkan frekuensi jenis tempat tinggal yang sudah dibakukan
table(data_mahasiswa$tipe_tinggal_baku)

```

> **Penjelasan `case_when()`**:
>
> Fungsi `case_when()` (bagian dari `dplyr`) sangat berguna untuk membuat variabel baru berdasarkan serangkaian aturan kondisional, mirip seperti pernyataan `IF-ELSE IF-ELSE`. Di dalam `mutate()`, kita membuat kolom baru bernama `tipe_tinggal_baku`.
>
> -   **Aturan pertama**: `str_detect(tolower(jenis_tinggal), "kos|asrama|rusunawa") ~ "Kos/Asrama"`
>
>     -   `tolower(jenis_tinggal)`: Mengubah semua teks di kolom `jenis_tinggal` menjadi huruf kecil agar pencarian tidak sensitif terhadap huruf besar/kecil.
>
>     -   `str_detect(...)`: Fungsi ini memeriksa apakah sebuah teks mengandung pola tertentu.
>
>     -   `"kos|asrama|rusunawa"`: Ini adalah polanya. Tanda `|` berarti "ATAU". Jadi, fungsi ini mencari kata "kos" ATAU "asrama" ATAU "rusunawa".
>
>     -   `~ "Kos/Asrama"`: Jika salah satu kata kunci ditemukan, maka nilai untuk kolom `tipe_tinggal_baku` adalah "Kos/Asrama".
>
> -   **Aturan kedua**: `TRUE ~ "Rumah Keluarga/Pribadi"`
>
>     -   `TRUE`: Ini adalah kondisi "penampung" atau *default*. Jika tidak ada kondisi sebelumnya yang terpenuhi, aturan ini akan dijalankan.
>
>     -   `~ "Rumah Keluarga/Pribadi"`: Memberi nilai "Rumah Keluarga/Pribadi" untuk semua baris yang tidak cocok dengan aturan pertama.
>
> Singkatnya, kode ini membakukan data `jenis_tinggal` yang bervariasi menjadi dua kategori yang bersih dan konsisten untuk analisis proporsi.

Pada tahap ini, kita menganggap data gabungan dari 1.206 mahasiswa sebagai **"populasi"** kita untuk tujuan simulasi.

## Distribusi *Sampling* dan *Standard Error*

Distribusi *sampling* adalah distribusi dari suatu statistik (misalnya, rata-rata) yang dihitung dari semua kemungkinan sampel dengan ukuran yang sama yang diambil dari sebuah populasi. Ini adalah istilah lain dari **distribusi statistik sampel**.

Teorema Limit Pusat (*Central Limit Theorem*) menyatakan bahwa jika kita mengambil sampel yang cukup besar, distribusi *sampling* dari rata-rata akan mendekati distribusi normal.

### Mendefinisikan Parameter Populasi

Pertama, mari kita hitung rata-rata dan standar deviasi "populasi" kita sebagai acuan.

```{r mean-sd-parameter}
# Menghitung rata-rata jarak "populasi"
pop_mean <- mean(data_mahasiswa$jarak_km)
# Menghitung standar deviasi jarak "populasi"
pop_sd <- sd(data_mahasiswa$jarak_km)

paste("Rata-rata Jarak Populasi (Î¼):", round(pop_mean, 2), "km")
paste("Standar Deviasi Populasi (Ïƒ):", round(pop_sd, 2), "km")
```

### Simulasi Pengambilan Sampel

Sekarang, kita akan mensimulasikan proses pengambilan sampel secara berulang. Kita akan mengambil 1000 sampel acak, masing-masing berukuran 50 mahasiswa (`n=50`), lalu menghitung rata-rata jarak untuk setiap sampel.

```{r simulasi-sampling}
# Menetapkan parameter simulasi
ukuran_sampel <- 50
jumlah_simulasi <- 1000

# Menjalankan simulasi
set.seed(123) # Untuk hasil yang dapat direproduksi. Silakan ganti seed sesuai keinginan Anda.
# 'replicate' akan menjalankan ekspresi kedua sebanyak 'jumlah_simulasi' kali
rataan_sampel <- replicate(jumlah_simulasi, {
  sampel_jarak <- sample(data_mahasiswa$jarak_km, ukuran_sampel)
  mean(sampel_jarak)
})

# Membuat dataframe dari hasil simulasi
df_sampling <- data.frame(rataan_sampel)
head(df_sampling)
```

::: {.rmdexercise}
**Aktivitas Mandiri 1: Simulasi dengan Parameter Berbeda [STP-4.3]**

Modifikasi kode simulasi di atas:
1. Ubah `ukuran_sampel` menjadi 30 (dari 50)
2. Ubah `jumlah_simulasi` menjadi 500 (dari 1000)
3. Hitung ulang SE empiris dan teoritis
4. Buat histogram distribusi sampling yang baru
5. Bandingkan:
   - Bagaimana bentuk distribusi berubah dengan n=30 vs n=50?
   - Apakah SE empiris dan teoritis masih dekat?
:::

### Visualisasi Distribusi Sampling

Kumpulan dari 1000 rata-rata sampel inilah yang membentuk **distribusi sampling**. Mari kita visualisasikan dalam bentuk histogram.

```{r visualisasi-simulasi}
# Visualisasi Distribusi Sampling dengan Histogram
ggplot(df_sampling, aes(x = rataan_sampel)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  geom_density(color = "red", size = 1) +
  geom_vline(xintercept = pop_mean, color = "blue", linetype = "dashed", size = 1.2) +
  labs(
    title = "Distribusi Sampling dari Rata-rata Jarak Tempuh",
    subtitle = paste("Ukuran Sampel (n) =", ukuran_sampel, "| Jumlah Simulasi =", jumlah_simulasi),
    x = "Rata-rata Jarak Sampel (km)",
    y = "Densitas"
  ) +
  annotate("text", x = pop_mean * 1.1, y = 0.1, label = paste("Î¼ =", round(pop_mean, 2)), color = "blue") +
  theme_minimal()

```

Perhatikan bagaimana distribusi dari rata-rata sampel berbentuk seperti lonceng (mendekati normal) dan berpusat di sekitar rata-rata populasi (garis biru putus-putus).

### Menghitung *Standard Error* (SE)

*Standard Error* (SE) adalah standar deviasi dari distribusi sampling. Ini mengukur seberapa besar variasi rata-rata sampel di sekitar rata-rata populasi. SE dapat dipahami dari dua perspektif: satu dari sisi teori dalam simulasi, dan satu lagi dari sisi praktik ketika kita hanya memiliki satu sampel.

1.  **Empiris (dari simulasi)**: Menghitung standar deviasi dari 1000 rata-rata sampel yang kita hasilkan.

2.  **Teoritis (dari populasi)**: Menggunakan rumus $SE=\frac{\sigma}{\sqrt{n}}$, di mana $Ïƒ$ adalah standar deviasi populasi dan $n$ adalah ukuran sampel.

3.  **Estimasi (dari sampel)**: Dalam praktik statistika inferensial, kita hampir tidak pernah mengetahui . Oleh karena itu, kita mengestimasinya menggunakan standar deviasi dari sampel kita sendiri (s). Rumusnya menjadi $SE=\frac{s}{\sqrt{n}}$. **Inilah nilai yang sebenarnya digunakan saat kita membuat interval kepercayaan atau melakukan uji hipotesis dari data sampel nyata.**

```{r standard-error}
# 1. Standard Error Empiris (dari 1000 sampel)
se_empiris <- sd(df_sampling$rataan_sampel)

# 2. Standard Error Teoritis (menggunakan info populasi)
se_teoritis <- pop_sd / sqrt(ukuran_sampel)

paste("Standard Error (Empiris, dari simulasi):", round(se_empiris, 3))
paste("Standard Error (Teoritis, dari populasi):", round(se_teoritis, 3))
```

Mari kita hitung estimasi standard error dari satu sampel acak yang akan kita gunakan nanti di Bagian 4.5.

```{r standar-error-dari-sampel}
# Mengambil satu sampel acak (sama seperti di Bagian 4.1)
set.seed(42)
sampel_tunggal_untuk_se <- sample(data_mahasiswa$jarak_km, ukuran_sampel)
sd_sampel_tunggal <- sd(sampel_tunggal_untuk_se)

# 3. Estimasi Standard Error (dari satu sampel, kasus nyata)
se_estimasi <- sd_sampel_tunggal / sqrt(ukuran_sampel)
paste("Estimasi Standard Error (dari satu sampel):", round(se_estimasi, 3))
```

Perhatikan bahwa nilai SE Empiris dan Teoritis sangat dekat karena berasal dari simulasi di mana parameter populasi diketahui. Nilai SE Estimasi akan bervariasi tergantung sampel mana yang kita ambil, namun nilai inilah yang paling realistis untuk digunakan dalam analisis nyata.

## Estimasi Parameter-1: Interval Kepercayaan Rata-rata

Untuk bagian ini kita akan menggunakan *library* bernama `MKinfer`yang berguna untuk menghasilkan interval kepercayaan sebagai estimasi rentang.

Lakukan instalasi *library* ini dengan perintah berikut.

```{r instalasi-MKinfer, eval=FALSE}
install.packages("MKinfer")
```

Kemudian muat paket `MKinfer` tersebut.

```{r muat-MKinfer}
library(MKinfer)
```

### Mengambil Satu Sampel

```{r mean-sd-sampel-tunggal}
# Kita gunakan sampel yang sudah dibuat sebelumnya
sampel_tunggal <- sampel_tunggal_untuk_se
mean_sampel_tunggal <- mean(sampel_tunggal)

cat(paste("Rata-rata Sampel Tunggal:", round(mean_sampel_tunggal, 2), "km\n"))
cat(paste("Standar Deviasi Sampel Tunggal:", round(sd_sampel_tunggal, 2), "km\n"))
```

### Menghasilkan Interval Kepercayaan

```{r interval-kepercayaan-rata2}
# Menghitung interval kepercayaan 95% menggunakan MKinfer
hasil_ci_mean <- meanCI(sampel_tunggal, conf.level = 0.95)

# Menampilkan hasil
hasil_ci_mean
```

Hasil dari fungsi `meanCI` tersebut langsung menunjukkan rentang kepercayaan yang limit bawahnya ditunjukkan oleh angka di bawah `2.5%`dan limit atasnya oleh angka di bawah `97.5%`. Nilai-nilai ini adalah nilai $\alpha/2$ yang dibagi dua ke kiri dan kanan grafik.

**Pertanyaan**

Berapakah rentang kepercayaan untuk rata-rata jarak tempat tinggal dari kampus dari sampel kita? Tuliskan interpretasinya yang tepat. Bandingkan dengan rata-rata parameter

```{r pertanyaan-ci-mean}
# Jawablah pertanyaan di atas dengan menuliskannya sebagai komentar di chunk ini
# Rentang kepercayaannya adalah 2,81 - 3,95 km

# Apa interpretasi dari hasil ini?
# Rata-rata jarak dari kampus untuk tempat tinggal seluruh mahasiswa berada di rentang 2,81 - 3,95 km. Jika dibandingkan dengan rata-rata populasi, rata-rata populasi ternyata masuk di rentang ini.
pop_mean
```

## Estimasi Parameter-2: Interval Kepercayaan Proporsi

Selain rata-rata, kita juga sering tertarik untuk mengestimasi proporsi dari suatu kategori dalam populasi. Contohnya, berapa persentase mahasiswa yang tinggal di kos/asrama? Prosesnya mirip: kita mengambil sampel, menghitung proporsi sampel, lalu membangun interval kepercayaan di sekitar proporsi tersebut.

### Parameter Proporsi

Pertama, mari kita hitung proporsi "populasi" yang sebenarnya dari data kita. Kita akan mencari proporsi mahasiswa yang tinggal di "Kos/Asrama".

```{r parameter-proporsi}
# Menghitung proporsi populasi
tabel_populasi <- table(data_mahasiswa$tipe_tinggal_baku)
pop_prop <- prop.table(tabel_populasi)["Kos/Asrama"]

cat("Tabel Frekuensi Jenis Tinggal di Populasi:\n")
print(tabel_populasi)
cat(paste("\nProporsi Mahasiswa di Kos/Asrama (p):", round(pop_prop, 4)))
```

### Mengambil Satu Sampel dan Menghitung Proporsinya

Sekarang, kita ambil satu sampel acak (misalnya, `n=100`) dan hitung proporsi sampel $\hat{p}$ mahasiswa yang tinggal di kos/asrama.

```{r statistik-proporsi}
# Menetapkan ukuran sampel
ukuran_sampel_prop <- 100

# Mengambil sampel acak dari kolom tipe tinggal
set.seed(101) # Menggunakan seed baru
sampel_prop <- sample(data_mahasiswa$tipe_tinggal_baku, ukuran_sampel_prop)

# Menghitung frekuensi di dalam sampel
tabel_sampel <- table(sampel_prop)
# Menghitung proporsi sampel
prop_sampel <- prop.table(tabel_sampel)["Kos/Asrama"]

cat("Tabel Frekuensi Jenis Tinggal di Sampel:\n")
print(tabel_sampel)
cat(paste("\nProporsi Sampel Mahasiswa di Kos/Asrama (p-hat):", round(prop_sampel, 4)))
```

### Menghasilkan Interval Kepercayaan untuk Proporsi

Kita akan menggunakan fungsi `binomCI()` di R. Fungsi ini memerlukan jumlah "sukses", yakni jumlah mahasiswa di kos/asrama, dan total ukuran sampel.

```{r estimasi-proporsi}
# Mendapatkan jumlah "sukses" dari tabel sampel
jumlah_sukses <- tabel_sampel["Kos/Asrama"]
total_sampel <- ukuran_sampel_prop

# Menghitung interval kepercayaan 95% untuk proporsi
hasil_prop_test <- binomCI(jumlah_sukses, total_sampel, conf.level = 0.95)
# Menampilkan hasil
print(hasil_prop_test)
```

**Pertanyaan**

Berapakah rentang kepercayaan untuk proporsi mahasiswa yang tinggal di kos/asrama? Tuliskan interpretasinya yang tepat. Bandingkan dengan proporsi parameter.

```{r pertanyaan-ci-prop}
# Jawablah pertanyaan di atas dengan menuliskannya sebagai komentar di chunk ini  # Rentang kepercayaannya adalah 0,37 hingga 0,56

# Tuliskan interpretasi dari rentang tersebut
# Tidak banyak mahasiswa yang tinggal di kos/asrama, karena rentang kepercayaan parameter proporsi mahasiswa yang tinggal di kos/asrama adalah 37% hingga 56% saja.
```

::: {.rmdexercise}
**Aktivitas Mandiri 2: Interval Kepercayaan 99% [STP-5.2]**

Untuk proporsi mahasiswa di Kos/Asrama:
1. Hitung interval kepercayaan 99% (`conf.level = 0.99`)
2. Bandingkan dengan hasil 95%
3. Mana yang lebih lebar? Mengapa?

Untuk rata-rata jarak:
1. Ambil sampel baru dengan `ukuran_sampel = 75`
2. Hitung CI 90%
3. Interpretasikan hasilnya
:::

::: {.rmdexercise}
**Aktivitas Mandiri 3: Interval Kepercayaan 97% [STP-4.3, STP-5.2]**

**Petunjuk:** Gunakan `conf.level = 0.97`

1. **Rata-rata Jarak:**
   - Hitung CI 97% untuk rata-rata jarak
   - Interpretasi: "Kita 97% yakin bahwa rata-rata jarak populasi berada di rentang..."

2. **Proporsi Penghuni Kos/Asrama:**
   - Hitung CI 97% untuk proporsi
   
3. **Analisis Perbandingan:**
   - Bandingkan CI 97%, 95%, dan 90%
   - Jelaskan trade-off antara lebar interval dan tingkat kepercayaan
:::

------------------------------------------------------------------------




<!--chapter:end:04-distribusi-statistik-interval-kepercayaan.Rmd-->

# Modul-5: Uji Hipotesis

Setelah mempelajari modul ini, Anda diharapkan dapat:

1. mampu menghasilkan uji hipotesis satu populasi dengan menggunakan perangkat lunak komputer [STP-6.2]{.capaian}
2. mampu menghasilkan uji hipotesis dua atau lebih populasi pada suatu kasus menggunakan perangkat lunak komputer [STP-7.2]{.capaian}


---

## Pendahuluan

Uji hipotesis adalah salah satu teknik dalam analisis statistik inferensial yang memperkirakan parameter melalui pernyataan-pernyataan dugaan atau **hipotesis**. Hipotesis di sini adalah pernyataan yang mengandung dugaan bahwa nilai parameter adalah sama dengan suatu nilai atau berbeda. Hipotesis yang sama dengan suatu nilai kita sebut dengan **hipotesis kosong *(null hypothesis)***, sementara yang berbeda disebut **hipotesis alternatif *(alternative hypothesis)***

## Perangkat Lunak dan Pustaka (Libraries)

Seperti biasa, kita perlu memuat pustaka *(libraries)* yang diperlukan dalam pengolahan data kita.

Dalam modul ini kita akan menggunakan sebuah pustaka bernama `stats` yang merupakan pustaka khusus untuk perhitungan-perhitungan statistik dan juga penghasil angka acak.

```{r}
library(tidyverse)
library(readr)
library(stats)
```

Biasanya pustaka `stats` sudah termuat secara bawaan *(default)* saat kita menjalankan R melalui RStudio. Untuk mengecek apakah suatu pustaka sudah termuat ketika kita menjalankan R, tulis perintah berikut.

``` r
"package:{nama pustaka}" %in% search() # ganti {nama pustaka} dengan nama pustaka yang ingin dicari

"package: stats" %in% search() # untuk mengecek apakah 'stats' sudah dimuat
```

## Memuat Data

``` r
data_mahasiswa <- read_csv2("data_mahasiswa.csv")
# read_csv2() â†’ untuk file CSV dgn pemisah titik koma (;)
# read_csv() â†’ untuk file CSV dgn pemisah koma (,).
```

```{r}
data_mahasiswa <- read_csv2("datasets/data_mahasiswa.csv") 
```

## Perkenalan Markdown: LaTeX

Dalam file Markdown terdapat fitur bahasa LaTeX. Bahasa ini digunakan untuk menulis simbol matematis.

Untuk menyisipkan persamaan matematis menggunakan LaTeX, kita dapat menggunakan perintah Insert \> LaTeX Math \> Inline Math/Display Math. Inline Math akan menyisipkan simbol matematis di dalam paragraf, sementara Display Math membuat persamaan di bagian terpisah dari paragraf.

Dalam mode Source, Inline Math disisipkan dengan mengetikkan `$$` terlebih dahulu dan menuliskan simbolnya di antara dua `$` tersebut. Sementara itu, untuk Display Math kita perlu mengetikkan empat buah tanda `$` sehingga terlihat seperti berikut.

``` markdown
$$
H_0 : \mu_0 = 4
\newline H_1 : \mu_0 \ne 4
$$
```

Hasilnya adalah seperti berikut:

$$
H_0 : \mu_0 = 4\newline H_1 : \mu_0 \ne 4
$$

Anda dapat mempelajari penulisan LaTeX selengkapnya [di sini](https://www.overleaf.com/learn/latex/Mathematical_expressions#Further_reading "https://www.overleaf.com/learn/latex/Mathematical_expressions#Further_reading").

## Uji Hipotesis Satu Populasi

Pengujian hipotesis satu populasi bermakna pengujian hipotesis untuk suatu parameter yang berasal dari satu buah populasi saja. Misalnya, dalam kasus modul ini, kita memiliki populasi berupa seluruh mahasiswa yang berkuliah di Kota Bandar Lampung dan sekitarnya.

Dalam uji hipotesis satu populasi, kita hanya berfokus pada satu kelompok data, dan ingin mengetahui apakah parameter populasi sama dengan nilai tertentu atau tidak. Nilai acuan ini biasanya berasal dari teori, standar, atau dugaan awal. Ada dua jenis parameter yang bisa diuji:

**Rata-rata** (Âµ) â†’ misalnya, apakah rata-rata jarak mahasiswa ke kampus = 4 km?

**Proporsi** (p) â†’ misalnya, apakah proporsi mahasiswa yang tinggal di kos/asrama = 50%?

Prinsipnya sama: kita rumuskan hipotesis nol (H0), tentukan hipotesis alternatif (H1), hitung statistik uji (Z atau t), tentukan daerah kritis, lalu disimpulkan.

Penjelasan lebih lanjut akan dibahas dalam subbab-subbab berikut.

### Rata-rata

Dalam kasus ini, kita akan menguji hipotesis parameter rata-rata berupa jarak mahasiswa yang berkuliah di universitas-universitas di Kota Bandar Lampung dan sekitarnya. Berdasarkan `data_mahasiswa` , kita dapat menghitung rata-rata statistik jarak mahasiswa yang menjadi responden. Rata-rata statistik jarak tersebut kita gunakan untuk menguji hipotesis parameter rata-rata dengan suatu nilai.

Jika dimisalkan suatu nilai tersebut adalah 4 km, maka hipotesis yang diujinya menjadi "rata-rata jarak tempat tinggal mahasiswa ke kampusnya masing-masing di Kota Bandar Lampung dan sekitarnya adalah 4 km." Ini disebut **hipotesis kosong**, karena memuat kesamaan terhadap suatu nilai. Sementara itu, lawannya, yakni **hipotesis alternatif**, akan dibahas di masing-masing bagian.

**Membuat fungsi perhitungan statistik uji**

Pertama, mari kita buat sebuah fungsi di R untuk menghitung nilai statistik uji. Dengan adanya fungsi ini, kita tidak perlu lagi melakukan perhitungan manual setiap kali menguji hipotesis. Fungsi ini akan menerima masukan berupa rata-rata sampel, rata-rata hipotesis, simpangan baku, dan ukuran sampel, kemudian menghasilkan nilai statistik uji Z.



```{r membuat-fungsi-mean1pop}
# Membuat fungsi uji hipotesis (hypothesis testing, ht) untuk rata-rata (mean)
# dengan 1 populasi (1pop)
# Keterangan input:
#   - xbar : statistik rata-rata
#   - mu   : parameter rata-rata
#   - sd   : statistik simpangan baku
#   - n    : ukuran sampel
ht_mean_1pop <- function(xbar, mu, sd, n) {
  se <- sd/sqrt(n) # menghitung standard error untuk rata-rata
  Z_hitung <- (xbar - mu)/se # menghitung nilai Z dari statistik
  return(Z_hitung)
}
```

**Mendeklarasikan variabel uji**

Setelah fungsi dibuat, kita deklarasikan variabel-variabel yang akan digunakan. Variabel-variabel ini akan dipakai langsung sebagai input fungsi uji hipotesis. Dengan mendeklarasikannya lebih dulu, kita memastikan semua nilai yang diperlukan untuk perhitungan sudah tersedia dengan jelas dan proses penghitungan menjadi lebih rapi.



```{r mendeklarasikan-variabel-uji-mean1pop}
# Mendeklarasikan variabel-variabel yang akan diuji
sample_mean <- mean(data_mahasiswa$jarak_km) # artinya menghitung rata-rata dari kolom jarak_km pada data data_mahasiswa.
pop_mean <- 4.0 # ini nilai hipotesis Î¼â‚€ yang ingin diuji.
sample_sd <- sd(data_mahasiswa$jarak_km)
# Menghasilkan data frame ringkasan dataset dengan menghitung jumlah mahasiswa sebagai ukuran sampel
ukuran_sampel <- data_mahasiswa |>  # "|>" disebut pipe operator, fungsinya untuk meneruskan hasil dari suatu ekspresi ke fungsi berikutnya (bisa pakai shortcut : Ctrl + Shift + M).
  summarize(ukuran_sampel = n())
# Menyimpan angka jumlah mahasiswa sebagai variabel n
ukuran_sampel <- ukuran_sampel$ukuran_sampel # mengekstrak angka dari tabel menjadi nilai tunggal (scalar) agar bisa dipakai dalam perhitungan berikutnya.

# Menampilkan variabel-variabel yang akan diuji
cat("Rata-rata jarak sampel adalah", sample_mean, "km.", 
    "\nParameter rata-rata jarak yang diuji adalah", pop_mean, "km.",
    "\nSimpangan baku jarak sampel adalah", sample_sd, "km.",
    "\nUkuran sampel adalah", ukuran_sampel, "orang.")
```

### Memahami Distribusi Normal dan Area Kritis
Dalam uji hipotesis, kita menggunakan distribusi normal standar (kurva Z) untuk menentukan apakah statistik uji kita jatuh pada area "tidak biasa" (area kritis/penolakan) atau area "biasa" (area penerimaan Hâ‚€).

#### Visualisasi Two-Tailed Test (Î± = 0.05)

Untuk memahami konsep area kritis, perhatikan Gambar \@ref(fig:dist-normal-two-tailed). Gambar tersebut menunjukkan bahwa untuk uji two-tailed dengan Î± = 0.05, area kritis terbagi menjadi dua bagian (masing-masing 2.5%) di kedua ekor distribusi.

```{r dist-normal-two-tailed, echo=FALSE, fig.cap='Distribusi Normal dengan Area Kritis Two-Tailed (Î± = 0.05)', fig.align='center', fig.width=8, fig.height=5}
library(ggplot2)
# Data untuk kurva normal
x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)
df_normal <- data.frame(x = x, y = y)
# Z kritis untuk alpha = 0.05 two-tailed
z_kritis <- qnorm(0.975)  # 1.96
ggplot(df_normal, aes(x = x, y = y)) +
  # Kurva normal
  geom_line(size = 1, color = "darkblue") +
  
  # Area penerimaan H0 (tengah)
  geom_area(data = subset(df_normal, x >= -z_kritis & x <= z_kritis),
            aes(x = x, y = y), fill = "lightblue", alpha = 0.5) +
  
  # Area kritis kiri
  geom_area(data = subset(df_normal, x <= -z_kritis),
            aes(x = x, y = y), fill = "red", alpha = 0.3) +
  
  # Area kritis kanan
  geom_area(data = subset(df_normal, x >= z_kritis),
            aes(x = x, y = y), fill = "red", alpha = 0.3) +
  
  # Garis vertikal untuk Z kritis
  geom_vline(xintercept = c(-z_kritis, z_kritis), 
             linetype = "dashed", color = "red", size = 0.8) +
  
  # Anotasi
  annotate("text", x = -z_kritis, y = -0.02, 
           label = paste("-", round(z_kritis, 2)), size = 4, color = "red") +
  annotate("text", x = z_kritis, y = -0.02, 
           label = paste("+", round(z_kritis, 2)), size = 4, color = "red") +
  annotate("text", x = -2.7, y = 0.05, 
           label = "Area Kritis\n(2.5%)", size = 3.5, color = "darkred") +
  annotate("text", x = 2.7, y = 0.05, 
           label = "Area Kritis\n(2.5%)", size = 3.5, color = "darkred") +
  annotate("text", x = 0, y = 0.2, 
           label = "Area Penerimaan Hâ‚€\n(95%)", size = 4, color = "darkblue") +
  
  # Tema
  labs(title = "Distribusi Normal Standar: Two-Tailed Test (Î± = 0.05)",
       x = "Nilai Z",
       y = "Densitas") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

**Penjelasan:**

- Area biru (tengah): Area penerimaan Hâ‚€ sebesar 95%
- Area merah (kiri & kanan): Area kritis total 5% (2.5% + 2.5%)
- Jika |Z hitung| > 1.96 â†’ Tolak Hâ‚€ (jatuh di area merah)
- Fungsi `qnorm(0.025)` = -1.96 dan `qnorm(0.975)` = +1.96

#### Visualisasi Left-Tailed Test (Î± = 0.05)

```{r dist-normal-left-tailed, echo=FALSE, fig.cap='Distribusi Normal dengan Area Kritis Left-Tailed (Î± = 0.05)', fig.align='center', fig.width=8, fig.height=5}
# Z kritis untuk left-tailed
z_kritis_left <- qnorm(0.05)  # -1.64
ggplot(df_normal, aes(x = x, y = y)) +
  geom_line(size = 1, color = "darkblue") +
  
  # Area penerimaan H0 (kanan)
  geom_area(data = subset(df_normal, x >= z_kritis_left),
            aes(x = x, y = y), fill = "lightblue", alpha = 0.5) +
  
  # Area kritis kiri
  geom_area(data = subset(df_normal, x <= z_kritis_left),
            aes(x = x, y = y), fill = "red", alpha = 0.3) +
  
  # Garis vertikal
  geom_vline(xintercept = z_kritis_left, 
             linetype = "dashed", color = "red", size = 0.8) +
  
  # Anotasi
  annotate("text", x = z_kritis_left, y = -0.02, 
           label = round(z_kritis_left, 2), size = 4, color = "red") +
  annotate("text", x = -2.5, y = 0.05, 
           label = "Area Kritis\n(5%)", size = 3.5, color = "darkred") +
  annotate("text", x = 1, y = 0.2, 
           label = "Area Penerimaan Hâ‚€\n(95%)", size = 4, color = "darkblue") +
  
  labs(title = "Distribusi Normal Standar: Left-Tailed Test (Î± = 0.05)",
       x = "Nilai Z",
       y = "Densitas") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```
**Catatan:** Untuk left-tailed test, seluruh Î± (5%) berada di ekor kiri. Z kritis = `qnorm(0.05)` = -1.64

#### Visualisasi Right-Tailed Test (Î± = 0.05)

```{r dist-normal-right-tailed, echo=FALSE, fig.cap='Distribusi Normal dengan Area Kritis Right-Tailed (Î± = 0.05)', fig.align='center', fig.width=8, fig.height=5}
# Z kritis untuk right-tailed
z_kritis_right <- qnorm(0.95)  # 1.64
ggplot(df_normal, aes(x = x, y = y)) +
  geom_line(size = 1, color = "darkblue") +
  
  # Area penerimaan H0 (kiri)
  geom_area(data = subset(df_normal, x <= z_kritis_right),
            aes(x = x, y = y), fill = "lightblue", alpha = 0.5) +
  
  # Area kritis kanan
  geom_area(data = subset(df_normal, x >= z_kritis_right),
            aes(x = x, y = y), fill = "red", alpha = 0.3) +
  
  # Garis vertikal
  geom_vline(xintercept = z_kritis_right, 
             linetype = "dashed", color = "red", size = 0.8) +
  
  # Anotasi
  annotate("text", x = z_kritis_right, y = -0.02, 
           label = paste("+", round(z_kritis_right, 2)), size = 4, color = "red") +
  annotate("text", x = 2.5, y = 0.05, 
           label = "Area Kritis\n(5%)", size = 3.5, color = "darkred") +
  annotate("text", x = -1, y = 0.2, 
           label = "Area Penerimaan Hâ‚€\n(95%)", size = 4, color = "darkblue") +
  
  labs(title = "Distribusi Normal Standar: Right-Tailed Test (Î± = 0.05)",
       x = "Nilai Z",
       y = "Densitas") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

**Catatan:** Untuk right-tailed test, seluruh Î± (5%) berada di ekor kanan. Z kritis = `qnorm(0.95)` = 1.64

#### Hubungan dengan Fungsi `qnorm()`
Tiga visualisasi di atas menunjukkan bagaimana fungsi `qnorm()` bekerja:

- **Two-tailed:** `qnorm(alpha/2)` dan `qnorm(1 - alpha/2)` â†’ Â±1.96
- **Left-tailed:** `qnorm(alpha)` â†’ -1.64
- **Right-tailed:** `qnorm(1 - alpha)` â†’ +1.64

**Interpretasi Keputusan:**
- Jika Z hitung jatuh di area merah â†’ **Tolak Hâ‚€**
- Jika Z hitung jatuh di area biru â†’ **Gagal tolak Hâ‚€**

#### *Two-tailed Test* (Tidak Berarah)

Uji dua arah (two-tailed test) adalah salah satu bentuk pengujian hipotesis statistik yang digunakan ketika peneliti ingin mengetahui apakah nilai rata-rata populasi berbeda secara signifikan dari suatu nilai tertentu (nilai hipotesis, biasanya dilambangkan Î¼â‚€), tanpa memandang arah perbedaan tersebut. Artinya, kita tidak hanya mempertanyakan apakah rata-rata lebih besar atau lebih kecil, tetapi fokus pada apakah terdapat perbedaan yang cukup signifikan ke salah satu arah. Dalam uji ini, kita ingin mengetahui apakah rata-rata jarak tempuh mahasiswa menuju kampus berbeda secara signifikan dari 4 km, tanpa menentukan apakah lebih besar atau lebih kecil.

##### Merumuskan hipotesis

Langkah pertama adalah merumuskan hipotesis. Di sini kita mendefinisikan dua kemungkinan: hipotesis nol (H0) dan hipotesis alternatif (H1). H0 biasanya menyatakan bahwa â€œtidak ada perbedaanâ€ atau â€œnilai parameter sama dengan nilai tertentuâ€. Sebaliknya, H1 menyatakan adanya perbedaan yang signifikan. Pada uji ini, Hipotesis nol menyatakan bahwa rata-rata sama dengan 4 km, sedangkan hipotesis alternatif menyatakan bahwa rata-rata tidak sama dengan 4 km. Dengan demikian, kita sedang menguji apakah terdapat perbedaan nyata dari nilai acuan tersebut.



```{r merumuskan-hipotesis-mean1poptt}
cat("H0 : rata-rata jarak = 4 km", # fungsi "cat()" digunakan untuk mecetak teks ke console dengan format yang bisa kita atur sendiri.
    "\n\nH1 : rata-rata jarak != 4 km") # "!=" berarti "tidak sama dengan" (menandakan uji dua sisi).
```

##### Memilih distribusi *sampling*, wilayah dan titik kritis

Setelah hipotesis dirumuskan, kita perlu menentukan distribusi sampling dan titik kritis. Distribusi sampling adalah distribusi dari nilai rata-rata sampel jika kita mengambil banyak sampel dari populasi. Titik kritis adalah nilai ambang yang menentukan wilayah penolakan hipotesis nol. Dalam uji dua arah, daerah kritis terletak di kedua ujung distribusi normal dengan luas masing-masing sebesar Î±/2. Misalnya, dengan Î± = 0,05, maka masing-masing sisi memiliki 0,025. Artinya, hanya jika nilai uji berada jauh di salah satu sisi, kita akan menolak H0.



```{r memilih-distribusi-sampling-wil-titik-kritis-mean1poptt}
# Hipotesis yang dipakai tidak berarah, maka wilayah kritis adalah alpha/2
alpha <- 0.05
Z.crit_2tail <- abs(qnorm(alpha/2)) # Nilai yang digunakan adalah nilai absolut, karena dibagi 2, tanda tidak berpengaruh

cat("Titik kritis uji two-tailed:",Z.crit_2tail)
```

##### Menghitung statistik uji

Setelah menentukan titik kritis, kita menghitung nilai statistik uji menggunakan data yang kita miliki. Nilai ini menunjukkan seberapa jauh rata-rata sampel menyimpang dari nilai hipotesis populasi, dalam satuan standar error. Jika nilai ini berada di luar batas kritis, maka penyimpangan tersebut dianggap terlalu besar untuk hanya terjadi karena kebetulan.



```{r menghitung-stat-uji-mean1poptt}
# hasil perhitungan statistik uji diabsolutkan untuk mengambil nilainya saja tanpa tandanya
Z_meanJarak <- abs(ht_mean_1pop(sample_mean, pop_mean, sample_sd, ukuran_sampel))

cat("Hasil statistik uji rata-rata:", Z_meanJarak)
```

##### Menarik kesimpulan

Langkah terakhir adalah menarik kesimpulan berdasarkan perbandingan antara nilai statistik uji dan titik kritis. Jika nilai statistik uji (absolut) lebih kecil dari titik kritis, maka kita gagal menolak Hâ‚€, artinya perbedaan yang terlihat kemungkinan hanya kebetulan sampel. Jika lebih besar atau sama, kita menolak Hâ‚€, artinya ada bukti yang cukup bahwa rata-rata jarak tidak sama dengan 4.



```{r menarik-kesimpulan-mean1poptt}
if (Z_meanJarak < Z.crit_2tail) {
  tolak_h0 <- FALSE
  cat("Hipotesis kosong gagal ditolak. Perbedaan rata-rata sampel", round(sample_mean, 2), "dengan", pop_mean, "hanyalah kebetulan")
} else {
  tolak_h0 <- TRUE  
  cat("Hipotesis kosong ditolak. Rata-rata jarak pada sampel mahasiswa sebesar", round(sample_mean, 2), "km menunjukkan perbedaan yang signifikan")
}
```

#### *One-tailed Test* (Berarah)

Uji satu arah (one-tailed test) digunakan ketika kita memiliki dugaan arah perbedaan. Misalnya, kita ingin tahu apakah rata-rata sampel lebih kecil dari 4 km, bukan sekadar berbeda. Dalam konteks ini, daerah kritis hanya berada di salah satu sisi distribusi. Uji satu arah biasanya lebih sensitif karena semua probabilitas Î± ditempatkan di satu sisi, sehingga lebih mudah untuk mendeteksi perbedaan yang sesuai dengan arah hipotesis alternatif.

##### Merumuskan Hipotesis

Untuk uji satu arah, hipotesis alternatif ditentukan dengan arah tertentu. Misalnya, jika kita menduga rata-rata jarak lebih kecil dari 4 km, maka:



Dengan cara ini, kita hanya akan menolak H0 jika bukti menunjukkan bahwa rata-rata memang lebih kecil. Jika ternyata rata-rata lebih besar, maka hal itu tidak mendukung H1.

```{r merumuskan-hipotesis-mean1popot}
cat("H0 : rata-rata jarak = 4 km",
    "\n\nH1 : rata-rata jarak < 4 km")
```

##### Memilih distribusi sampling, wilayah, serta titik kritis

Karena hipotesis alternatif hanya mengarah ke satu sisi, maka daerah kritis hanya ditetapkan di sisi kiri atau kanan distribusi normal. Jika H1 menyatakan rata-rata lebih kecil, maka titik kritis ditentukan pada sisi kiri. Sebaliknya, jika H1 menyatakan rata-rata lebih besar, maka titik kritis ada di sisi kanan. Dengan Î± = 0,05, seluruh probabilitas kesalahan ditempatkan di satu sisi distribusi.



```{r memilih-distribusi-sampling-wil-titik-kritis-mean1popot}
tail <- "kiri" # H1 menyatakan lebih kecil dari (left-tailed)

if (tail == "kiri") {
  Z.crit_1tail <- qnorm(alpha)
} else {
  Z.crit_1tail <- qnorm(1-alpha)
}

cat("Titik kritis uji one-tailed:", Z.crit_1tail)
```

##### Menghitung statistik uji

Setelah titik kritis ditentukan, kita menghitung nilai statistik uji. Pada uji satu arah, tanda dari nilai Z menjadi sangat penting. Hal ini karena nilai negatif atau positif menunjukkan arah penyimpangan rata-rata sampel dari nilai populasi.



```{r menghitung-stat-uji-mean1popot}
# Hasil perhitungan statistik uji TIDAK diabsolutkan
Z_meanJarak <- ht_mean_1pop(sample_mean, pop_mean, sample_sd, ukuran_sampel)

cat("Hasil statistik uji rata-rata:", Z_meanJarak)
```

##### Menarik kesimpulan

Langkah terakhir adalah membandingkan nilai statistik uji dengan titik kritis. Jika nilai uji lebih kecil dari titik kritis atau jatuh ke dalam daerah kritis, maka H0 ditolak, artinya perbedaan rata-rata kemungkinan hanyalah kebetulan. Sebaliknya, jika nilai uji lebih besar, maka H0 gagal ditolak yang berarti tidak ada bukti cukup untuk menyatakan adanya perbedaan.



```{r menarik-kesimpulan-mean1popot}
if (Z_meanJarak < Z.crit_1tail) {
  tolak_h0 <- TRUE
  cat("Hipotesis kosong ditolak. Rata-rata jarak pada sampel mahasiswa sebesar", round(sample_mean, 2), "km menunjukkan perbedaan yang signifikan (lebih kecil)")
} else {
  tolak_h0 <- FALSE  
  cat("Hipotesis kosong gagal ditolak. Perbedaan rata-rata sampel dengan populasi hanyalah kebetulan")
}
```

### Proporsi

Proporsi adalah perbandingan jumlah elemen yang memenuhi suatu kriteria terhadap jumlah total. Misalnya, dalam kasus mahasiswa, kita bisa melihat proporsi mahasiswa yang tinggal di kos/asrama dibandingkan dengan seluruh mahasiswa dalam sampel.

Pengujian proporsi bermanfaat ketika kita ingin menguji apakah proporsi sampel yang kita peroleh berbeda secara signifikan dari nilai proporsi populasi yang diasumsikan. Contoh kasusnya adalah: "Apakah benar 50% mahasiswa di Bandar Lampung tinggal di kos/asrama?" Jika hasil sampel kita menunjukkan 47% atau 55%, kita perlu uji hipotesis untuk menentukan apakah perbedaan tersebut kebetulan atau memang signifikan.

##### Membuat fungsi

Untuk memudahkan proses, kita membuat sebuah fungsi di R yang dapat menghitung statistik uji Z untuk proporsi satu populasi. Fungsi ini akan menerima input berupa:



```{r membuat-fungsi-prop1pop}
ht_prop_1pop <- function(p_hat, P, n) {
  se <- sqrt((p_hat * (1-p_hat))/n) # menghitung standard error untuk rata-rata
  Z_hitung <- (p_hat - P)/se # menghitung nilai Z dari statistik
  return(Z_hitung)
}
```

##### Meringkas Data

Sebelum melakukan uji hipotesis, kita perlu mengetahui berapa proporsi mahasiswa yang tinggal di masing-masing tipe tempat tinggal. Kita bisa gunakan fungsi group_by() dan summarize() untuk menghitung jumlah mahasiswa berdasarkan tipe tempat tinggal, lalu menambahkan kolom proporsi. Dengan cara ini, kita mendapatkan ringkasan data yang memperlihatkan distribusi tempat tinggal mahasiswa.



```{r meringkas-data-1}
summarize_tempatTinggal <- data_mahasiswa |> 
  group_by("Tipe tinggal" = tipe_tinggal_baku) |> 
  summarize("Jumlah" = n()) |> 
  mutate("proporsi" = Jumlah/sum(Jumlah))

summarize_tempatTinggal
```

##### Menyimpan Nilai Proporsi

Setelah kita memperoleh ringkasan data, kita simpan nilai proporsi mahasiswa yang tinggal di kos atau asrama ke dalam sebuah variabel. Dengan cara ini, nilai tersebut dapat digunakan dengan mudah dalam perhitungan selanjutnya tanpa harus menghitung ulang.



```{r menyimpan-nilai-proporsi-2}
proporsi_kosAsrama <- summarize_tempatTinggal$proporsi[1]
proporsi_kosAsrama
```

##### Mendeklarasikan variabel pengujian

Pada tahap ini, kita menentukan variabel-variabel utama yang akan digunakan dalam uji hipotesis. Semua variabel inilah yang nantinya akan dimasukkan ke dalam fungsi uji hipotesis yang telah dibuat.



```{r mendeklarasikan-variabel-uji-3}
# Mendeklarasikan variabel-variabel yang akan diuji
sample_prop <- proporsi_kosAsrama
pop_prop <- 0.5

# Menghasilkan data frame ringkasan dataset dengan menghitung jumlah mahasiswa sebagai ukuran sampel
ukuran_sampel <- data_mahasiswa |>
  summarize(ukuran_sampel = n())
# Menyimpan angka jumlah mahasiswa sebagai variabel n
ukuran_sampel <- ukuran_sampel$ukuran_sampel

# Menampilkan variabel-variabel yang akan diuji
cat("Proporsi penghuni Kos/Asrama sampel adalah", sample_prop,
    "\nParameter proporsi penghuni Kos/Asrama yang diuji adalah", pop_prop,
    "\nUkuran sampel adalah", ukuran_sampel, "orang.")
```

#### *Two-tailed Test*

Pada pengujian hipotesis proporsi dengan two-tailed test, kita ingin mengetahui apakah proporsi sampel berbeda secara signifikan dari proporsi populasi yang dihipotesiskan. Artinya, kita hanya fokus pada perbedaan, bukan pada arah perbedaan. Misalnya, kita ingin menguji apakah proporsi mahasiswa yang tinggal di kos/asrama benar-benar sama dengan 50% atau tidak. Jika hasilnya jauh lebih besar atau jauh lebih kecil, keduanya dianggap sebagai bukti menolak hipotesis nol.

##### Merumuskan hipotesis

Sama seperti uji dua arah pada rata-rata, uji dua arah pada proporsi diawali dengan merumuskan hipotesis. Di sini kita mendefinisikan dua kemungkinan: hipotesis nol (H0) dan hipotesis alternatif (H1). H0 biasanya menyatakan bahwa â€œtidak ada perbedaanâ€ atau â€œnilai parameter sama dengan nilai tertentuâ€. Sebaliknya, H1 menyatakan adanya perbedaan yang signifikan. Dalam uji dua arah, rumus hipotesis ditulis sebagai:



```{r merumuskan-hipotesis-4}
cat("H0 : prop. Kos/Asrama = 0,5",
    "\n\nH1 : prop. Kos/Asrama != 0,5")
```

##### Memilih distribusi sampling, wilayah dan titik kritis

Sama seperti sebelumnya, setelah hipotesis ditetapkan, kita perlu menentukan distribusi yang digunakan. Untuk kasus proporsi dengan ukuran sampel besar, digunakan distribusi normal. Kemudian, karena kita menggunakan uji dua arah, wilayah kritis akan terbagi dua, masing-masing di ekor kiri dan kanan distribusi. Kali ini, kita menggunakan taraf signifikansi Î±=0.10.



```{r memilih-distribusi-sampling-wil-titik-kritis-5}
# Hipotesis yang dipakai tidak berarah, maka wilayah kritis adalah alpha/2
alpha <- 0.10 # (tingkat signifikansi 10%)
Z.crit_2tail <- abs(qnorm(alpha/2)) # Nilai yang digunakan adalah nilai absolut

cat("Titik kritis uji two-tailed:", Z.crit_2tail)
```

##### Menghitung Statistik Uji

Setelah titik kritis ditentukan, kita menghitung nilai statistik uji Z berdasarkan proporsi sampel dan proporsi populasi yang diuji.



```{r menghitung-stat-uji-6}
# Hasil perhitungan statistik uji diabsolutkan
Z_propKos <- abs(ht_prop_1pop(sample_prop, pop_prop, ukuran_sampel))

Z_propKos
```

##### Menarik kesimpulan

Langkah terakhir adalah membandingkan nilai statistik uji dengan titik kritis. Dari sini kita bisa menarik kesimpulan apakah hipotesis nol ditolak atau gagal ditolak. Jika nilai statistik uji (absolut) lebih kecil dari titik kritis, maka Hâ‚€ gagal ditolak, artinya perbedaan yang terlihat kemungkinan hanya kebetulan sampel. Jika lebih besar atau sama, maka Hâ‚€ ditolak, artinya ada bukti yang cukup bahwa proporsi tidak sama dengan 0,5.



```{r menarik-kesimpulan-7}
if (Z_propKos < Z.crit_2tail) {
  tolak_h0 <- FALSE
  cat("Hipotesis kosong gagal ditolak. Perbedaan proporsi penghuni Kos/Asrama sebanyak", round(sample_prop, 3), "dari", pop_prop, "hanyalah kebetulan")
} else {
  tolak_h0 <- TRUE  
  cat("Hipotesis kosong ditolak. Perbedaan proporsi penghuni Kos/Asrama sebanyak", round(sample_prop, 3), "dari", pop_prop, "adalah signifikan")
}
```

#### *One-tailed Test*

Pada uji hipotesis proporsi satu arah, kita hanya berfokus dengan satu sisi distribusi, yakni apakah proporsi lebih besar atau lebih kecil dari nilai yang dihipotesiskan (kiri untuk dugaan â€œ\<â€, kanan untuk dugaan â€œ\>â€). Uji ini lebih spesifik karena hipotesis alternatif sudah menetapkan arah. Misalnya, kita ingin tahu apakah proporsi mahasiswa kos/asrama lebih kecil dari 50%. Dalam uji ini, hanya sisi kiri distribusi yang menjadi perhatian.

##### Merumuskan hipotesis

Hipotesis dirumuskan sebagai berikut:



```{r merumuskan-hipotesis-8}
cat("H0 : prop. Kos/Asrama = 0,5",
    "\n\nH1 : prop. Kos/Asrama < 0,5")
```

##### Memilih distribusi Sampling, wilayah dan titik kritis

Distribusi sampling yang digunakan tetap distribusi normal. Namun, karena ini uji satu arah, maka seluruh Î± ditempatkan pada salah satu sisi. Jika hipotesis alternatifnya menyatakan lebih besar, maka daerah kritis ada di sebelah kanan. Jika menyatakan lebih kecil, maka daerah kritis ada di sebelah kiri. Dengan taraf signifikansi Î±, titik kritis dihitung dengan qnorm(1 - alpha) untuk sisi kanan atau qnorm(alpha) untuk sisi kiri.



```{r memilih-distribusi-sampling-wil-titik-kritis-9}
tail <- "kiri"

if (tail == "kiri") {
  Z.crit_1tail <- qnorm(alpha)
} else {
  Z.crit_1tail <- qnorm(1-alpha)
}

cat("Titik kritis uji one-tailed:", Z.crit_1tail)
```

##### Menghitung statistik uji

Sama seperti pada uji dua arah, kita menghitung nilai statistik uji Z dengan fungsi yang sudah dibuat sebelumnya tetapi kali ini kita tidak mengambil nilai absolut karena tanda statistik memberi informasi arah.



```{r menghitung-stat-uji-10}
# Hasil perhitungan statistik uji TIDAK diabsolutkan
Z_propKos <- ht_prop_1pop(sample_prop, pop_prop, ukuran_sampel)

Z_propKos
```

##### Menarik kesimpulan

Kesimpulan diambil dengan membandingkan nilai statistik uji (Z_propKos) dengan titik kritis (Z.crit_1tail). Untuk uji satu arah (kiri), kita menolak Hâ‚€ jika nilai statistik uji lebih kecil dari titik kritis. Jika tidak, kita gagal menolak Hâ‚€. Kesimpulan ini menjelaskan apakah ada cukup bukti untuk menyatakan proporsi memang lebih kecil dari nilai acuan.



```{r menarik-kesimpulan-11}
if (Z_propKos < Z.crit_1tail) {
  tolak_h0 <- TRUE
  cat("Hipotesis kosong ditolak. Perbedaan proporsi penghuni Kos/Asrama sebanyak", round(sample_prop, 3), "dari", pop_prop, "adalah signifikan (lebih kecil)")
} else {
  tolak_h0 <- FALSE  
  cat("Hipotesis kosong gagal ditolak. Perbedaan proporsi penghuni Kos/Asrama sebanyak", round(sample_prop, 3), "dari", pop_prop, "hanyalah kebetulan")
}
```

## Uji Hipotesis 2 Populasi Independen

Dua populasi dikatakan independen apabila tidak ada pengaruh antara populasi 1 dengan populasi lain. Artinya, data dari populasi pertama dan kedua berdiri sendiri, tidak saling berkaitan. Contohnya adalah membandingkan rata-rata jarak tempat tinggal mahasiswa ITERA dengan mahasiswa UINRIL, di mana setiap kelompok mahasiswa berasal dari populasi yang berbeda.

### Rata-rata

##### Merumuskan fungsi

Pada langkah ini, kita akan membuat fungsi uji hipotesis rata-rata untuk dua populasi independen. Fungsi ini diperlukan karena kita ingin menghitung nilai statistik uji (Z) berdasarkan data ringkasan dari dua sampel Dengan fungsi ini, kita bisa langsung memasukkan nilai-nilai statistik dari kedua populasi dan mendapatkan nilai Z yang akan dibandingkan dengan titik kritis.



```{r merumuskan-fungsi-12}
ht_mean_2popIn <- function(xbar1, xbar2, sd1, sd2, n1, n2) {
  se <- sqrt(             # Indentasi diberikan untuk memudahkan
    (                     # pembacaan karena banyaknya tanda kurung
      (sd1^2)/(n1 - 1)
    ) + (
      (sd2^2)/(n2 - 1)
    )
  )
  Z_hitung <- (xbar1 - xbar2)/se # menghitung nilai Z dari statistik
  return(Z_hitung)
}
```

##### Menghitung mean 2 populasi

Sebelum menjalankan uji hipotesis, kita perlu mendapatkan data ringkasan berupa rata-rata, simpangan baku, dan jumlah sampel dari masing-masing populasi. Pada tahap ini, kita akan membuat tabel ringkasan jarak mahasiswa dari rumah ke kampus berdasarkan kelompok kampus. Data ini nantinya akan menjadi input untuk fungsi yang sudah kita buat di langkah sebelumnya. Dengan cara ini, kita bisa lebih mudah membandingkan dua populasi secara langsung.



```{r menghitung-mean-2-populasi-12}
summarize_Jarak2Pop <- data_mahasiswa |>
  group_by(Kampus = kampus) |>
  summarize(`Rata-rata` = mean(jarak_km),
            `Simpangan baku` = sd(jarak_km),
            Jumlah = n())

summarize_Jarak2Pop
```

##### Mendeklarasikan variabel uji

Setelah mendapatkan ringkasan data, kita harus menyimpan nilai rata-rata, simpangan baku, dan ukuran sampel ke dalam variabel khusus. Variabel-variabel ini akan dipakai langsung sebagai input fungsi uji hipotesis. Dengan mendeklarasikannya lebih dulu, proses penghitungan menjadi lebih rapi dan mudah diikuti.



```{r mendeklarasikan-variabel-uji-13s}
mean_jarakUINRIL <- summarize_Jarak2Pop$`Rata-rata`[3]
mean_jarakITERA <- summarize_Jarak2Pop$`Rata-rata`[1]

sd_jarakUINRIL <- summarize_Jarak2Pop$`Simpangan baku`[3]
sd_jarakITERA <- summarize_Jarak2Pop$`Simpangan baku`[1]

n_jarakUINRIL <- summarize_Jarak2Pop$Jumlah[3]
n_jarakITERA <- summarize_Jarak2Pop$Jumlah[1]
```

#### *Two-tailed Test*

##### Merumuskan hipotesis

Sama seerti sebelumnya, langkah pertama dalam uji hipotesis adalah menyusun hipotesis nol (H0) dan hipotesis alternatif (H1). Untuk kasus two-tailed test, hipotesis alternatif menyatakan adanya perbedaan rata-rata tanpa menyebutkan arah (lebih besar atau lebih kecil). Artinya, kita hanya ingin tahu apakah terdapat perbedaan signifikan atau tidak, tanpa peduli siapa yang lebih besar. Hipotesis nol menyatakan tidak ada perbedaan, atau selisih rata-rata sama dengan nol.



```{r merumuskan-hipotesis-15}
cat("H0: mu_jarakUINRIL - mu_jarakITERA = 0",
    "\n\nH1: mu_jarakUINRIL - mu_jarakITERA != 0")
```

##### Memilih distribusi sampling, wilayah, dan titik kritis

Setelah hipotesis dirumuskan, kita harus menentukan distribusi sampling yang dipakai serta wilayah kritisnya. Karena ukuran sampel cukup besar, distribusi normal standar (Z) digunakan sebagai acuan. Untuk two-tailed test, wilayah kritis terbagi dua sama besar di kedua sisi kurva distribusi. Nilai kritis diperoleh dari tabel distribusi normal pada Î±/2, lalu dibuat dalam bentuk absolut karena titik kritis simetris di kedua sisi.



```{r memilih-distribusi-sampling-wil-titik-kritis-15}
# Hipotesis yang dipakai tidak berarah, maka wilayah kritis adalah alpha/2
alpha <- 0.001

Z.crit_2tail <- abs(qnorm(alpha/2)) # Nilai yang digunakan adalah nilai absolut

cat("Titik kritis uji two-tailed:", Z.crit_2tail)
```

##### Menghitung statistik uji

Setelah mengetahui titik kritis, kita hitung nilai statistik uji (Z) dari data yang dimiliki. Nilai ini diperoleh dengan memasukkan rata-rata, simpangan baku, dan ukuran sampel ke fungsi ht_mean_2popIn. Karena pengujian dilakukan dua sisi, nilai Z hasil perhitungan diabsolutkan agar bisa dibandingkan langsung dengan titik kritis.



```{r menghitung-stat-uji-a}
# Hasil perhitungan statistik uji diabsolutkan
Z_meanJarak2Pop <- abs(ht_mean_2popIn(mean_jarakUINRIL, mean_jarakITERA,
                                      sd_jarakUINRIL, sd_jarakITERA,
                                      n_jarakUINRIL, n_jarakITERA))

Z_meanJarak2Pop
```

##### Menarik kesimpulan

Langkah terakhir adalah membandingkan nilai statistik uji dengan titik kritis. Jika Z hitung lebih kecil dari Z kritis, maka H0 gagal ditolak, artinya perbedaan rata-rata jarak antara dua populasi kemungkinan hanyalah kebetulan. Jika Z hitung lebih besar, maka H0 ditolak, yang berarti terdapat cukup bukti untuk menyatakan adanya perbedaan.



```{r menarik-kesimpulan-b}
if (Z_meanJarak2Pop < Z.crit_2tail) {
  tolak_h0 <- FALSE
  cat("Hipotesis kosong gagal ditolak. Perbedaan rata-rata jarak mahasiswa UINRIL dengan ITERA dari sampel hanyalah kebetulan.")
} else {
  tolak_h0 <- TRUE  
  cat("Hipotesis kosong ditolak. Perbedaan rata-rata jarak mahasiswa UINRIL dengan ITERA dari sampel signifikan.")
}
```

#### *One-tailed Test*

##### Merumuskan hipotesis

Untuk one-tailed test, hipotesis alternatif (H1) menyebutkan arah perbedaan yang spesifik, misalnya rata-rata populasi 1 lebih kecil dari populasi 2. Berbeda dengan two-tailed test yang hanya memeriksa â€œada perbedaanâ€, one-tailed test lebih fokus untuk mengetahui apakah perbedaan itu terjadi sesuai arah yang dihipotesiskan. Hipotesis nol (H0) tetap menyatakan tidak ada perbedaan, tetapi pengujian difokuskan hanya pada satu sisi distribusi.



```{r merumuskan-hipotesis-c}
cat("H0: mu_jarakUINRIL - mu_jarakITERA = 0",
    "\n\nH1: mu_jarakUINRIL - mu_jarakITERA < 0")
```

##### Memilih distribusi sampling, wilayah, dan titik kritis

Dalam pengujian one-tailed, kita perlu menentukan sisi mana yang akan digunakan sebagai wilayah kritis. Jika hipotesis alternatif menyebutkan â€œlebih kecilâ€, maka wilayah kritis berada di sisi kiri distribusi. Sebaliknya, jika hipotesis menyebutkan â€œlebih besarâ€, wilayah kritis diletakkan di sisi kanan.



```{r memilih-distribusi-sampling-wil-titik-kritis-a}
tail <- "kiri"

if (tail == "kiri") {
  Z.crit_1tail <- qnorm(alpha)
} else {
  Z.crit_1tail <- qnorm(1-alpha)
}

cat("Titik kritis uji one-tailed:", Z.crit_1tail)
```

##### Menghitung Statistik uji

Selanjutnya, kita menghitung nilai statistik uji menggunakan fungsi ht_mean_2popIn. Berbeda dengan two-tailed test, pada one-tailed test nilai Z tidak diabsolutkan karena arah perbedaan menjadi penting.



```{r menghitung-stat-uji-d}
# Hasil perhitungan statistik uji TIDAK diabsolutkan
Z_meanJarak2Pop <- ht_mean_2popIn(mean_jarakUINRIL, mean_jarakITERA,
                                  sd_jarakUINRIL, sd_jarakITERA,
                                  n_jarakUINRIL, n_jarakITERA)

Z_meanJarak2Pop
```

##### Menarik kesimpulan

Tahap terakhir adalah menarik kesimpulan dengan cara membandingkan nilai statistik uji terhadap titik kritis. Jika nilai Z hitung jatuh pada wilayah kritis (misalnya lebih kecil dari Z kritis kiri), maka hipotesis nol ditolak. Artinya, ada bukti cukup untuk menyatakan rata-rata jarak mahasiswa ITERA memang lebih kecil dari mahasiswa UINRIL sesuai hipotesis arah. Jika tidak, maka hipotesis nol gagal ditolak, dan kita simpulkan bahwa arah perbedaan yang diduga tidak terbukti secara signifikan.



```{r menarik-kesimpulan-c}
if (Z_meanJarak2Pop < Z.crit_1tail) {
  tolak_h0 <- TRUE
  cat("Hipotesis kosong ditolak. Mahasiswa ITERA secara rata-rata tinggal lebih jauh dari kampus dibandingkan mahasiswa UINRIL significanly.")
} else {
  tolak_h0 <- FALSE  
  cat("Hipotesis kosong gagal ditolak. Tidak cukup bukti menyatakan mahasiswa ITERA tinggal lebih jauh.")
}
```

### Proporsi

Pada bagian ini kita akan melakukan uji hipotesis terhadap proporsi dua populasi yang independen. Berbeda dengan rata-rata, proporsi digunakan ketika data berbentuk kategori (misalnya pilihan tinggal di kos/asrama atau tinggal bersama keluarga). Prinsip pengujian tetap sama, yaitu membandingkan apakah perbedaan proporsi antar populasi signifikan atau hanya karena kebetulan sampel.

##### Membuat fungsi

Sama seperti sebelumnya, langkah pertama adalah membuat fungsi khusus untuk menghitung nilai statistik uji pada uji hipotesis proporsi dua populasi independen. Fungsi ini menerima input berupa proporsi sampel masing-masing populasi (p_hat1 dan p_hat2) serta ukuran sampelnya (n1 dan n2). Di dalam fungsi, dihitung terlebih dahulu proporsi gabungan (p_gab) yang mewakili keseluruhan sampel. Kemudian dihitung standard error (SE), dan akhirnya didapatkan nilai Z hitung.

```{r membuat-fungsi-0}
# Membuat fungsi uji hipotesis (hypothesis testing, ht) untuk rata-rata (mean)
# dengan 1 populasi (2pop) Independen (In)
# Keterangan input:
#   - xbar1 : statistik rata-rata populasi #1
#   - xbar2 : statistik rata-rata populasi #2
#   - sd1   : statistik simpangan baku populasi #1
#   - sd2   : statistik simpangan baku populasi #2
#   - n1    : ukuran sampel dari populasi #1
#   - n2    : ukuran sampel dari populasi #2
ht_prop_2popIn <- function(p_hat1, p_hat2, n1, n2) {
  p_gab <- ((n1*p_hat1 + n2*p_hat2))/(n1 + n2) # Total proporsi yang diuji
                                               # untuk kedua populasi
  se <- sqrt(
    (p_gab*(1-p_gab)) * ( # Indentasi diberikan untuk memudahkan pembacaan
      (1/n1) + (1/n2)     # karena banyaknya kurung
    )
  )
  Z_hitung <- (p_hat1 - p_hat2)/se # menghitung nilai Z dari statistik
  return(Z_hitung)
}
```

##### Mendeklarasikan variabel uji

Setelah fungsi dibuat, kita perlu menyiapkan data yang akan diuji. Pertama, data mahasiswa dikelompokkan berdasarkan kampus dan tipe_tinggal_baku. Selanjutnya dihitung proporsi tiap kategori (misalnya proporsi mahasiswa yang tinggal di kos/asrama). Data kemudian diubah dari format long ke wide sehingga tiap kategori menjadi variabel. Dari hasil ini kita bisa mengambil proporsi masing-masing populasi, serta ukuran sampel total pada tiap kampus.

```{r mendeklarasikan-variabel-uji-g}
summarize_tempatTinggal2Pop <- data_mahasiswa |> 
  group_by(kampus, tipe_tinggal_baku) |> 
  summarize(Jumlah = n()) |>
  mutate(proporsi = Jumlah/sum(Jumlah)) |> # menghitung proporsi tiap kategori.
  select(-Jumlah) |> 
  spread(tipe_tinggal_baku, proporsi) # mengubah data long menjadi wide (kolom                                          # kategori jadi variabel).

summarize_tempatTinggal2Pop

proporsi_kosAsrama_ITERA <- summarize_tempatTinggal2Pop$`Kos/Asrama`[1]
proporsi_kosAsrama_UINRIL <- summarize_tempatTinggal2Pop$`Kos/Asrama`[3]

n_kosAsrama_2Pop <- data_mahasiswa |> 
  count(kampus)

n_kosAsrama_ITERA <- n_kosAsrama_2Pop$n[1]
n_kosAsrama_UINRIL <- n_kosAsrama_2Pop$n[3]
```

####*Two-tailed Test*

```{r coba-sendiri0}
# Gunakan CI = 93%, artinya alpha = 7% = 0.07
alpha <- 0.07

# Hitung Z kritis 2-tailed
Z.crit_2tail <- abs(qnorm(alpha/2))

# Hitung statistik uji proporsi 2 populasi
# Asumsi: Menggunakan data proporsi kos/asrama ITERA vs UINRIL yang sudah disiapkan sebelumnya
Z_prop2Pop <- abs(ht_prop_2popIn(proporsi_kosAsrama_UINRIL, proporsi_kosAsrama_ITERA,
                             n_kosAsrama_UINRIL, n_kosAsrama_ITERA))

cat("Titik Kritis:", Z.crit_2tail, "\nZ Hitung:", Z_prop2Pop, "\n")

if (Z_prop2Pop < Z.crit_2tail) {
  cat("Hipotesis nol gagal ditolak.")
} else {
  cat("Hipotesis nol ditolak.")
}
```

#### *One-tailed Test*

```{r coba-sendiri1}
# Gunakan CI = 96%, artinya alpha = 4% = 0.04
alpha <- 0.04
tail <- "kiri" # Asumsi uji lebih kecil (UINRIL < ITERA misalnya)

# Hitung Z kritis 1-tailed
if (tail == "kiri") {
  Z.crit_1tail <- qnorm(alpha)
} else {
  Z.crit_1tail <- qnorm(1-alpha)
}

# Hitung statistik uji (tidak absolut)
Z_prop2Pop <- ht_prop_2popIn(proporsi_kosAsrama_UINRIL, proporsi_kosAsrama_ITERA,
                             n_kosAsrama_UINRIL, n_kosAsrama_ITERA)

cat("Titik Kritis:", Z.crit_1tail, "\nZ Hitung:", Z_prop2Pop, "\n")

if (Z_prop2Pop < Z.crit_1tail) {
  cat("Hipotesis nol ditolak (Signifikan).")
} else {
  cat("Hipotesis nol gagal ditolak.")
}
```

## Uji Hipotesis 2 Populasi Dependen

Menguji hipotesis 2 populasi yang dependen pada dasarnya sama persis dengan uji hipotesis 1 populasi, karena statistik yang diuji adalah **perbedaan nilai sampel**. Biasanya berbentuk "sebelum-sesudah". Contoh: mengukur nilai mahasiswa sebelum dan sesudah diberi pelatihan. Bedanya dengan independen : kita tidak bandingkan dua kelompok berbeda, tapi pasangan data dari kelompok yang sama dalam dua kondisi.

Perbedaan nilai sampel jumlah nilainya hanya 1, sehingga bisa diperlakukan seperti halnya perhitungan uji hipotesis 1 populasi. Simpangan baku yang diketahui pun adalah simpangan baku **perbedaan nilainya, sehingga jumlah nilainya hanya 1 juga**.

## Soal Latihan



<!--chapter:end:05-uji-hipotesis.Rmd-->

# Modul-6: Analisis Hubungan Korelatif: Korelasi Variabel Nominal dan Ordinal

Setelah mempelajari modul ini, Anda diharapkan dapat:

1. mampu menghasilkan koefisien korelasi variabel di tingkat nominal dengan perangkat lunak komputer [STP-9.2]{.capaian}
2. mampu menghasilkan koefisien korelasi variabel di tingkat ordinal dengan perangkat lunak komputer [STP-10.2]{.capaian}


---

## Pendahuluan

Analisis korelasi adalah salah satu teknik analisis yang termasuk ke dalam lingkup statistika bivariat, statistika yang analisisnya melibatkan dua variabel **sekaligus**. Pada praktikum-praktikum sebelumnya kita hanya melibatkan satu variabel saja, misalnya:

-   pada praktikum ke-2, kita mengaplikasikan persentase hanya pada variabel `Jenis.Kelamin`, `Fakultas`, `Tingkat.Semester`, `Uang.Saku`, atau`jenis.tempat.tinggal` saja, tetapi tidak menghubungkannya satu sama lain,

    ``` r
    data.ubl |> 
      tbl_summary(include = c(Jenis.Kelamin,
                              Fakultas,
                              Tingkat.Semester,
                              Uang.Saku,
                              jenis.tempat.tinggal)) |> 
      as_flex_table()
    ```

-   pada praktikum ke-3, kita membuat histogram untuk variabel `Umur` saja

    ``` r
    histogram <- ggplot(data.ubl.cleaned) +
      geom_histogram(mapping = aes(x = Umur), binwidth = 1, fill = "darkseagreen", color = "white") +
      labs(
        title = "Distribusi Umur Mahasiswa",
        x = "Umur (Tahun)",
        y = "Frekuensi"
      ) +
      theme_minimal()

    histogram
    ```

-   pada praktikum-praktikum tentang analisis statistik inferensial, kita hanya tertarik pada proporsi atau rata-rata suatu variabel saja, yang pastinya tunggal.

Dalam praktikum ini kita akan mempraktikkan analisis korelasi pada dua variabel **secara bersamaan.** Ketika kita tertarik pada analisis untuk dua variabel secara bersamaan, artinya kita sedang menganalisis sebuah **keterkaitan** atau sebuah **hubungan**. Dalam praktikum ini, hubungan itu disebut **korelasi**.

Korelasi yang akan kita pelajari adalah korelasi pada pasangan variabel dengan tingkat pengukuran nominal dan juga ordinal.

## Pustaka *(Libraries)* yang Diperlukan dan Memuat Data

Seperti biasa, kita perlu memuat pustaka *(libraries)* yang diperlukan dalam pengolahan data kita. Untuk memuat tabel silang kita akan gunakan pustaka `gtsummary` kembali seperti pada praktikum ke-2

```{r }
library(tidyverse)
library(readr)
```

**Memuat dataset**

Kita akan menggunakan dataset keempat kampus di Kota Bandar Lampung dan sekitarnya sebagai bahan. Tulis ulang dan jalankan baris perintah berikut untuk mengolah data keempat kampus

```{r}
# Membaca data
data_mahasiswa <- read_csv2("datasets/Data Praktikum 06.csv")
```

**Mengatur Faktor untuk Variabel Kategoris**

Setelah membaca data, kita perlu mengatur variabel-variabel nominal dan ordinal dengan mengatur nilai-nilainya berupa *factor*.

Namun sebelum itu, kita akan membuat vektor-vektor untuk kita aplikasikan menjadi *factor* dengan memanfaatkan `group_by` dan `summarize` yang berasal dari pustaka `dplyr`.

```{r membuat-vektor}
# MEMBUAT FAKTOR UNTUK KAMPUS
# Meringkas data berdasarkan kolom Kampus PT
faktor_kampus <- data_mahasiswa |>
  group_by(kampus = Kampus_PT) |>
  summarize(jumlah = n())
# Membuat vektor untuk faktor Kampus PT dari kolom nama Kampus
faktor_kampus <- faktor_kampus$kampus

# MEMBUAT FAKTOR UNTUK FAKULTAS
# Meringkas data berdasarkan kolom Fakultas
faktor_fakultas <- data_mahasiswa |>
  group_by(fakultas = Fakultas) |>
  summarize(jumlah = n())
# Membuat vektor untuk faktor Fakultas dari kolom nama fakultas
faktor_fakultas <- faktor_fakultas$fakultas

# MEMBUAT FAKTOR UNTUK PROGRAM STUDI
# Meringkas data berdasarkan kolom Prodi
faktor_prodi <- data_mahasiswa |>
  group_by(prodi = Prodi) |>
  summarize(jumlah = n())
# Membuat vektor untuk faktor Prodi dari kolom nama Prodi
faktor_prodi <- faktor_prodi$prodi

# MEMBUAT FAKTOR UNTUK JENIS KELAMIN
# Meringkas data berdasarkan kolom Jenis Kelamin
faktor_jk <- data_mahasiswa |>
  group_by(jk = `Jenis Kelamin`) |> 
  summarize(jumlah = n())
# Membuat vektor untuk faktor Jenis Kelamin dari kolom nama Jenis Kelamin
faktor_jk <- faktor_jk$jk

# MEMBUAT FAKTOR UNTUK TINGKAT SEMESTER
# Meringkas data berdasarkan kolom Tingkat Semester
faktor_semester <- data_mahasiswa |>
  group_by(semester = `Tingkat Semester`) |>
  summarize(jumlah = n())
# Membuat vektor faktor Tingkat Semester dari kolom Tingkat Semester
faktor_semester <- faktor_semester$semester

# MEMBUAT FAKTOR UNTUK UANG SAKU
# Meringkas data berdasarkan kolom Uang Saku
faktor_uangsaku <- data_mahasiswa |>
  group_by(uang = `Uang Saku`) |>
  summarize(jumlah = n())
# Memperbaiki urutan uang saku
faktor_uangsaku$uang[c(1,4)] <- faktor_uangsaku$uang[c(4,1)]
faktor_uangsaku$jumlah[c(1,4)] <- faktor_uangsaku$jumlah[c(4,1)]

faktor_uangsaku$uang[c(2,4)] <- faktor_uangsaku$uang[c(4,2)]
faktor_uangsaku$jumlah[c(2,4)] <- faktor_uangsaku$jumlah[c(4,2)]

faktor_uangsaku$uang[c(3,4)] <- faktor_uangsaku$uang[c(4,3)]
faktor_uangsaku$jumlah[c(3,4)] <- faktor_uangsaku$jumlah[c(4,3)]

# Membuat vektor faktor Tingkat Uang Saku dari kolom Uang Saku
faktor_uangsaku <- faktor_uangsaku$uang

# MEMBUAT FAKTOR UNTUK KENDARAAN UTAMA
# Meringkas data berdasarkan kolom Kendaraan Utama
faktor_kendaraanutama <- data_mahasiswa |>
  group_by(kendaraan = `kendaraan utama`) |>
  summarize(jumlah = n())
# Membuat vektpr faktor untuk kendaraan utama dari kolom 'kendaraan'
faktor_kendaraanutama <- faktor_kendaraanutama$kendaraan


# MEMBUAT FAKTOR JENIS TEMPAT TINGGAL
# Meringkas data berdasarkan kolom Jenis Tempat Tinggal
faktor_jenistempattinggal <- data_mahasiswa |>
  group_by(tempat_tinggal = `jenis tempat tinggal`) |>
  summarize(jumlah = n())
# Membuat vektor faktor untuk jenis tempat tinggal berdasarkan kolom Jenis Tempat Tinggal
faktor_jenistempattinggal <- faktor_jenistempattinggal$tempat_tinggal
```

Barulah selanjutnya kita bisa mengatur *factor* untuk setiap variabel kategoris

```{r mengatur-faktor}
data_mahasiswa <- data_mahasiswa |>
  mutate (Kampus_PT = factor(Kampus_PT, levels = faktor_kampus),
         `Jenis Kelamin` = factor(`Jenis Kelamin`, levels = faktor_jk),
         Fakultas = factor(Fakultas, levels = faktor_fakultas),
         Prodi = factor(Prodi, levels = faktor_prodi),
         `Tingkat Semester` = factor(`Tingkat Semester`, levels = faktor_semester,
                                     ordered = TRUE), # Variabel ordinal
         `Uang Saku` = factor(`Uang Saku`, levels = faktor_uangsaku,
                              ordered = TRUE), # Variabel ordinal
         `kendaraan utama` = factor(`kendaraan utama`, levels = faktor_kendaraanutama),
         `jenis tempat tinggal` = factor(`jenis tempat tinggal`, levels = faktor_jenistempattinggal)
         )
```

Kita dapat memeriksa hasil pekerjaan kita dengan perintah `glimpse`

```{r memeriksa-hasil-factor}
# Memeriksa hasil pengaturan factor
glimpse(data_mahasiswa)
```

## Pembuatan Tabel Silang

Setelah kita memastikan data kita bersih, kita siap untuk menganalisis korelasi antarvariabel kategoris.

Korelasi antarvariabel kategoris memerlukan "bahan baku" berupa **tabel silang** atau ***cross table***. Kebanyakan literatur juga menggunakan istilah ***contingency table***. Tabel silang adalah tabel dua arah, yakni yang baik baris maupun kolomnya adalah **nilai-nilai dari dua variabel** yang disilangkan.

*Chunk* berikut memperlihatkan bagaimana membuat tabel silang antara variabel `jenis tempat tinggal` dengan `kendaraan utama`.

```{r membuat-tabel-silang}
library(gtsummary)
library(flextable)

# Menghasilkan tabel silang antara variabel kendaraan utama dan jenis tempat tinggal
# untuk keperluan presentasi
data_mahasiswa |>
  select(`jenis tempat tinggal`, `kendaraan utama`) |>
  tbl_summary(by = `jenis tempat tinggal`) |>
  as_flex_table()
```

Tabel silang yang merupakan hasil dari *script* di atas adalah seperti berikut. Baris menunjukkan kategori dalam variabel `kendaraan utama`, sementara kolom menunjukkan kategori dalam variabel `jenis tempat tinggal`. Nilai-nilai dalam sel-selnya adalah frekuensi/jumlah data yang termasuk ke dalam kondisi berupa kategori kedua variabel.

Perhatikan cara menginterpretasi informasi dari tabel tersebut:

-   jumlah pengguna layanan online yang tinggal di kos bersama-sama adalah 19 orang, yang setara dengan 16%.

-   tidak ada pengguna sepeda yang tinggal di Asrama, Kos bersama-sama, atau mengontrak rumah secara pribadi. Keberadaannya juga langka pada kalangan mahasiswa yang tinggal di rumah pribadi atau di saudaranya.

![Tabel Silang antara variabel jenis kendaraan utama dengan jenis tempat tinggal](images/hasil%20tabel%20silang.png){width="600"}

Selain dengan `tbl_summary()` yang gunanya cenderung untuk presentasi, kita dapat menggunakan perintah `table()` untuk menghasilkan tabel silang yang siap dioperasikan ke dalam perhitungan koefisien korelasi di tahap selanjutnya. Perintah `table()` mengambil dua masukan, yakni vektor variabel-variabel yang kita akan analisis, dipisahkan dengan tanda koma (`,`).

```{r perintah-table()}
table(data_mahasiswa$`jenis tempat tinggal`,  # vektor variabel-variabel ini kita akses dari 
      data_mahasiswa$`kendaraan utama`)       # dataset menggunakan operator '$'
```

**Latihan: buatlah tabel silang antara variabel `Tingkat Semester` dan `Uang Saku` baik dengan `gt_summary` maupun dengan `table()`!**

## Analisis Korelasi Antarvariabel Nominal

Dalam analisis korelasi variabel nominal, kita mengukur **keberadaan** dan juga **kekuatan hubungan**. Ukuran yang kita pakai untuk menyatakan hal tersebut adalah **koefisien korelasi variabel nominal**, yang di antaranya adalah koefisien $\phi$ **(phi)**, **V Cramer** dan **koefisien C**. Ketiga koefisien tersebut dihitung dari nilai $\chi^2$ ("chi kuadrat").

Selain itu, terdapat juga $\lambda$ **(lambda)** yang merupakan koefisien korelasi variabel nominal berbasis *error,* atau disebut juga PRE *(proportional reduction of error).*

Ukuran dari keempat koefisien tersebut adalah besarnya yang berkisar **antara 0 dan 1** dengan **0 berarti tidak ada hubungan sama sekali** dan **1 berarti hubungan yang ada sangat kuat.**

### Koefisien Korelasi Variabel Nominal Berbasis $\chi^2$

Yang pertama adalah koefisien korelasi berbasis nilai $\chi^2$ . Karena berbasis nilai $\chi^2$, maka kita harus menghitung terlebih dahulu nilai $\chi^2$ antara dua variabel kita.

Untuk menghitung $\chi^2$ kita menggunakan dua perintah utama dalam R, yakni `table()` dan `chisq.test()`. Perintah `table()` berfungsi membuat tabel silang yang berguna sebagai "bahan baku" perhitungan $\chi^2$ kita, kemudian perintah `chisq.test()` menghitung nilai $\chi^2$ tersebut.

```{r menghitung-chi-square}
# Menyimpan tabel
t4tinggal_kend <- table(data_mahasiswa$`kendaraan utama`,
                        data_mahasiswa$`jenis tempat tinggal`)
# Menyimpan hasil chi-square test
chisq_t4tinggal_kend <- 
  t4tinggal_kend |>
  chisq.test()

```

Seperti yang bisa kita lihat, hasil perhitungan berupa variabel R `chisq_t4tinggal_kend` berada di bagian data, dan jika kita perluas, maka di dalamnya terdapat banyak variabel-variabel lain. Variabel-variabel lain tersebut menyimpan berbagai nilai yang menjadi bagian dari hasil perhitungan. Nilai-nilai yang penting untuk

-   `.$statistic` menyimpan nilai $\chi^2$ dari tabel. Ini digunakan untuk menghitung kekuatan korelasi

-   `.$parameter` menyimpan nilai *degree of freedom* (df)

-   `.$p.value` menyimpan nilai probabilitas untuk menerima $H_0$ yang berarti tidak ada hubungan antara dua variabel yang dianalisis

-   `.$expected` menyimpan tabel frekuensi yang diharapkan dari data kita

Tampilkan seluruh nilai tersebut

```{r menampilkan-nilai-penting}
chisq_t4tinggal_kend$statistic

chisq_t4tinggal_kend$parameter

chisq_t4tinggal_kend$p.value

chisq_t4tinggal_kend$expected
```

Kita akan menghitung nilai koefisien V Cramer untuk menyatakan korelasi antara jenis kendaraan yang digunakan sebagai moda ke kampus dan jenis tempat tinggal mahasiswa menggunakan rumus berikut dan berdasarkan nilai $\chi^2$ yang kita dapatkan dari tes sebelumnya.

$$
V = \sqrt{\frac{\chi^2}{n \times min(câˆ’1,râˆ’1)}}â€‹â€‹
$$

```{r menghitung-koefisien-V}
# Menyimpan nilai Chi-squared menggunakan metode "as.numeric"
chisq_t4tinggal_kend <- as.numeric(chisq_t4tinggal_kend$statistic)

# Menghitung jumlah data
n <- data_mahasiswa |>
  summarize(jumlah = n())
n <- n$jumlah

# Menghitung jumlah kategori dari 'jenis tempat tinggal' sebagai jumlah kolom
kolom <- data_mahasiswa |>
  group_by(jenis = `jenis tempat tinggal`) |>
  summarize(jumlah = n())
kolom <- length(kolom$jenis)

# Menghitung jumlah kategori dari 'kendaraan utama' sebagai jumlah baris
baris <- data_mahasiswa |>
  group_by(kend = `kendaraan utama`) |>
  summarize(jumlah = (n))
baris <- length(baris$kend)

# Menghitung koefisien V
v_t4tinggal_kend <- sqrt(chisq_t4tinggal_kend/(n * min(kolom-1, baris-1)))
v_t4tinggal_kend
```

**Kesimpulan:** Hasil dari perhitungan koefisien V adalah **0,253**. Angka ini menunjukkan hubungan yang sedikit lemah, karena berada di bawah nilai tengah-tengah yaitu 0,5. Artinya, hubungan antara jenis tempat tinggal dengan jenis kendaraan yang sering digunakan ke kampus tidak begitu kuat.

**Cara lain:** kita dapat menggunakan pustaka `rcompanion` untuk menghitung koefisien V Cramer, yaitu dengan perintah `cramerV()`. Perintah ini mengambil langsung vektor kolom variabel yang kita akan analisis, sehingga menggunakan notasi `$` untuk mengakses kolom `` `jenis tempat tinggal` `` dan `` `kendaraan utama` ``.

Tentunya kita harus menginstal pustaka tersebut jika belum memilikinya dengan perintah `install.packages('rcompanion')`.

```{r, eval=FALSE}
install.packages("rcompanion")
```

```{r menggunakan-pustaka-rcompanion}
library(rcompanion)

cramerV(data_mahasiswa$`jenis tempat tinggal`, data_mahasiswa$`kendaraan utama`)
```

### Koefisien Korelasi Variabel Nominal Berbasis *Error*

Untuk analisis korelasi variabel nominal berbasis *error* yang menggunakan koefisien $\lambda$ kita dapat menggunakan perintah `lambda()` yang ada di dalam pustaka `RCPA3`. Terlebih dahulu tentunya lakukan instalasi pustaka tersebut dengan perintah `install.packages('RCPA3')`.

Perintah `lambda()` mengambil masukan berupa tabel silang seperti yang kita buat pada perhitungan $\chi^2$, yakni perintah `table()` .

```{r, eval=FALSE}
install.packages("RCPA3")
```

```{r menghitung-lambda}
library(RCPA3)

# Menghitung koefisien lambda
lambda_t4tinggal_kend <- lambda(t4tinggal_kend, digits = 3, detailed = TRUE)
# digits menandakan berapa desimal angka yang kita hasilkan
# detailed menandakan apakah kita memperlihatkan nilai-nilai error yang dihitung
```

## Analisis Korelasi Antarvariabel Ordinal

Dalam analisis korelasi variabel ordinal, kita tidak hanya dapat mengukur keberadaan dan juga kekuatan hubungan, tetapi juga **arah hubungan**. Yang dimaksud dengan 'arah hubungan' adalah **searah** atau **berlawanan**. Hubungan searah berarti semakin tinggi nilai variabel #1, maka semakin tinggi juga nilai variabel #2, begitu pula sebaliknya. Akan tetapi, jika arah hubungan berlawanan, semakin tinggi nilai variabel #1 maka semakin rendah nilai variabel #2, begitu pula sebaliknya.

Arah hubungan ditunjukkan oleh **tanda koefisien** dan kekuatannya ditunjukkan oleh **besar angka koefisien.** Oleh karena itu, nilai korelasi pada variabel ordinal berkisar antara $-1$ hingga $+1$ dengan tanda $-$ untuk menandakan hubungan berlawanan dan $+$ untuk hubungan searah.

Kita dapat menggunakan perintah `GKgamma()` dari pustaka `vcdExtra`. Lakukan instalasi pustaka terlebih dahulu dengan perintah `install.packages('vcdExtra')`.

Perintah `GKgamma()` mengambil masukan sama seperti `chisq.test()`, yakni tabel silang yang dihasilkan dari perintah `table()`.

Dalam praktikum ini, kita akan menganalisis kekuatan dan arah hubungan antara Uang Saku dan Tingkat Semester. Apakah mahasiswa dengan tingkat semester makin tinggi uang sakunya makin tinggi pula, atau sebaliknya?

```{r, eval=FALSE}
install.packages("vcdExtra")
```

```{r menghitung-koefisien-gamma}
library(vcdExtra)

# Membuat variabel table() sebagai masukan
uangSaku_tingkatSemester <- table(data_mahasiswa$`Uang Saku`,
                                  data_mahasiswa$`Tingkat Semester`)

# Menghitung nilai Gamma dari variabel table() yang sudah dibuat
G_uangSaku_tingkatSemester <- GKgamma(uangSaku_tingkatSemester)

# Menampilkan nilai Gamma
G_uangSaku_tingkatSemester
```

Seperti halnya nilai variabel hasil perhitungan `chisq.test()`, hasil perhitungan `GKgamma()` juga terdiri atas banyak variabel. Nilai gamma sendiri dapat kita akses dengan `.$gamma`.

Nilai lain yang penting bagi kita adalah nilai `.$C` dan `.$D` . Nilai-nilai tersebut adalah nilai operasi dalam sel tabel silang yang merupakan penyusun dalam perhitungan koefisien tersebut mengikuti rumus berikut:

$$
G = \frac{C-D}{C+D}
$$

```{r mengakses-penyusun-rumus-gamma}
# Menampilkan nilai C dan D
print(G_uangSaku_tingkatSemester$C)
print(G_uangSaku_tingkatSemester$D)
```

::: {.rmdexercise}
**Aktivitas Mandiri 3: Analisis Korelasi Komprehensif [STP-9.2, STP-10.2]**

**A. Korelasi Nominal [STP-9.2]:**

1. **Fakultas vs Prodi:**
   - Hitung V Cramer dan Lambda
   - Interpretasikan kekuatan hubungan

2. **Jenis Kelamin vs Kendaraan Utama:**
   - Hitung kedua koefisien
   - Bandingkan dengan hubungan Fak ultas-Prodi
  
**B. Korelasi Ordinal [STP-10.2]:**

3. **Tingkat Semester vs Uang Saku:**
   - Hitung koefisien Gamma
   - Interpretasikan arah dan kekuatan hubungan
:::

------------------------------------------------------------------------

<!--chapter:end:06-korelasi-nominal-ordinal.Rmd-->

# Modul-7: Analisis Hubungan Korelatif: Korelasi Variabel Metrik

Setelah mempelajari modul ini, Anda diharapkan mampu menghasilkan koefisien korelasi variabel di tingkat metrik dengan perangkat lunak komputer. [STP-11.2]{.capaian}


---

## Pendahuluan

Analisis korelasi adalah salah satu teknik analisis yang termasuk ke dalam lingkup statistika bivariat, statistika yang analisisnya melibatkan dua variabel **sekaligus**. Pada praktikum sebelumnya kita sudah mengenal koefisien-koefisien berikut untuk menganalisis korelasi antara dua variabel nominal dan ordinal:

-   V Cramer dan $\lambda$ (lambda) untuk dua variabel nominal
-   Gamma (G) untuk dua variabel ordinal

Dalam praktikum ini kita akan mempraktikkan analisis korelasi pada **dua variabel** **metrik.** Pada praktikum sebelumnya kita mengetahui bahwa dari koefisien-koefisien korelasi kita dapat mengetahui:

-   **kekuatan** untuk dua variabel nominal

-   **kekuatan** dan **arah** untuk dua variabel ordinal

Untuk dua variabel metrik, selain **kekuatan** dan juga **arah hubungan**, kita juga dapat menganalisis **pola** hubungan tersebut, yakni persebaran titik-titik data secara **grafis**.

Dalam praktikum ini kita akan mempraktikkan perhitungan dua jenis koefisien: **Spearman's rho** ($\rho$) dan **Pearson's r.**

## Pustaka *(Libraries)* yang Diperlukan dan Memuat Data

Seperti biasa, kita perlu memuat pustaka *(libraries)* yang diperlukan dalam pengolahan data kita. Dalam analisis korelasi variabel metrik kita tidak lagi menggunakan tabel silang, tetapi kita langsung menganalisis kolom-kolom yang ada di dataset kita.

```{r }
library(tidyverse)
library(readr)
```

**Memuat dataset**

Kita akan menggunakan dataset keempat kampus di Kota Bandar Lampung dan sekitarnya sebagai bahan. Tulis ulang dan jalankan baris perintah berikut untuk mengolah data keempat kampus

```{r}
# Membaca data
data_mahasiswa <- read_csv2("datasets/Data Praktikum 07.csv")
```

**Mengatur Faktor untuk Variabel Kategoris: Opsional**

Karena kita hanya akan berkutat dengan variabel-variabel metrik, maka kita bisa saja melewatkan tahap ini.

## Pola Hubungan Data

## 6.3. Pola Hubungan Data

Dalam analisis korelasi variabel-variabel metrik kita dapat menganalisis satu lagi sifat hubungan dalam dua variabel yang kita perhitungkan: **pola hubungan data.** Pola hubungan adalah bentuk sebaran titik-titik yang dapat kita lihat dengan diagram pencar *(scatter plot)*.

**Membuat Diagram Pencar**

Membuat diagram pencar dapat dilakukan dengan menerapkan perintah `geom_point()` dari pustaka `ggplot2`yang dimuat bersama pustaka `tidyverse`.

Kita akan melihat pola sebaran data kita dilihat dari variabel jarak dari kampus (`jarak`) dengan biaya yang dikeluarkan untuk transportasi selama sepekan (`biaya sepekan`). Variabel-variabel yang akan kita lihat hubungannya itu kita masukkan ke `x` dan `y` yang adalah dalam perintah `aes()`.

```{r membuat-scatter-plot}
# Membuat diagram pencar antara variabel jarak dan biaya transportasi sepekan
scatter_plot <- ggplot(data = data_mahasiswa,
                       mapping = aes(x = jarak, # variabel di sumbu X
                                     y = `biaya sepekan`)) + # variabel di sumbu Y
  geom_point(aes(color = `jenis tempat tinggal`)) + # perintah untuk menampilkan diagram pencar
  labs(title = "Jarak tempat tinggal vs. Biaya Transportasi Sepekan",
       y = "Biaya transportasi sepekan (ribu rupiah)",
       x = "Jarak dari tempat tinggal ke kampus (km)")

# Menampilkan diagram
scatter_plot
```

Dari diagram yang dihasilkan kita dapat menarik interpretasi hubungan antara kedua variabel secara visual:

-   Tidak ada kecenderungan arah hubungan antara jarak tempat tinggal ke kampus dengan biaya transportasi per pekan
-   Terdapat responden yang tinggal dekat dengan kampus (\<10 km) tetapi biayanya tetap tinggi (\>Rp200 ribu), juga yang tinggal jauh dari kampus (20-40 km) tetapi biayanya rendah (\<Rp200 ribu)

Dari hasil diagram ini kita sudah bisa menduga bahwa hubungan antara jarak tempat tinggal ke kampus dengan biaya yang dikeluarkan tidak terlalu erat dan arahnya tidak beraturan.

Akan tetapi, untuk lebih jelas, kita perlu meninjaunya lewat angka koefisien korelasi.

## Analisis Korelasi Spearman's $\rho$

Setidaknya ada dua kondisi yang menganjurkan kita menganalisis korelasi suatu pasangan variabel metrik dengan koefisien $\rho$ Spearman:

-   Koefisien $\rho$ Spearman biasanya digunakan untuk menganalisis korelasi dua variabel peringkat *(rank)*. Dengan kata lain, koefisien ini lebih cocok dikenakan pada variabel-variabel dengan tingkat pengukuran **interval**, seperti peringkat, *rating* atau data lain yang tidak memiliki titik nol absolut yang bermakna.

-   Kita **tidak menemukan adanya hubungan linear** antara dua variabel metrik yang kita analisis. Jika menurut pola data kita ditemukan hubungan linear, kita dianjurkan menggunakan koefisien $\rho$ Spearman ini.

Kita akan menggunakan koefisien korelasi $\rho$ Spearman ini untuk menganalisis hubungan antara jarak tempat tinggal dengan biaya yang dikeluarkan per pekan.

Koefisien korelasi untuk variabel metrik di R dapat dianalisis dengan perintah `cor()` yang mengambil masukan berupa vektor data angka variabel-variabel yang kita analisis. Adapun jenis korelasi dapat kita pilih dengan menambahkan argumen `method =` yang dapat bernilai `"spearman",` `"kendall"`, atau `"pearson"`, sesuai dengan metode yang kita gunakan.

```{r korelasi-spearman-rho}
# Mengatur variabel x dan y
x <- data_mahasiswa$jarak
y <- data_mahasiswa$`biaya sepekan`

cor(x, y, method = "spearman")
```

Sebagaimana koefisien-koefisien korelasi lainnya, nilai $\rho$ Spearman berkisar antara $-1$ hingga $+1$ yang menyatakan hubungan berlawanan yang kuat hingga hubungan searah yang kuat. Secara umum, tanda positif pada koefisien tersebut menunjukkan hubungan yang searah antara biaya transportasi sepekan dengan jarak tempuh ke kampus. Akan tetapi, dilihat dari besar nilainya, sulit mengatakan bahwa terdapat hubungan yang kuat antara jarak tempuh ke kampus dengan biaya perjalanan sepekan.

## Analisis Korelasi Pearson's *r*

Untuk analisis menggunakan koefisien korelasi Pearson's r, kita akan memodifikasi sedikit data kita. Kita akan melihat hubungan antara jumlah perjalanan di hari kerja *(weekdays)* dengan jarak tempat tinggal ke kampus **untuk pengguna transportasi online saja**. Dengan demikian, kita perlu membuat dataset terpisah dari dataset utama kita.

Terlebih dahulu, kita perlu membuat variabel khusus `Jumlah Perjalanan Weekdays` yang merupakan penjumlahan dari kolom-kolom `Jumlah Perjalanan Senin` hingga `Jumlah Perjalanan Jumat`. Perhatikan cara pembuatannya yang menggunakan perintah `rowSums()` dan `across()` yang merupakan perintah khusus untuk operasi-operasi antarkolom. Tanda `:` bermakna "pilih kolom dari jumlah perjalanan hari senin sampai kolom jumlah perjalanan hari jumat". Hal ini memungkinkan karena dalam dataset kita kolom-kolom tersebut posisinya berdekatan.

```{r membuat-kolom-jumlah-perj-weekdays}
# Membuat kolom jumlah perjalanan weekdays
data_mahasiswa <- data_mahasiswa |> 
  mutate(`Jumlah Perjalanan Weekdays` = rowSums(
    across(`Jumlah Perjalanan Senin`:`Jumlah Perjalanan Jumat`)
  ))
```

Setelah itu, barulah kita membuat dataset khusus pengguna layanan online saja. Kita menggunakan perintah `filter()` dengan operator `==` yang bermakna *saringlah data dengan nilai* `` `kendaraan utama` `` *sama dengan* `"Layanan online"`*.*

```{r filter-data-online}
# Memilih responden mahasiswa pengguna angkutan daring saja
# dan membuatnya menjadi dataset baru
data_mahasiswa_online <- data_mahasiswa |> 
  filter(`kendaraan utama` == "Layanan online")
```

Kita dapat mengecek hasilnya dengan melakukan perintah `group_by()` dan `summarize()`. Hasilnya akan menampilkan `kendaraan utama` kita hanya bernilai `"Layanan online"`

```{r mengecek-hasil-filter}
# Menampilkan hasil filter
data_mahasiswa_online |> 
  group_by(`kendaraan utama`) |> 
  summarize("jumlah" = n())
```

Kemudian, kita bisa menghitung koefisien korelasi Pearson's $r$-nya.

```{r korelasi-pearson-r}
# Mengatur variabel x dan y
x <- data_mahasiswa_online$jarak
y <- data_mahasiswa_online$`Jumlah Perjalanan Weekdays`

cor(x, y, method = "pearson")
```

Interpretasi hasil koefisien tersebut sama dengan interpretasi koefisien korelasi variabel ordinal, yakni tanda menunjukkan arah hubungan sementara besar angka menunjukkan kekuatan hubungan.

**Latihan: Interpretasikan nilai korelasi r tersebut**

Kita akan menelaah hubungan antara dua variabel tersebut berdasarkan tampilan visualnya dari diagram pencar *(scatterplot)*.

```{r}
# Membuat diagram pencar antara variabel jumlah perjalanan weekdays dan jarak tempat tinggal pengguna online
scatter_plot <- ggplot(data = data_mahasiswa_online,
                       mapping = aes(x = jarak, # variabel di sumbu X
                                     y = `Jumlah Perjalanan Weekdays`)) + # variabel di sumbu Y
  geom_point() + # perintah untuk menampilkan diagram pencar
  labs(title = "Jumlah Perjalanan Weekdays vs Jarak Tempat Tinggal dari Kampus",
       subtitle = "Pengguna layanan daring",
       y = "Jumlah Perjalanan Weekdays",
       x = "Jarak dari kampus (km)")

# Menampilkan scatter plot
scatter_plot
```

Perhatikan bentuk sebaran titik-titik dalam diagram pencarnya. Secara sekilas, sebaran titik-titik tersebut membentuk formasi kemiringan ke bawah, akan tetapi kerapatannya kecil.

::: {.rmdexercise}
**Aktivitas Mandiri 3: Analisis Korelasi Metrik Komprehensif [STP-11.2]**

1. **Pilih 3 Pasang Variabel Metrik:**
   - Buat scatter plot untuk setiap pasangan
   - Pilih Pearson atau Spearman berdasarkan pola
   - Hitung koefisien korelasi
   - Interpretasikan arah dan kekuatan

2. **Jelaskan Pemilihan Metode:**
   - Mengapa Pearson atau Spearman untuk setiap pasangan?
   - Pertimbangkan: pola linear vs monoton, outlier, distribusi data
:::

------------------------------------------------------------------------

<!--chapter:end:07-korelasi-metrik.Rmd-->

# Modul-8: Analisis Hubungan Kausalitas: Regresi Linear Sederhana dan Berganda

Setelah mempelajari modul ini, Anda diharapkan dapat:

1. mampu menghasilkan regresi linear sederhana dengan perangkat lunak komputer [STP-13.3]{.capaian}
2. mampu menghasilkan persamaan regresi linear berganda dengan perangkat lunak komputer [STP-14.3]{.capaian}


---

## Pendahuluan

Analisis regresi linear adalah analisis statistik untuk menyatakan hubungan sebab-akibat (kausalitas) antar minimal dua variabel. Analisis regresi linear yang melibatkan *dua variabel saja* (*satu variabel dependen* dan *satu variabel independen*), kita sebut sebagai **regresi linear sederhana**, sedangkan analisis regresi linar yang melibatkan lebih dari dua variabel (*satu variabel dependen* dan *lebih dari satu variabel independen*) kita sebut sebagai **regresi linear berganda *(multiple linear regression)***

Analisis regresi linear mewajibkan tingkat pengukuran minimal untuk variabel dependennya adalah **metrik**. Sementara itu, variabel independennya dapat berupa metrik atau bukan (ordinal/nominal).

Analisis regresi linear menghasilkan persamaan yang disebut **persamaan regresi linear**. Bentuk umum persamaan regresi linear tersebut adalah sebagai berikut.

$$
y = Î²_0 + Î²_1x
$$

dengan

-   $y$ adalah variabel dependen (disebut juga *variabel respons* atau *predicted variable*)
-   $x$ adalah variabel independen (disebut juga *variabel eksplanatory* atau *predictor variable*)
-   $\beta_0$ adalah konstanta yang menjadi *intercept*, yaitu nilai $y$ ketika $x=0$
-   $\beta_1$ adalah koefisien yang menyatakan seberapa besar perubahan $y$ ketika satu unit nilai $x$ berubah.

Persamaan regresi linear di atas adalah untuk **analisis regresi linear sederhana**, yakni analisis regresi linear yang melibatkan dua variabel saja. Untuk **regresi linear berganda**, kita hanya perlu menambahkan pasangan $\beta$ dan $x$ lainnya, sehingga bentuk umum untuk persamaan regresi linear berganda adalah seperti berikut.

$$
y = Î²_0 + Î²_1x_1 + Î²_2x_2 + ... + Î²_kx_k
$$

dengan

-   $x_k$ adalah variabel independen ke-$k$
-   $\beta_k$ adalah koefisien untuk variabel independen ke-$k$ tersebut

## Penjelasan Kasus

Dalam praktikum kali ini, kita akan memodelkan hubungan kausal antara dua variabel metrik: **jarak tempat tinggal ke kampus** dan **biaya perjalanan sepekan** untuk mahasiswa-mahasiswi yang menggunakan **kendaraan layanan online saja**. Harga perjalanan menggunakan layanan *online* tentunya dipengaruhi oleh jarak tempuh kendaraan tersebut. Hubungan kausal ini menjadi kasus untuk **regresi linear sederhana**.

Untuk **regresi linear berganda**, kita akan melibatkan satu variabel tambahan sebagai variabel independen, yakni variabel berjenis kategoris , sehingga kita memiliki total variabel sejumlah 3 buah (1 variabel dependen, 2 variabel independen).

## Memuat Pustaka *(Libraries)* yang Diperlukan

Seperti biasa, kita perlu memuat pustaka *(libraries)* yang diperlukan dalam pengolahan data kita. Seperti halnya juga analisis korelasi variabel metrik, kita tidak lagi menggunakan tabel silang, tetapi kita langsung menganalisis kolom-kolom yang ada di dataset kita.

```{r }
library(tidyverse) # untuk mengolah data terstruktur
library(readr) # untuk membaca file csv
library(gtsummary) # untuk memproduksi tabel hasil pembuatan regresi dengan cepat dan rapi
```

## Memuat Dataset

Kita akan menggunakan dataset keempat kampus di Kota Bandar Lampung dan sekitarnya sebagai bahan. Kemudian kita akan menyaring objek-objek yang memiliki nilai variabel `kendaraan utama` sama dengan `'Layanan online'`.

```{r}
# Membaca data dari file csv
data_mahasiswa <- read_csv2("datasets/Data Praktikum 08.csv")

# Memisahkan data mahasiswa yang menggunakan kendaraan online sebagai moda utama
data_mahasiswa_online <- data_mahasiswa |> 
  filter(`kendaraan utama` == 'Layanan online')
```

## Pola Hubungan Data

Sebagai pendahuluan, kita akan mengidentifikasi kekuatan, arah, dan pola hubungan antara variabel dependen dan independen kita (biaya perjalanan sepekan dan jarak tempat tinggal-kampus). Untuk itu kita dapat menghitung koefisien korelasi untuk hubungan variabel metrik juga, yakni koefisien korelasi Pearson's $r$.

Pola hubungan akan kita analisis dengan membuat diagram pencar *(scatter plot)* antara variabel dependen dengan variabel independennya.

**Menghitung Koefisien Pearson's** $r$

Menghitung koefisien korelasi Pearson's $r$ dapat kita lakukan dengan perintah `cor()` dengan atribut `method = "pearson"` setelah terlebih dahulu menyimpan nilai masing-masing variabel ke dalam suatu vektor.

```{r}
# Menyimpan vektor jarak dan biaya (perjalanan) sepekan ke dalam variabel 
# 'x' dan 'y'
x <- data_mahasiswa_online$jarak
y <- data_mahasiswa_online$`biaya sepekan`

cor(x, y, use = "complete.obs", method = "pearson")
```

> **Jawablah:** Tuliskan interpretasi kalian terhadap koefisien korelasi antara variabel jarak tempuh dengan biaya perjalanan sepekan.
>
> *Petunjuk: ulas kekuatan serta arah hubungannya serta maknai secara kontekstual ulasan tersebut*

**Membuat Diagram Pencar**

Membuat diagram pencar dapat dilakukan dengan menerapkan perintah `geom_point()` dari pustaka `ggplot2` yang dimuat bersama pustaka `tidyverse`.

```{r}
# Membuat diagram pencar antara variabel jarak dan biaya transportasi sepekan
# untuk mahasiswa yang pakai layanan online
scp <- ggplot(data = data_mahasiswa_online,
              mapping = aes(x = jarak, # variabel di sumbu X
                            y = `biaya sepekan`)
              ) + # variabel di sumbu Y
  geom_point(color = 'navy',  # perintah untuk menampilkan diagram pencar dengan warna biru
             size = 1.5,      # mengatur ukuran titik
             shape = 15) +    # mengatur bentuk titik menjadi persegi
  labs(title = "Jarak tempat tinggal vs. Biaya Transportasi Sepekan",
       subtitle = "Mahasiswa dengan Moda Transportasi Layanan Online",
       y = "Biaya transportasi sepekan (ribu rupiah)",
       x = "Jarak dari tempat tinggal ke kampus (km)")

# Menampilkan diagram
scp
```

Setelah Anda melakukan pembuatan diagram pencar tersebut, Anda akan menyadari bahwa kita memiliki *outlier* (pencilan), yakni objek yang memiliki nilai jarak dari tempat tinggal ke kampus mencapai hampir 25 km.

Keberadaan pencilan ini akan mengganggu hasil analisis kita. Mari kita buktikan dengan menghilangkan data pencilan tersebut.

```{r}
# Menghilangkan observasi pencilan dengan menyaring observasi dengan
# jarak < 15 km
data_mahasiswa_online <- data_mahasiswa_online |> 
  filter(jarak < 15)
```

Di sini kita akan menghitung ulang nilai koefisien korelasi kita.

```{r}
# Menghitung korelasi antara biaya sepekan dengan jarak dari dataset yang
# sudah dihilangkan pencilannya
x <- data_mahasiswa_online$jarak
y <- data_mahasiswa_online$`biaya sepekan`

cor(x, y, method = "pearson")
```

> **Jawablah:** Bagaimana perbedaan nilai koefisiennya?

Kita pun dapat memeriksa hasil perbaikan dataset kita dari diagram pencar yang baru berikut.

```{r}
# Membuat diagram pencar antara variabel jarak dan biaya transportasi sepekan
# untuk mahasiswa yang pakai layanan online, setelah pencilan dihilangkan
scp <- ggplot(data = data_mahasiswa_online,
              mapping = aes(x = jarak, # variabel di sumbu X
                            y = `biaya sepekan`)) + # variabel di sumbu Y
  geom_point(color = 'navy',  # perintah untuk menampilkan diagram pencar
             size = 1.5,      # mengatur ukuran titik
             shape = 15) +    # mengatur bentuk titik menjadi persegi
  labs(title = "Jarak tempat tinggal vs. Biaya Transportasi Sepekan",
       subtitle = "Mahasiswa dengan Moda Transportasi Layanan Online",
       y = "Biaya transportasi sepekan (ribu rupiah)",
       x = "Jarak dari tempat tinggal ke kampus (km)")

# Menampilkan diagram yang baru
scp
```

## Model Regresi Linear Sederhana

Dalam bagian ini kita akan mempelajari cara menyusun, menampilkan, menafsirkan/menginterpretasi, dan memprediksi nilai variabel dependen berdasarkan model yang kita susun.

### Penyusunan Model

Untuk membuat persamaan model regresi linear, kita akan menggunakan perintah `lm` yang sudah disediakan secara bawaan oleh R. Hasil dari perintah ini dapat kita simpan sebagai variabel tertentu.

```{r}
# Membuat model regresi linear
model <- lm(y ~ x, data = data_mahasiswa_online)
```

Argumen yang kita gunakan adalah `var_dependen ~ var_independen` serta nama dataset yang kita gunakan. Tanda `~` (disebut *tilde*) dapat kita masukkan dengan menekan `Shift` + `` ` `` yang ada di sebelah kiri tombol angka 1 di *keyboard* kita.

Sebelumnya kita sudah mendefinisikan `y` dan `x` sebagai variabel untuk vektor biaya transportasi sepekan dan vektor jarak, sehingga kita bisa langsung menggunakannya di atas. Dataset yang kita gunakan adalah dataset mahasiswa yang menggunakan layanan *online* sebagai moda transportasi utama yang kita simpan dalam `data_mahasiswa_online`.

### Penampilan Model

Untuk menampilkan hasil penyusunan model regresi linear, kita akan menggunakan perintah `summary` yang juga sudah disediakan secara bawaan oleh R.

```{r hasil-regresi}
# Menampilkan hasil model regresi linear
summary(model)
```

Yang ditampilkan dengan perintah tersebut antara lain adalah sebagai berikut. Penjelasan lebih lanjutnya akan diberikan di subbagian selanjutnya.

-   `Call` : bentuk persamaan model yang sudah kita input sebelumnya

-   `Residuals` : informasi residual model

-   `Coefficients` : tabel yang menunjukkan angka-angka dalam persamaan model yang dihasilkan

-   Nilai-nilai uji kualitas model seperti `Residual standard error` *(standard error* estimasi), *Multiple R-squared* dan *Adjusted R-squared* (koefisien determinasi), serta *F-statistic* (uji signifikansi model).

Selain menggunakan `summary`, kita juga dapat menggunakan perintah `tbl_regression`, perintah yang disediakan oleh paket/*library* `gtsummary`. Hasil dari perintah ini adalah tabel yang sudah diformat sesuai dengan *templat* artikel ilmiah.

```{r}
# Menampilkan hasil model regresi linear dengan tbl_regression
tbl_regression(model)
```

Jika kalian menemukan pertanyaan untuk menginstal sebuah paket di *console*, yakni `broom.helpers`, pilih saja "Yes" untuk mengunduh dan menginstalnya.

Secara bawaan, tabel tidak menampilkan nilai konstanta *(intercept)*, menampilkan nilai *confidence level* 95%, dan menampilkan nilai dari variabel independen sesuai variabel yang kita tetapkan sebelumnya, dalam hal ini adalah `x`. Untuk menggantinya, kita dapat melakukan penyesuaian perintah sebagai berikut.

```{r}
tbl_regression(
  model,
  intercept = TRUE, # mengatur intercept-nya ditampilkan
  conf.level = 0.99, # mengatur nilai confidence level menjadi 99%
  label = list(x ~ "Jarak tempuh ke kampus, km") # Mengganti tulisan "x" saja menjadi yang
) # lebih bermakna
```

### Penafsiran/interpretasi Model

Yang kita akan tafsirkan dari model kita di antaranya adalah:

-   persamaan model

-   makna nilai konstanta dan koefisien

-   uji kualitas model (ANOVA, `F-statistic`)

-   uji kualitas variabel (`Pr(>|t|)`)

#### Tafsiran persamaan model

Persamaan model dapat kita tafsirkan berdasarkan keluaran dari `summary` berupa `Coefficients` atau hasil dari `tbl_regression` milik `gtsummary`.

Berdasarkan keluaran kedua perintah tersebut, kita dapat mengetahui bagaimana persamaan regresi linearnya dengan mengganti bentuk umum persamaan regresi linear dengan angka-angka yang dihasilkan di `model`.

Bentuk umum:

$$
y = Î²_0 + Î²_1x
$$

Dengan mengambil hasil dari *summary(model)*, kita dapat menuliskan persamaan regresi linear kita menjadi:

$$
y = 93 - 5,3x
$$

Dari persamaan model ini kita dapat menggambar garis yang melewati titik-titik data kita. Ini merupakan persamaan garis terbaik dari seluruh kemungkinan persamaan garis yang ada, yang kita tentukan dengan meminimalkan kuadrat terkecil.

```{r}
# Membuat diagram pencar antara variabel jarak dan biaya transportasi sepekan
# untuk mahasiswa yang pakai layanan online, setelah pencilan dihilangkan,
# ditambah garis dari persamaan regresi
scp <- ggplot(data = data_mahasiswa_online,
              mapping = aes(x = jarak, # variabel di sumbu X
                            y = `biaya sepekan`)) + # variabel di sumbu Y
  geom_point(color = 'navy',  
             size = 1.5,      
             shape = 15) +    
  geom_abline(aes(intercept = coef(model)[1],
                  slope = coef(model)[2],
                  color = "red")) +
  labs(title = "Jarak tempat tinggal vs. Biaya Transportasi Sepekan",
       subtitle = "Mahasiswa dengan Moda Transportasi Layanan Online",
       y = "Biaya transportasi sepekan (ribu rupiah)",
       x = "Jarak dari tempat tinggal ke kampus (km)")

# Menampilkan diagram pencar
scp
```

-   `coef(model)[1]` mengacu pada keluaran fungsi `coef` dari variabel `model` kita yang pertama (`[1]`), yakni angka *intercept*/konstantanya. Ini menjadi nilai dari atribut `intercept` yang terletak dalam fungsi `geom_abline`

-   `coef(model)[2]` mengacu pada keluaran fungsi `coef` dari variabel `model` kita yang kedua ([`2]`), yakni angka koefisien variabel independen kita. Ini menjadi nilai dari atribut `slope` yang terletak dalam fungsi `geom_abline` karena nilai koefisien variabel independen menunjukkan kemiringan garis persamaan regresi linear kita

Persamaan model dapat kita tafsirkan berdasarkan keluaran dari `summary` berupa `Coefficients` atau hasil dari `tbl_regression` milik `gtsummary`.

Berdasarkan keluaran kedua perintah tersebut, kita dapat mengetahui bagaimana persamaan regresi linearnya dengan mengganti bentuk umum persamaan regresi linear dengan angka-angka yang dihasilkan di `model`.

Bentuk umum:

$$
y = Î²_0 + Î²_1x
$$

Dengan mengambil hasil dari *summary(model)*, kita dapat menuliskan persamaan regresi linear kita menjadi:

$$
y = 93 - 5,3x
$$

Dari persamaan model ini kita dapat menggambar garis yang melewati titik-titik data kita. Ini merupakan persamaan garis terbaik dari seluruh kemungkinan persamaan garis yang ada, yang kita tentukan dengan meminimalkan kuadrat terkecil.

```{r}
# Membuat diagram pencar antara variabel jarak dan biaya transportasi sepekan
# untuk mahasiswa yang pakai layanan online, setelah pencilan dihilangkan,
# ditambah garis dari persamaan regresi
scp <- ggplot(data = data_mahasiswa_online,
              mapping = aes(x = jarak, # variabel di sumbu X
                            y = `biaya sepekan`)) + # variabel di sumbu Y
  geom_point(color = 'navy',  
             size = 1.5,      
             shape = 15) +    
  geom_abline(aes(intercept = coef(model)[1],
                  slope = coef(model)[2],
                  color = "red")) +
  labs(title = "Jarak tempat tinggal vs. Biaya Transportasi Sepekan",
       subtitle = "Mahasiswa dengan Moda Transportasi Layanan Online",
       y = "Biaya transportasi sepekan (ribu rupiah)",
       x = "Jarak dari tempat tinggal ke kampus (km)")

# Menampilkan diagram pencar
scp
```

-   `coef(model)[1]` mengacu pada keluaran fungsi `coef` dari variabel `model` kita yang pertama (`[1]`), yakni angka *intercept*/konstantanya. Ini menjadi nilai dari atribut `intercept` yang terletak dalam fungsi `geom_abline`

-   `coef(model)[2]` mengacu pada keluaran fungsi `coef` dari variabel `model` kita yang kedua ([`2]`), yakni angka koefisien variabel independen kita. Ini menjadi nilai dari atribut `slope` yang terletak dalam fungsi `geom_abline` karena nilai koefisien variabel independen menunjukkan kemiringan garis persamaan regresi linear kita

#### Tafsiran nilai konstanta dan koefisien

Persamaan regresi linear ini bermakna nilai konstanta sebesar 93 berarti bahwa dengan tinggal di kampus ($x=0$), mahasiswa masih akan mengeluarkan biaya sebesar 93.000 rupiah (ingat bahwa variabel `biaya sepekan` menggunakan satuan ribuan rupiah) untuk mengakses kampus selama sepekan. Kita bisa pahami hal tersebut sebagai perkiraan harga sewa penginapan di kampus.

Sementara itu, nilai koefisien sebesar $-5,3$ berarti bahwa penambahan jarak sebesar 1 km akan **mengurangi** biaya transportasi sepekan sebesar 5.300 rupiah. Artinya, makin jauh 1 km seorang mahasiswa tinggal dari kampus, makin kecil pula biaya transportasi sepekannya sebesar 5.300 rupiah.

> **Pertanyaan bonus:** Mengapa mahasiswa yang tinggal lebih jauh dari kampus biaya perjalanan sepekannya lebih kecil? Bukankah biaya transportasi makin jauh malah makin mahal?

#### Tafsiran uji kualitas model

Uji kualitas model kita terdiri atas *standard error* dari residual, koefisien determinasi atau $R^2$, dan uji signifikansi persamaan menggunakan statistik $F$ (`F-statistic`) yang merupakan hasil ANOVA *(analysis of variance)*.

-   *Standard error* dari residual mencerminkan rata-rata galat (residu), yaitu selisih nilai variabel dependen yang dihitung (biaya perjalanan sepekan hasil prediksi dari model) dengan nilai variabel dependen yang kita peroleh dari data.

    -   Hasil `summary` menunjukkan angka 38,11 yang artinya rata-rata kesalahan prediksi dari model kita adalah sebesar 38.110 rupiah.

-   Koefisien determinasi atau $R^2$ menyatakan kesesuaian *(fit)* dari model kita, yakni seberapa banyak proporsi variansi data variabel dependen kita (biaya perjalanan sepekan) dijelaskan oleh variabel independennya (jarak dari kampus ke tempat tinggal).

    Sisa dari angka $R^2$ ini adalah banyak variansi yang tidak dijelaskan oleh variabel independen, artinya dijelaskan oleh variabel lainnya yang tidak ada dalam model dan juga keacakan (misal dalam pengambilan data atau kejadian acak).

    -   Hasil `summary` menunjukkan angka 0,095 yang berarti hanya 9,5% variansi biaya perjalanan sepekan dijelaskan oleh variansi jarak perjalanan ke kampus.

    -   Makin tinggi nilai $R^2$ dari model kita, makin besar proporsi variansi variabel dependen kita dijelaskan oleh variabel independennya.

    -   Hal ini menunjukkan bahwa pengaruh dari variabel independen kita terhadap variabel dependennya kuat

-   Koefisien uji signifikansi ($F$) (`F-statistics`) adalah uji hipotesis ANOVA *(analysis of variance)* yang membuktikan hipotesis nol bahwa tidak ada hubungan antara variabel dependen dengan variabel independen yang kita modelkan. Penerimaan hipotesis nol ini ditandai dari nilai signifikansi (`p-value`) yang lebih kecil dari 5% (`0.05`).

    -   Hasil `summary` menunjukkan bahwa nilai `p-value` kita adalah `1,721e-05`. Angka tersebut menyatakan notasi ilmiah $1,721\times10^{-5}$ yang berarti bahwa nilai `p-value` kita sangat-sangat lebih kecil dari `0.05.`

    -   Ini artinya kita tidak dapat menerima hipotesis nol kita yang menyatakan tidak ada hubungan antara variabel biaya perjalanan sepekan (variabel dependen) dengan variabel jarak tempuh ke kampus (variabel independen).

**Simpulan tafsiran kualitas model**: kita sudah melihat bahwa hubungan kausal antara variabel jarak ke kampus terhadap biaya perjalanan sepekan adalah terbalik dengan besar kemiringan 5,3. Hubungan kausal tersebut benar-benar ada berdasarkan hasil dari koefisien uji signifikansi (ANOVA) yang *p-value-*nya \<0,05. Akan tetapi, hubungan tersebut tidak cukup kuat karena nilai koefisien determinasi yang kecil, yakni hanya 9% saja.

#### Tafsiran uji kualitas variabel

Uji kualitas variabel adalah pengujian terhadap signifikansi atau kepentingan variabel independen kita. Hasil pengujian ini diperlihatkan oleh angka *p-value* dari uji t (`t value`)-nya, yakni yang ada di kolom `Pr(>|t|)`.

Apabila nilai `Pr(>|t|)` kita \>0,05 maka variabel independen kita dianggap **tidak signifikan**, karena artinya nilai koefisien yang ada di kolom `Estimate` **sebenarnya adalah nol** sehingga **bisa dikeluarkan dari persamaan regresi linear**.

Sebaliknya, jika nilai `Pr(>|t|)` kita \<0,05 maka variabel independen kita dianggap **signifikan**, artinya nilai koefisien yang ada di kolom `Estimate` **sebenarnya adalah nilai koefisien tersebut.**

Nilai `Pr(>|t|)` variabel `x` adalah `1,721e-05` yang berarti koefisien senilai `-5.321` adalah **signifikan**.

### Melakukan Prediksi

Kita melakukan prediksi dengan menggunakan perintah `predict`. Misalkan kita ingin melakukan prediksi biaya perjalanan sepekan untuk mahasiswa yang tinggal di jarak 90 dan 120 km dari kampus

```{r}
bahan_pred <- tibble(x = c(90, 120))

predict(model, bahan_pred)
```

-   Perintah `tibble` adalah perintah untuk membuat dataset berisi kolom `x` yang terdiri atas 2 nilai: 90 km dan 120 km. Kita menyimpan dataset contoh tersebut ke dalam variabel bernama `bahan_pred`

-   Dalam membuat dataset untuk prediksi kita harus memperhatikan nama variabel/nama kolom yang kita berikan dalam perintah `tibble`. Nama kolom yang akan kita prediksi harus **sama persis** dengan nama variabel yang kita nyatakan dalam perintah `lm`.

## Model Regresi Linear Berganda

Dalam bagian ini kita hanya akan mempelajari penggunaan variabel *dummy* untuk meningkatkan kekuatan prediksi kita. Di akhir, Anda akan menafsirkan hal-hal yang sudah Anda pelajari pada bagian regresi linear.

Kita akan menggunakan variabel `jenis tempat tinggal` untuk variabel *dummy*. Pertama, kita akan mengatur jenis nilai pada kolom `jenis tempat tinggal` menggunakan perintah `factor`.

```{r}
# Membuat nilai kolom menjadi variabel kategoris dengan 'factor'
data_mahasiswa_online$`jenis tempat tinggal` <- factor(data_mahasiswa_online$`jenis tempat tinggal`)
```

Kedua, kita akan membuat model seperti halnya yang kita lakukan dalam analisis regresi linear sederhana. Kita akan menggunakan nama yang lebih representatif.

```{r}
# Membuat variabel-variabel
jarak <- x # variabel 'x' saja diubah menjadi 'jarak'
biaya <- y # variabel 'y' saja diubah menjadi 'biaya'
ling <- data_mahasiswa_online$`jenis tempat tinggal` # tempat tinggal diberi
                                                     # nama 'ling'

# Menyatakan model
mdl <- lm(biaya ~ jarak + ling, data = data_mahasiswa_online)

# Melihat hasil pemodelan
summary(mdl)
```

Selanjutnya, kita akan menafsirkan hasil dari summary model ini.

### Penjelasan Variabel *Dummy*

Dalam persamaan model kita tersebut, variabel `ling` atau `jenis tempat tinggal` diubah menjadi variabel *dummy* :

1.  `lingKos sendiri`,
2.  `lingRumah mengontrak bersama`,
3.  `lingRumah mengontrak pribadi`,
4.  `lingRumah pribadi`, dan
5.  `lingRumah saudara`.

Nama variabel-variabel tersebut tak lain adalah gabungan kata `ling` dengan tiap-tiap kategori dalam variabel `jenis tempat tinggal`.

Perhatikan bahwa kita jadi memiliki 5 variabel *dummy* dari satu variabel kategoris `jenis tempat tinggal` yang terdiri atas 6 kategori nilai: "Kos bersama-sama", "Kos sendiri", "Rumah mengontrak bersama", "Rumah mengontrak pribadi", "Rumah pribadi", dan "Rumah saudara."

Variabel *dummy* adalah variabel yang bernilai 0 (nol) atau 1 (satu) saja. Nol artinya variabel *dummy* tersebut bernilai "salah" atau "tidak", sedangkan satu artinya variabel *dummy* tersebut bernilai "benar" atau "ya."

Variabel-variabel *dummy* yang 5 buah ini hanya akan bernilai 1 atau 0 sesuai dengan kategori dari variabel `jenis tempat tinggal` suatu objek. Perhatikan bahwa kita tidak punya "`lingKos sendiri`" dalam variabel *dummy* kita. Ini artinya apabila kategori `jenis tempat tinggal` suatu objek adalah "Kos sendiri", **kelima variabel *dummy* akan bernilai 0.**

Tabel berikut merangkum nilai-nilai variabel *dummy* untuk setiap kategori nilai variabel `jenis tempat tinggal`.

| Kategori                 | `lingKos sendiri` | `lingRumah mengontrak bersama` | `lingRumah mengontrak pribadi` | `lingRumah pribadi` | `lingRumah saudara` |
| ------------------------ | ----------------- | ------------------------------ | ------------------------------ | ------------------- | ------------------- |
| Kos sendiri              | 1                 | 0                              | 0                              | 0                   | 0                   |
| Rumah mengontrak bersama | 0                 | 1                              | 0                              | 0                   | 0                   |
| Rumah mengontrak pribadi | 0                 | 0                              | 1                              | 0                   | 0                   |
| Rumah pribadi            | 0                 | 0                              | 0                              | 1                   | 0                   |
| Rumah saudara            | 0                 | 0                              | 0                              | 0                   | 1                   |
| Kos bersama              | 0                 | 0                              | 0                              | 0                   | 0                   |

: Nilai variabel dummy untuk setiap kategori

### Interpretasi Variabel *Dummy*

Dalam menginterpretasi variable *dummy* kita tidak bisa menggunakan `Pr(>|t|)` semata, karena variabel *dummy* pada hakikatnya sepaket. Jadi, walaupun nilai `Pr(>|t|)` sebuah variabel *dummy* adalah \>0,05 ia akan tetap berada dalam persamaan regresi linear.

Interpretasi koefisien variabel *dummy* adalah dengan memahami bahwa nilai variabel dependen berubah sesuai nilai koefisien apabila variabel *dummy* tersebut bernilai **benar** atau **1**. Artinya, jika mahasiswa tinggal di kosan sendirian (`lingKos sendiri = 1`), maka biaya transportasi sepekan berkurang sebesar `20.779` yang juga berarti sebesar 20,7 ribu rupiah. Jika mahasiswa tinggal di rumah pribadi (`lingRumah pribadi = 1`) maka biaya transportasi sepekan bertambah sebesar `20.348` atau 20,3 ribu rupiah.

### Prediksi Model

Dari persamaan model regresi linear kita, kita juga dapat memprediksi nilai biaya perjalanan sepekan untuk mahasiswa-mahasiswa dengan kondisi lain. Misalnya kita ingin memprediksi biaya sepekan transportasi mahasiswa yang tinggal di Rumah saudara berjarak 7,9 km dari kampus dan di Rumah kontrakan bersama yang berjarak 10 km dari kampus.

```{r}
# Menyusun dataset untuk diprediksi
mhs <- tibble(jarak = c(7.9, 10),
              ling = c("Rumah saudara", "Rumah mengontrak bersama")
              )

# melihat hasil prediksi
predict(mdl, mhs)
```

> **Jawablah:**
>
> a.  Bagaimana persamaan model regresi linear berganda kita?
> b.  Tafsirlah kualitas model kita, mulai uji kualitas model ($F$), $R^2$, serta uji kualitas setiap variabel
> c.  Apa saja yang meningkatkan dan menurunkan biaya perjalanan sepekan mahasiswa?

::: {.rmdexercise}
**Aktivitas Mandiri 4: Analisis Regresi Komprehensif [STP-13.3, STP-14.3]**

**A. Regresi Linear Sederhana [STP-13.3]:**

Model: `jumlah perjalanan weekdays` vs `jarak`
1. Buat model sederhana
2. Tuliskan persamaan regresi
3. Interpretasikan intercept dan slope
4. Uji kualitas model (F-statistic, RÂ²)

**B. Regresi Linear Berganda [STP-14.3]:**

Model: `jumlah perjalanan weekdays` ~ `jarak` + `umur` + `jenis tempat tinggal`
1. Buat model berganda
2. Tuliskan persamaan lengkap
3. Identifikasi variabel signifikan
4. Bandingkan RÂ²

**C. Interpretasi:**
- Faktor yang meningkatkan/menurunkan jumlah perjalanan?
- Proporsi variansi yang dijelaskan?
:::

------------------------------------------------------------------------

<!--chapter:end:08-regresi-linear.Rmd-->

# Modul-9: Analisis Hubungan Multivariat Interdependensi - Analisis Faktor dan PCA

Setelah mempelajari modul ini, Anda diharapkan dapat menghasilkan komponen prinsip menggunakan perangkat lunak komputer [STP-14.3]{.capaian}


---

## Pendahuluan

Analisis Komponen Prinsip (*Principal Component Analysis*, PCA) dan Analisis Faktor (*Common Factor Analysis*) adalah metode analisis multivariat yang digunakan untuk meringkas atau mereduksi jumlah variabel yang banyak menjadi beberapa dimensi baru (disebut komponen atau faktor) yang lebih sedikit, namun tetap merepresentasikan informasi dari variabel asli.

Kedua metode ini termasuk dalam analisis interdependensi, di mana seluruh variabel dianggap setara dan saling berhubungan satu sama lain, tanpa ada pembagian variabel independen dan dependen.

## Studi Kasus

Kita akan menggunakan data @bindar2022faktor, yaitu penelitian mengenai preferensi masyarakat Kota Bandung dalam mengakses lokasi *Car-Free Day* (CFD). Terdapat 12 variabel yang akan dianalisis:

1.  `ongkos`: Total biaya perjalanan
2.  `bparkir`: Biaya parkir
3.  `durasi`: Durasi perjalanan
4.  `bareng`: Jumlah rombongan dalam perjalanan
5.  `toplajur`: Jumlah lajur jalan terbanyak yang dilalui
6.  `usia`: Usia pelaku perjalanan
7.  `jmlmotor`: Jumlah sepeda motor di rumah tangga
8.  `jmlmobil`: Jumlah mobil di rumah tangga
9.  `jmlsepeda`: Jumlah sepeda di rumah tangga
10. `jmldewasa`: Jumlah orang dewasa dalam rumah tangga
11. `jmlanak`: Jumlah anak-anak dalam rumah tangga
12. `jarak`: Jarak tempuh dari rumah ke lokasi CFD

## Memuat Pustaka *(Libraries)*

Kita membutuhkan paket `tidyverse` untuk manipulasi data dan `psych` untuk melakukan uji KMO, Bartlett, serta fungsi analisis faktor dan PCA.

```{r }
library(tidyverse)
library(psych)
```

## Asumsi Awal

Sebelum melakukan analisis komponen prinsip atau analisis faktor, idealnya kita perlu memeriksa asumsi dasar, yaitu:

1.  **Linearitas**: Adanya hubungan linear antarvariabel.
2.  **Normalitas**: Variabel berdistribusi normal multivariat.

Kita dapat melakukan inspeksi visual menggunakan matriks diagram pencar (*scatter plot matrix*). Di sini kita menggunakan fungsi `pairs.panels` dari paket `psych` yang memberikan informasi lengkap berupa scatter plot, histogram, dan nilai korelasi.

```{r asumsi-awal, fig.width=10, fig.height=10, results='asis'}
# Membaca data (Kita muat di sini untuk keperluan inspeksi awal)
# Jika data belum dimuat, baris ini akan memuatnya.
data_cfd <- read_csv2("datasets/Data Praktikum 09.csv")

# Memilih 12 variabel metrik yang akan dianalisis sesuai studi kasus
# Variabel ini sama dengan yang akan digunakan pada tahap persiapan data selanjutnya
data_selected <- data_cfd |> 
  select(ongkos, bparkir, durasi, bareng, toplajur, usia, 
         jmlmotor, jmlmobil, jmlsepeda, jmldewasa, jmlanak, jarak)

# Membuat Scatter Plot Matrix menggunakan psych::pairs.panels
pairs.panels(data_selected,
             method = "pearson", # Menggunakan korelasi Pearson
             hist.col = "#00AFBB", # Warna histogram
             density = FALSE,    # Tidak menampilkan garis density agar lebih bersih
             lm.col = "red",   # Mengubah warna data points menjadi abu-abu gelap
             ellipses = TRUE,   # Menampilkan elips korelasi untuk melihat pola linearitas
             lm = TRUE,         # Menampilkan garis regresi linear lurus
             main = "Scatter Plot Matrix Asumsi Awal")
```

**Penjelasan Kode dan Output:**

-   **Kode**: Kita menggunakan fungsi `pairs.panels` dari paket `psych`. Argumen `method = "pearson"` digunakan untuk menghitung koefisien korelasi Pearson. `hist.col` mengatur warna histogram di diagonal utama. `ellipses = TRUE` menambahkan elips yang menggambarkan kovarians dan arah hubungan.
-   **Output**:
    -   **Diagonal Utama**: Menampilkan histogram distribusi frekuensi untuk setiap variabel. Kita dapat melihat apakah distribusi variabel mendekati normal (bentuk lonceng) atau menceng (*skewed*).
    -   **Bawah Diagonal**: Menampilkan *scatter plot* (diagram pencar) untuk setiap pasangan variabel. Ini berguna untuk mendeteksi pola hubungan (apakah linear) dan adanya pencilan (*outliers*).
    -   **Atas Diagonal**: Menampilkan nilai koefisien korelasi Pearson ($r$). Ukuran font angka korelasi menyesuaikan dengan besarnya nilai korelasi (semakin besar nilai, semakin besar font). **Interpretasi Singkat**:
    -   **Normalitas**: Pada diagonal utama, histogram yang berbentuk lonceng menunjukkan distribusi mendekati normal. Distribusi yang menceng (*skewed*) atau tidak simetris menandakan ketidaknormalan.
    -   **Linearitas**: Perhatikan bagian bawah diagonal (Scatter Plot).
        -   **Garis Tren**: Indikasi linearitas dapat dilihat dari garis tren (biasanya berwarna merah) yang terbentuk di antara titik-titik data. Jika garis tersebut cenderung lurus, maka hubungan antar variabel bersifat linear.
        -   **Elips**: Bentuk elips menunjukkan kekuatan korelasi. **Elips yang pipih (sempit)** menandakan korelasi kuat dan hubungan yang jelas. Sebaliknya, **elips yang cenderung bulat** menandakan korelasi yang lemah.
        -   Perbesar grafik dengan membuka hasil di jendela baru atau klik 'Zoom' jika ia muncul di panel 'Plots'.

**Latihan 2:**

Berdasarkan *Scatter Plot Matrix* di atas:

1.  Sebutkan satu variabel yang menurut Anda memiliki distribusi mendekati normal (lihat histogram diagonal)!
2.  Sebutkan pasangan variabel yang memiliki hubungan linear cukup kuat (lihat bentuk elips/sebaran data)!

## Mempersiapkan Data

Kita memastikan kembali variabel yang akan digunakan dalam analisis ini.

```{r}
# Memilih variabel yang akan dianalisis
data_analisis <- data_cfd |> 
  select(ongkos, bparkir, durasi, bareng, toplajur, usia, 
         jmlmotor, jmlmobil, jmlsepeda, jmldewasa, jmlanak, jarak)

# Melihat sekilas data
glimpse(data_analisis)
```

**Latihan 1:**

Berdasarkan output `glimpse` di atas, jawablah pertanyaan berikut:

1.  Berapa jumlah observasi (baris) atau objek dalam data tersebut?
2.  Berapa jumlah variabel (kolom) yang aktif digunakan dalam analisis?

## Uji Kelayakan Data (Asumsi)

Sebelum melakukan ekstraksi dimensi, kita perlu memastikan data layak untuk dianalisis faktor/PCA. Dua indikator utama adalah **Uji Bartlett of Sphericity** dan **Measure of Sampling Adequacy (MSA)** atau **Kaiser-Meyer-Olkin (KMO)**.

### Uji Bartlett of Sphericity

Uji ini melihat apakah terdapat korelasi antarvariabel dalam data. Syarat: Nilai $p < 0,05$.

```{r uji-bartlett}
# Uji Bartlett
cortest.bartlett(data_analisis)
```

**Latihan 3:**

Lihat nilai $p.value$ pada output di atas. Apakah nilai tersebut $< 0.05$? Apa kesimpulan Anda mengenai korelasi antar variabel dalam data ini? (Apakah matriks korelasi berbeda secara signifikan dengan matriks identitas?)

### Uji KMO dan MSA

Nilai KMO keseluruhan harus $> 0,5$. Selain itu, nilai MSA per variabel (diagonal pada matriks anti-image correlation) juga harus $> 0,5$.

```{r uji-kmo}
# Uji KMO
KMO(data_analisis)
```

Berdasarkan hasil di atas: - Nilai KMO Keseluruhan (*Overall MSA*) = 0,63 (Layak, \> 0,5). - Namun, jika dilihat per variabel (*MSA for each item*), terdapat variabel dengan nilai \< 0,5 yaitu `jmldewasa` (0,48) dan `jmlanak` (0,44).

Sesuai prosedur, kita harus mengeluarkan variabel yang tidak memenuhi syarat MSA.

```{r revisi-data}
# Mengeluarkan variabel jmldewasa dan jmlanak
data_analisis_final <- data_analisis |> 
  select(-jmldewasa, -jmlanak)

# Cek ulang KMO
KMO(data_analisis_final)
```

Sekarang seluruh variabel memiliki MSA \> 0,5 dan KMO keseluruhan naik menjadi 0,68. Data siap diekstraksi.

## Mengekstrak Dimensi Baru

Langkah selanjutnya adalah menentukan berapa jumlah dimensi (faktor/komponen) yang akan dibentuk. Kita dapat menggunakan **Analisis Paralel** atau melihat **Nilai Eigen** (*Eigenvalues*) dan **Scree Plot**.

### Nilai Eigen dan Total Variansi

Kita akan melihat berapa banyak variansi yang bisa dijelaskan oleh setiap komponen.

```{r eigen-values}
# Melakukan PCA tanpa rotasi untuk melihat Eigenvalues
analisis_awal <- principal(data_analisis_final, nfactors = 10, rotate = "none")

# Menampilkan nilai eigen
analisis_awal$values
```

Kriteria umum penentuan jumlah dimensi: 1. **Kaiser's Criterion**: Ambil komponen dengan nilai eigen \> 1. 2. **Cumulative Variance**: Ambil jumlah komponen yang menjelaskan total variansi \> 60%.

Dari nilai eigen di atas, terdapat 4 komponen dengan nilai \> 1 (2.488, 1.650, 1.236, 1.017).

### *Scree Plot*

Grafik ini menunjukkan penurunan nilai eigen. Titik di mana grafik mulai melandai (siku) menunjukkan batas jumlah faktor.

```{r scree-plot}
# Membuat Scree Plot
scree(data_analisis_final, pc=TRUE)
```

**Latihan 4:**

1.  Berdasarkan **Kaiser's Criterion** (Nilai Eigen \> 1) pada sub-bab 9.7.1, berapa komponen yang sebaiknya diekstrak?
2.  Berdasarkan **Scree Plot** di atas (lihat titik siku/ *elbow*), berapa komponen yang sebaiknya diekstrak?

Berdasarkan analisis-analisis sebelumnya, diputuskan untuk menggunakan **4 dimensi**.

## Melakukan Analisis Faktor dan Rotasi

Kita akan melakukan ekstraksi 4 faktor menggunakan metode **Analisis Faktor** (untuk pengelompokan variabel) dan **PCA** (untuk pembentukan variat), kemudian melakukan **Rotasi Varimax** agar pengelompokan variabel lebih tegas (nilai *loading* kontras).

### Analisis Faktor (Common Factor Analysis)

Analisis ini bertujuan mengelompokkan variabel-variabel yang mirip (korelasi tinggi) ke dalam faktor laten.

```{r analisis-faktor}
# Analisis Faktor dengan 4 faktor dan rotasi Varimax
# fm="pa" (Principal Axis) adalah metode umum untuk Common Factor Analysis di R (mirip SPSS)
af_result <- fa(data_analisis_final, nfactors = 4, rotate = "varimax", fm = "pa")

# Menampilkan hasil loading faktor
print(af_result$loadings, cutoff = 0.3)
```

*Catatan: `cutoff = 0.3` digunakan untuk menyembunyikan nilai loading yang kecil agar tabel lebih mudah dibaca.*

**Cara Membaca Output:** Perhatikan matriks komponen yang dirotasi (*Rotated Factor Matrix*). Setiap kolom (PA1, PA2, dst) merepresentasikan faktor. Nilai angka adalah *factor loading* (korelasi antara variabel dengan faktor).

**Contoh Identifikasi Faktor 1 (PA1):** Lihat kolom `PA1`. Variabel dengan nilai *loading* terbesar (dan di atas 0.5) adalah: - `durasi` (0.98) - `jarak` (0.96) Maka, Faktor 1 dibentuk oleh `durasi` dan `jarak`.

**Latihan 5:**

Berdasarkan output di atas, tentukan variabel pembentuk faktor lainnya:

1.  **Faktor 2 (PA2)**: Variabel apa saja yang memiliki *loading* tinggi di kolom ini?
2.  **Faktor 3 (PA3)**: Variabel apa saja yang memiliki *loading* tinggi di kolom ini?
3.  **Faktor 4 (PA4)**: Variabel apa saja yang memiliki *loading* tinggi di kolom ini?

### Analisis Komponen Prinsip (PCA)

Jika tujuan kita adalah mereduksi data menjadi skor komponen untuk analisis lanjutan (misal regresi), kita menggunakan PCA.

```{r pca-rotasi}
# PCA dengan 4 komponen dan rotasi Varimax
pca_result <- principal(data_analisis_final, nfactors = 4, rotate = "varimax")

# Menampilkan hasil loading komponen (untuk interpretasi)
print(pca_result$loadings, cutoff = 0.3)

# Menampilkan bobot skor komponen (weights) untuk pembentukan skor
print(pca_result$weights, digits = 3)
```

**Identifikasi Persamaan Komponen**

Komponen Prinsip (RC) adalah kombinasi linear dari variabel asal (yang sudah distandarisasi). Persamaannya dapat ditulis sebagai: $$RC_j = w_{1j}Z_1 + w_{2j}Z_2 + \dots + w_{pj}Z_p$$ Dimana $w$ adalah nilai **Component Score Coefficients (Weights)**, bukan nilai *loading*. Loading hanya menunjukkan korelasi, sedangkan weights menunjukkan bobot kontribusi setiap variabel dalam pembentukan skor komponen.

**Contoh:** Misalkan kita ingin membentuk persamaan untuk **RC1**. Lihat output `Weights` pada kolom `RC1`: - `durasi`: 0.524 - `jarak`: 0.451 - Variabel lain memiliki bobot yang lebih kecil.

Maka persamaannya: $$RC1 \approx 0.524(Z_{durasi}) + 0.451(Z_{jarak}) + \dots$$

**Menghasilkan Component Score**

Untuk mendapatkan nilai skor komponen setiap observasi secara otomatis, kita dapat mengakses objek `$scores` dari hasil PCA.

```{r component-scores}
# Menampilkan 6 baris pertama dari skor komponen
head(pca_result$scores)
```

**Latihan 6:**

Berdasarkan output weights PCA di atas, tuliskan persamaan matematis terbentuknya komponen **RC2**! (Sebutkan variabel mana saja yang memiliki kontribusi besar beserta koefisien weights-nya).

## Interpretasi dan Penamaan Dimensi

Langkah terakhir adalah memberi nama pada dimensi yang terbentuk berdasarkan variabel-variabel pembentuknya.

**Latihan 7:** Tuliskan seluruh kelompok dari analisis faktor dan juga seluruh persamaan komponen yang dihasilkan dari PCA!

::: {.rmdexercise}
**Aktivitas Mandiri Komprehensif: Analisis PCA Mandiri [STP-14.3]**

Gunakan dataset dengan variabel metrik yang berbeda:

1. **Persiapan:** Pilih variabel, cek normalitas, uji Bartlett/KMO
2. **Ekstraksi:** Hitung eigenvalues, buat scree plot, tentukan jumlah komponen
3. **Analisis:** Lakukan PCA dengan rotasi Varimax
4. **Interpretasi:** Identifikasi variabel pembentuk, beri nama komponen, tuliskan persamaan
5. **Evaluasi:** Hitung proporsi variansi yang dijelaskan
:::

------------------------------------------------------------------------

<!--chapter:end:09-komponen-prinsip.Rmd-->

# Referensi

<!--chapter:end:99-referensi.Rmd-->

